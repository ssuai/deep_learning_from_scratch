{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20668a4-e9a6-456c-b0cd-77bd5331ce26",
   "metadata": {},
   "source": [
    "Click this button to run in Colab.\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ssuai/deep_learning_from_scratch/blob/master/ch06/overfit_dropout.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6992e2e-402e-4f47-8e31-2d9ad25a1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load overfit_dropout.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c761e7-e18b-4cc2-85dc-49c5fde00dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions for Colab\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "if is_colab():\n",
    "    !git clone --filter=blob:none --sparse https://github.com/ssuai/deep_learning_from_scratch.git\n",
    "    %cd deep_learning_from_scratch\n",
    "    !git sparse-checkout set dataset common ch06\n",
    "else:            \n",
    "    import os\n",
    "    import sys\n",
    "    sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96e45cb-66ec-4cdf-8a44-a7e9a8b2305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90788d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3004322605815704\n",
      "=== epoch:1, train acc:0.16, test acc:0.1408 ===\n",
      "train loss:2.306294272354925\n",
      "train loss:2.3185687577122733\n",
      "train loss:2.3050947385943314\n",
      "=== epoch:2, train acc:0.15666666666666668, test acc:0.1409 ===\n",
      "train loss:2.302851074697065\n",
      "train loss:2.3167410784414875\n",
      "train loss:2.280691760297611\n",
      "=== epoch:3, train acc:0.15666666666666668, test acc:0.1415 ===\n",
      "train loss:2.3051096185571747\n",
      "train loss:2.299769720334355\n",
      "train loss:2.312480250688507\n",
      "=== epoch:4, train acc:0.16, test acc:0.1422 ===\n",
      "train loss:2.286592710620197\n",
      "train loss:2.3277768347015386\n",
      "train loss:2.298462956838907\n",
      "=== epoch:5, train acc:0.16333333333333333, test acc:0.1456 ===\n",
      "train loss:2.303077775996325\n",
      "train loss:2.3111394562067478\n",
      "train loss:2.2993012577090703\n",
      "=== epoch:6, train acc:0.17333333333333334, test acc:0.1471 ===\n",
      "train loss:2.290690144799314\n",
      "train loss:2.314820660890656\n",
      "train loss:2.3248671599392865\n",
      "=== epoch:7, train acc:0.17, test acc:0.1481 ===\n",
      "train loss:2.2991716169426883\n",
      "train loss:2.310703939934648\n",
      "train loss:2.3021227088734806\n",
      "=== epoch:8, train acc:0.18, test acc:0.1512 ===\n",
      "train loss:2.2750684186068413\n",
      "train loss:2.2965329832350077\n",
      "train loss:2.3021470681901586\n",
      "=== epoch:9, train acc:0.19, test acc:0.1522 ===\n",
      "train loss:2.28705161570904\n",
      "train loss:2.2870005015472863\n",
      "train loss:2.2934063320192717\n",
      "=== epoch:10, train acc:0.20333333333333334, test acc:0.1534 ===\n",
      "train loss:2.2949171018306003\n",
      "train loss:2.3071850730081467\n",
      "train loss:2.2957678081543946\n",
      "=== epoch:11, train acc:0.19333333333333333, test acc:0.1535 ===\n",
      "train loss:2.3124711697764386\n",
      "train loss:2.2989798328554163\n",
      "train loss:2.2947038224444793\n",
      "=== epoch:12, train acc:0.2, test acc:0.156 ===\n",
      "train loss:2.294996084280649\n",
      "train loss:2.295116735714573\n",
      "train loss:2.283089542221684\n",
      "=== epoch:13, train acc:0.20333333333333334, test acc:0.1562 ===\n",
      "train loss:2.289919487967156\n",
      "train loss:2.2965665205553405\n",
      "train loss:2.2870402810508863\n",
      "=== epoch:14, train acc:0.20666666666666667, test acc:0.1601 ===\n",
      "train loss:2.303023704007769\n",
      "train loss:2.289277843750464\n",
      "train loss:2.287272118195406\n",
      "=== epoch:15, train acc:0.21, test acc:0.1618 ===\n",
      "train loss:2.3006611356094893\n",
      "train loss:2.284111206166517\n",
      "train loss:2.2732345662414644\n",
      "=== epoch:16, train acc:0.20666666666666667, test acc:0.1645 ===\n",
      "train loss:2.2802126299598693\n",
      "train loss:2.280954750987452\n",
      "train loss:2.279833942373633\n",
      "=== epoch:17, train acc:0.21666666666666667, test acc:0.1667 ===\n",
      "train loss:2.292771377606739\n",
      "train loss:2.2838592495166803\n",
      "train loss:2.2750024545214877\n",
      "=== epoch:18, train acc:0.22, test acc:0.1675 ===\n",
      "train loss:2.2668613821930452\n",
      "train loss:2.2796493247134872\n",
      "train loss:2.28405415012641\n",
      "=== epoch:19, train acc:0.21666666666666667, test acc:0.1697 ===\n",
      "train loss:2.2846522806207825\n",
      "train loss:2.2975690219690708\n",
      "train loss:2.274907706776199\n",
      "=== epoch:20, train acc:0.21333333333333335, test acc:0.1714 ===\n",
      "train loss:2.2819788125647666\n",
      "train loss:2.2833519255505927\n",
      "train loss:2.279128637595647\n",
      "=== epoch:21, train acc:0.21333333333333335, test acc:0.1713 ===\n",
      "train loss:2.2734375013131807\n",
      "train loss:2.2686082893113944\n",
      "train loss:2.2624784331897376\n",
      "=== epoch:22, train acc:0.21, test acc:0.1729 ===\n",
      "train loss:2.2776133373967937\n",
      "train loss:2.276989118316765\n",
      "train loss:2.2834792024985244\n",
      "=== epoch:23, train acc:0.20666666666666667, test acc:0.1714 ===\n",
      "train loss:2.2695751520341885\n",
      "train loss:2.273806104223586\n",
      "train loss:2.2732983756017258\n",
      "=== epoch:24, train acc:0.21, test acc:0.1709 ===\n",
      "train loss:2.28127897609326\n",
      "train loss:2.2818865818201437\n",
      "train loss:2.279872869592997\n",
      "=== epoch:25, train acc:0.21, test acc:0.1728 ===\n",
      "train loss:2.2722077839913823\n",
      "train loss:2.2737273016579658\n",
      "train loss:2.261904278946829\n",
      "=== epoch:26, train acc:0.20666666666666667, test acc:0.1738 ===\n",
      "train loss:2.268396172589973\n",
      "train loss:2.2941411253078394\n",
      "train loss:2.280406115874399\n",
      "=== epoch:27, train acc:0.20666666666666667, test acc:0.1752 ===\n",
      "train loss:2.2777682938032977\n",
      "train loss:2.2701926852314265\n",
      "train loss:2.278056904143237\n",
      "=== epoch:28, train acc:0.21333333333333335, test acc:0.1768 ===\n",
      "train loss:2.271128480123661\n",
      "train loss:2.2687170155686176\n",
      "train loss:2.271386952244342\n",
      "=== epoch:29, train acc:0.21, test acc:0.1763 ===\n",
      "train loss:2.279452147132069\n",
      "train loss:2.2717897866296557\n",
      "train loss:2.2649663461045857\n",
      "=== epoch:30, train acc:0.21333333333333335, test acc:0.1793 ===\n",
      "train loss:2.2717726628799664\n",
      "train loss:2.279705219789957\n",
      "train loss:2.2561623450921995\n",
      "=== epoch:31, train acc:0.22333333333333333, test acc:0.1819 ===\n",
      "train loss:2.2423231047671557\n",
      "train loss:2.278528491316266\n",
      "train loss:2.272697140862522\n",
      "=== epoch:32, train acc:0.22333333333333333, test acc:0.1839 ===\n",
      "train loss:2.2646487601547527\n",
      "train loss:2.2576775198472934\n",
      "train loss:2.2808904415909086\n",
      "=== epoch:33, train acc:0.22, test acc:0.183 ===\n",
      "train loss:2.2621075671329347\n",
      "train loss:2.277656709576261\n",
      "train loss:2.280853132556831\n",
      "=== epoch:34, train acc:0.22666666666666666, test acc:0.1825 ===\n",
      "train loss:2.2714290555917405\n",
      "train loss:2.273849616386721\n",
      "train loss:2.2840847273184535\n",
      "=== epoch:35, train acc:0.23, test acc:0.1879 ===\n",
      "train loss:2.272315986008519\n",
      "train loss:2.259230912916023\n",
      "train loss:2.2695519199135568\n",
      "=== epoch:36, train acc:0.23333333333333334, test acc:0.1906 ===\n",
      "train loss:2.257888473246316\n",
      "train loss:2.2621563767263213\n",
      "train loss:2.274405496399181\n",
      "=== epoch:37, train acc:0.22666666666666666, test acc:0.1866 ===\n",
      "train loss:2.271954054508658\n",
      "train loss:2.28205051519626\n",
      "train loss:2.267375658198041\n",
      "=== epoch:38, train acc:0.23666666666666666, test acc:0.1898 ===\n",
      "train loss:2.265683722941206\n",
      "train loss:2.2537801084683453\n",
      "train loss:2.2605503444291855\n",
      "=== epoch:39, train acc:0.24, test acc:0.1905 ===\n",
      "train loss:2.261954150993314\n",
      "train loss:2.2589681929937955\n",
      "train loss:2.268451749450684\n",
      "=== epoch:40, train acc:0.24666666666666667, test acc:0.1941 ===\n",
      "train loss:2.2559899377244257\n",
      "train loss:2.2526257717772027\n",
      "train loss:2.2709853111943348\n",
      "=== epoch:41, train acc:0.24666666666666667, test acc:0.1935 ===\n",
      "train loss:2.251967362692945\n",
      "train loss:2.262357638511203\n",
      "train loss:2.253262847303153\n",
      "=== epoch:42, train acc:0.24333333333333335, test acc:0.1928 ===\n",
      "train loss:2.254792033078536\n",
      "train loss:2.257815963586059\n",
      "train loss:2.258072790052374\n",
      "=== epoch:43, train acc:0.24333333333333335, test acc:0.1934 ===\n",
      "train loss:2.2532366056147692\n",
      "train loss:2.260936520651919\n",
      "train loss:2.256222648735719\n",
      "=== epoch:44, train acc:0.24666666666666667, test acc:0.1936 ===\n",
      "train loss:2.2546912656386797\n",
      "train loss:2.2634440325801912\n",
      "train loss:2.2523348789865896\n",
      "=== epoch:45, train acc:0.23666666666666666, test acc:0.1948 ===\n",
      "train loss:2.254692733698509\n",
      "train loss:2.2558393510102914\n",
      "train loss:2.2647200794987783\n",
      "=== epoch:46, train acc:0.24666666666666667, test acc:0.1964 ===\n",
      "train loss:2.2692453176141147\n",
      "train loss:2.2661495918338503\n",
      "train loss:2.2553661874926485\n",
      "=== epoch:47, train acc:0.25, test acc:0.1973 ===\n",
      "train loss:2.253998004169861\n",
      "train loss:2.249883601155426\n",
      "train loss:2.2370080831512604\n",
      "=== epoch:48, train acc:0.25333333333333335, test acc:0.1958 ===\n",
      "train loss:2.2385557886799763\n",
      "train loss:2.249813420616743\n",
      "train loss:2.238430403895031\n",
      "=== epoch:49, train acc:0.25, test acc:0.1913 ===\n",
      "train loss:2.254979522830414\n",
      "train loss:2.2385218545306858\n",
      "train loss:2.2514979633180583\n",
      "=== epoch:50, train acc:0.23666666666666666, test acc:0.1917 ===\n",
      "train loss:2.2432858683941936\n",
      "train loss:2.2663131785145607\n",
      "train loss:2.2493189276455627\n",
      "=== epoch:51, train acc:0.26, test acc:0.1974 ===\n",
      "train loss:2.25756325501793\n",
      "train loss:2.237093271218294\n",
      "train loss:2.2389311493552455\n",
      "=== epoch:52, train acc:0.25333333333333335, test acc:0.1949 ===\n",
      "train loss:2.2422219271674804\n",
      "train loss:2.243121816184996\n",
      "train loss:2.2568212612591596\n",
      "=== epoch:53, train acc:0.25333333333333335, test acc:0.1923 ===\n",
      "train loss:2.237542690077276\n",
      "train loss:2.2513416367610137\n",
      "train loss:2.264916121879982\n",
      "=== epoch:54, train acc:0.25666666666666665, test acc:0.1961 ===\n",
      "train loss:2.249454107926658\n",
      "train loss:2.2420196751721093\n",
      "train loss:2.2576373395429625\n",
      "=== epoch:55, train acc:0.2633333333333333, test acc:0.1991 ===\n",
      "train loss:2.23839591614025\n",
      "train loss:2.2474879845729587\n",
      "train loss:2.231462210066239\n",
      "=== epoch:56, train acc:0.26, test acc:0.1979 ===\n",
      "train loss:2.2305876472064092\n",
      "train loss:2.225864999724889\n",
      "train loss:2.2580862914383335\n",
      "=== epoch:57, train acc:0.25666666666666665, test acc:0.1947 ===\n",
      "train loss:2.2298967777572694\n",
      "train loss:2.236383162685823\n",
      "train loss:2.2344312615764226\n",
      "=== epoch:58, train acc:0.24666666666666667, test acc:0.1888 ===\n",
      "train loss:2.2617271326583706\n",
      "train loss:2.244147887188147\n",
      "train loss:2.256342094858244\n",
      "=== epoch:59, train acc:0.25333333333333335, test acc:0.1926 ===\n",
      "train loss:2.2309885083545606\n",
      "train loss:2.237074118148143\n",
      "train loss:2.2138756485613382\n",
      "=== epoch:60, train acc:0.25333333333333335, test acc:0.1918 ===\n",
      "train loss:2.2377403942027523\n",
      "train loss:2.228217728167121\n",
      "train loss:2.244088997684922\n",
      "=== epoch:61, train acc:0.24666666666666667, test acc:0.1868 ===\n",
      "train loss:2.2387090956452886\n",
      "train loss:2.2268489128141566\n",
      "train loss:2.24051037758895\n",
      "=== epoch:62, train acc:0.24666666666666667, test acc:0.1889 ===\n",
      "train loss:2.2247747696949776\n",
      "train loss:2.24067444262844\n",
      "train loss:2.221145851410613\n",
      "=== epoch:63, train acc:0.25, test acc:0.1886 ===\n",
      "train loss:2.2302567709578454\n",
      "train loss:2.2222458384933095\n",
      "train loss:2.209845793365316\n",
      "=== epoch:64, train acc:0.24666666666666667, test acc:0.1877 ===\n",
      "train loss:2.2330924775415024\n",
      "train loss:2.2527736541716656\n",
      "train loss:2.2371574246191845\n",
      "=== epoch:65, train acc:0.24, test acc:0.186 ===\n",
      "train loss:2.2322200510732326\n",
      "train loss:2.2429104807163367\n",
      "train loss:2.237362301905189\n",
      "=== epoch:66, train acc:0.23666666666666666, test acc:0.1839 ===\n",
      "train loss:2.228634170201682\n",
      "train loss:2.2295167400937848\n",
      "train loss:2.236967014660581\n",
      "=== epoch:67, train acc:0.24666666666666667, test acc:0.1869 ===\n",
      "train loss:2.2112758073531693\n",
      "train loss:2.235301858929207\n",
      "train loss:2.214666657258658\n",
      "=== epoch:68, train acc:0.24666666666666667, test acc:0.1845 ===\n",
      "train loss:2.236024192077327\n",
      "train loss:2.218429967214435\n",
      "train loss:2.220901349362789\n",
      "=== epoch:69, train acc:0.25666666666666665, test acc:0.1895 ===\n",
      "train loss:2.204964344316905\n",
      "train loss:2.254349095748347\n",
      "train loss:2.2441387607413597\n",
      "=== epoch:70, train acc:0.25666666666666665, test acc:0.1902 ===\n",
      "train loss:2.2346980485136303\n",
      "train loss:2.215624390020607\n",
      "train loss:2.237600187639277\n",
      "=== epoch:71, train acc:0.26, test acc:0.1912 ===\n",
      "train loss:2.2289923608347864\n",
      "train loss:2.2003336086565475\n",
      "train loss:2.225604766887078\n",
      "=== epoch:72, train acc:0.25666666666666665, test acc:0.1905 ===\n",
      "train loss:2.2160383338237906\n",
      "train loss:2.227551350347082\n",
      "train loss:2.2379339639894353\n",
      "=== epoch:73, train acc:0.26, test acc:0.1959 ===\n",
      "train loss:2.2238119637878935\n",
      "train loss:2.214392569717335\n",
      "train loss:2.221673099375159\n",
      "=== epoch:74, train acc:0.26, test acc:0.1939 ===\n",
      "train loss:2.2099739126794122\n",
      "train loss:2.2046275561929467\n",
      "train loss:2.2395495008254516\n",
      "=== epoch:75, train acc:0.26, test acc:0.1959 ===\n",
      "train loss:2.2308645739318247\n",
      "train loss:2.227041580680301\n",
      "train loss:2.195665268488265\n",
      "=== epoch:76, train acc:0.25666666666666665, test acc:0.1975 ===\n",
      "train loss:2.205934011774333\n",
      "train loss:2.219951474761984\n",
      "train loss:2.225937549113171\n",
      "=== epoch:77, train acc:0.25666666666666665, test acc:0.1991 ===\n",
      "train loss:2.2149889773254072\n",
      "train loss:2.2130242650319123\n",
      "train loss:2.2118830755978944\n",
      "=== epoch:78, train acc:0.25666666666666665, test acc:0.2004 ===\n",
      "train loss:2.21942633472333\n",
      "train loss:2.227493105747227\n",
      "train loss:2.218682135274693\n",
      "=== epoch:79, train acc:0.25333333333333335, test acc:0.1985 ===\n",
      "train loss:2.225231398112022\n",
      "train loss:2.2361016991377545\n",
      "train loss:2.2051881757485225\n",
      "=== epoch:80, train acc:0.25333333333333335, test acc:0.2001 ===\n",
      "train loss:2.2050544053702628\n",
      "train loss:2.173512693259096\n",
      "train loss:2.2085701831321716\n",
      "=== epoch:81, train acc:0.25666666666666665, test acc:0.2 ===\n",
      "train loss:2.1913823763757296\n",
      "train loss:2.232910599632477\n",
      "train loss:2.212131538418697\n",
      "=== epoch:82, train acc:0.25666666666666665, test acc:0.203 ===\n",
      "train loss:2.2049239901091404\n",
      "train loss:2.2155418995157383\n",
      "train loss:2.2131164617248413\n",
      "=== epoch:83, train acc:0.25, test acc:0.2025 ===\n",
      "train loss:2.2403031618852314\n",
      "train loss:2.199386875752182\n",
      "train loss:2.1969712320898362\n",
      "=== epoch:84, train acc:0.25, test acc:0.2037 ===\n",
      "train loss:2.202000834966112\n",
      "train loss:2.2153679206843453\n",
      "train loss:2.2074332688453344\n",
      "=== epoch:85, train acc:0.25333333333333335, test acc:0.2042 ===\n",
      "train loss:2.1974897849946333\n",
      "train loss:2.1877834052759426\n",
      "train loss:2.2147695329240364\n",
      "=== epoch:86, train acc:0.24666666666666667, test acc:0.2047 ===\n",
      "train loss:2.224388208834718\n",
      "train loss:2.1996982138828054\n",
      "train loss:2.1964043802777353\n",
      "=== epoch:87, train acc:0.26, test acc:0.2084 ===\n",
      "train loss:2.1905592555141227\n",
      "train loss:2.179534929220604\n",
      "train loss:2.1900683310339777\n",
      "=== epoch:88, train acc:0.2633333333333333, test acc:0.2095 ===\n",
      "train loss:2.206762134750815\n",
      "train loss:2.1951809571887573\n",
      "train loss:2.180716131481163\n",
      "=== epoch:89, train acc:0.2633333333333333, test acc:0.2103 ===\n",
      "train loss:2.145760023162381\n",
      "train loss:2.212103445167589\n",
      "train loss:2.174502775399039\n",
      "=== epoch:90, train acc:0.26, test acc:0.2095 ===\n",
      "train loss:2.1825572700719817\n",
      "train loss:2.1418243226369444\n",
      "train loss:2.209967643406844\n",
      "=== epoch:91, train acc:0.26, test acc:0.2079 ===\n",
      "train loss:2.208533818306178\n",
      "train loss:2.2145679840127017\n",
      "train loss:2.233022686453936\n",
      "=== epoch:92, train acc:0.26, test acc:0.2111 ===\n",
      "train loss:2.1964975065209345\n",
      "train loss:2.178424282061921\n",
      "train loss:2.2085604963799605\n",
      "=== epoch:93, train acc:0.2633333333333333, test acc:0.2101 ===\n",
      "train loss:2.1956760254109167\n",
      "train loss:2.1906912776803806\n",
      "train loss:2.1631493246744737\n",
      "=== epoch:94, train acc:0.2633333333333333, test acc:0.212 ===\n",
      "train loss:2.136580760199598\n",
      "train loss:2.1825953738235935\n",
      "train loss:2.1673291020418692\n",
      "=== epoch:95, train acc:0.26, test acc:0.2117 ===\n",
      "train loss:2.144793969739068\n",
      "train loss:2.186448099442468\n",
      "train loss:2.2546600210753325\n",
      "=== epoch:96, train acc:0.26666666666666666, test acc:0.214 ===\n",
      "train loss:2.2066084259433643\n",
      "train loss:2.172735985934351\n",
      "train loss:2.2049457418482867\n",
      "=== epoch:97, train acc:0.2733333333333333, test acc:0.2185 ===\n",
      "train loss:2.18517979425421\n",
      "train loss:2.164009112682307\n",
      "train loss:2.168716062213321\n",
      "=== epoch:98, train acc:0.27666666666666667, test acc:0.221 ===\n",
      "train loss:2.1933266586893767\n",
      "train loss:2.1862417453489273\n",
      "train loss:2.1386453255114266\n",
      "=== epoch:99, train acc:0.2833333333333333, test acc:0.2224 ===\n",
      "train loss:2.1640233674466343\n",
      "train loss:2.153516396354708\n",
      "train loss:2.1816025339701803\n",
      "=== epoch:100, train acc:0.2833333333333333, test acc:0.2238 ===\n",
      "train loss:2.1884128420800155\n",
      "train loss:2.192483419931624\n",
      "train loss:2.1426534103181463\n",
      "=== epoch:101, train acc:0.28, test acc:0.2248 ===\n",
      "train loss:2.1512374636176634\n",
      "train loss:2.165827707528508\n",
      "train loss:2.167173127474439\n",
      "=== epoch:102, train acc:0.2833333333333333, test acc:0.2265 ===\n",
      "train loss:2.1716548926971977\n",
      "train loss:2.2063141925244922\n",
      "train loss:2.1713154284318574\n",
      "=== epoch:103, train acc:0.2966666666666667, test acc:0.2306 ===\n",
      "train loss:2.165207867957007\n",
      "train loss:2.189622980852476\n",
      "train loss:2.1859764652969087\n",
      "=== epoch:104, train acc:0.30666666666666664, test acc:0.236 ===\n",
      "train loss:2.1276762546529358\n",
      "train loss:2.1853935697345683\n",
      "train loss:2.1815862641907304\n",
      "=== epoch:105, train acc:0.30666666666666664, test acc:0.2364 ===\n",
      "train loss:2.1542827603621246\n",
      "train loss:2.1755846140605204\n",
      "train loss:2.119227139490269\n",
      "=== epoch:106, train acc:0.30666666666666664, test acc:0.2361 ===\n",
      "train loss:2.1609183473911218\n",
      "train loss:2.174090574130907\n",
      "train loss:2.1048772952609864\n",
      "=== epoch:107, train acc:0.30666666666666664, test acc:0.2363 ===\n",
      "train loss:2.1852235566643556\n",
      "train loss:2.1684343360448244\n",
      "train loss:2.1482503593783515\n",
      "=== epoch:108, train acc:0.31666666666666665, test acc:0.239 ===\n",
      "train loss:2.1334665264481534\n",
      "train loss:2.173715762952867\n",
      "train loss:2.159527710129649\n",
      "=== epoch:109, train acc:0.31666666666666665, test acc:0.2423 ===\n",
      "train loss:2.1657863334747662\n",
      "train loss:2.159480413158459\n",
      "train loss:2.1815276755737143\n",
      "=== epoch:110, train acc:0.32666666666666666, test acc:0.2464 ===\n",
      "train loss:2.162356184668428\n",
      "train loss:2.1737449013936625\n",
      "train loss:2.123161771707684\n",
      "=== epoch:111, train acc:0.33, test acc:0.2475 ===\n",
      "train loss:2.1095765781115627\n",
      "train loss:2.150471070313543\n",
      "train loss:2.1201708198311415\n",
      "=== epoch:112, train acc:0.3333333333333333, test acc:0.2487 ===\n",
      "train loss:2.148710359123217\n",
      "train loss:2.169758587994012\n",
      "train loss:2.160814227322835\n",
      "=== epoch:113, train acc:0.3333333333333333, test acc:0.251 ===\n",
      "train loss:2.1232793892613246\n",
      "train loss:2.1484282638658545\n",
      "train loss:2.0986625226622286\n",
      "=== epoch:114, train acc:0.33666666666666667, test acc:0.2519 ===\n",
      "train loss:2.136173459171347\n",
      "train loss:2.1294421485348156\n",
      "train loss:2.07390848327382\n",
      "=== epoch:115, train acc:0.32666666666666666, test acc:0.2518 ===\n",
      "train loss:2.1402108280993075\n",
      "train loss:2.1880398411379165\n",
      "train loss:2.163010182026023\n",
      "=== epoch:116, train acc:0.32666666666666666, test acc:0.2538 ===\n",
      "train loss:2.1275914072102493\n",
      "train loss:2.0720659194527644\n",
      "train loss:2.0402877584322217\n",
      "=== epoch:117, train acc:0.33, test acc:0.2525 ===\n",
      "train loss:2.1530101025499224\n",
      "train loss:2.0788373062552536\n",
      "train loss:2.1433410229698993\n",
      "=== epoch:118, train acc:0.3333333333333333, test acc:0.2545 ===\n",
      "train loss:2.084010057693514\n",
      "train loss:2.157550132317732\n",
      "train loss:2.1383861940539917\n",
      "=== epoch:119, train acc:0.34, test acc:0.2539 ===\n",
      "train loss:2.1915855175644414\n",
      "train loss:2.1006177602295466\n",
      "train loss:2.200101442179808\n",
      "=== epoch:120, train acc:0.3466666666666667, test acc:0.2598 ===\n",
      "train loss:2.086909323265863\n",
      "train loss:2.1016420337400628\n",
      "train loss:2.1126414740516064\n",
      "=== epoch:121, train acc:0.3466666666666667, test acc:0.2595 ===\n",
      "train loss:2.0880920535571477\n",
      "train loss:2.1388239697605793\n",
      "train loss:2.075833214052705\n",
      "=== epoch:122, train acc:0.3433333333333333, test acc:0.2609 ===\n",
      "train loss:2.1324797010071115\n",
      "train loss:2.1587052609219763\n",
      "train loss:2.0806400049713787\n",
      "=== epoch:123, train acc:0.3566666666666667, test acc:0.2644 ===\n",
      "train loss:2.0932864244528897\n",
      "train loss:2.1059171455712904\n",
      "train loss:2.097885178559203\n",
      "=== epoch:124, train acc:0.37, test acc:0.2661 ===\n",
      "train loss:2.1319302409422454\n",
      "train loss:2.0642137281620547\n",
      "train loss:2.0981345905874975\n",
      "=== epoch:125, train acc:0.37333333333333335, test acc:0.2693 ===\n",
      "train loss:2.0202834621104238\n",
      "train loss:2.0318287447342334\n",
      "train loss:2.1034174913588135\n",
      "=== epoch:126, train acc:0.37, test acc:0.2652 ===\n",
      "train loss:2.068012736345984\n",
      "train loss:2.098266841775004\n",
      "train loss:2.0850872326409005\n",
      "=== epoch:127, train acc:0.36, test acc:0.2643 ===\n",
      "train loss:2.0582040966316613\n",
      "train loss:2.0973075811423256\n",
      "train loss:2.116618606715576\n",
      "=== epoch:128, train acc:0.36333333333333334, test acc:0.2642 ===\n",
      "train loss:2.0718372653889277\n",
      "train loss:2.0527494920048905\n",
      "train loss:2.1050644526286324\n",
      "=== epoch:129, train acc:0.36333333333333334, test acc:0.267 ===\n",
      "train loss:2.106783594714809\n",
      "train loss:2.1209014229631453\n",
      "train loss:2.1002158759426144\n",
      "=== epoch:130, train acc:0.36666666666666664, test acc:0.271 ===\n",
      "train loss:2.0604069323541117\n",
      "train loss:2.051754845979536\n",
      "train loss:2.0515610325046194\n",
      "=== epoch:131, train acc:0.37666666666666665, test acc:0.2714 ===\n",
      "train loss:2.052572950020429\n",
      "train loss:2.0648144798473878\n",
      "train loss:2.0771677351739575\n",
      "=== epoch:132, train acc:0.37666666666666665, test acc:0.2745 ===\n",
      "train loss:1.9918667863040824\n",
      "train loss:2.0854572289990494\n",
      "train loss:2.0628348499624307\n",
      "=== epoch:133, train acc:0.37666666666666665, test acc:0.2776 ===\n",
      "train loss:2.0731669089006144\n",
      "train loss:2.0280297468355766\n",
      "train loss:2.0764853387374123\n",
      "=== epoch:134, train acc:0.3933333333333333, test acc:0.2829 ===\n",
      "train loss:2.1094135153842983\n",
      "train loss:2.0793360475403015\n",
      "train loss:2.0349582089254987\n",
      "=== epoch:135, train acc:0.39, test acc:0.2833 ===\n",
      "train loss:2.040964975911483\n",
      "train loss:2.0602315361600567\n",
      "train loss:2.0702575711498676\n",
      "=== epoch:136, train acc:0.3933333333333333, test acc:0.2874 ===\n",
      "train loss:2.032277957650205\n",
      "train loss:2.1019582494486024\n",
      "train loss:2.039065262140499\n",
      "=== epoch:137, train acc:0.3933333333333333, test acc:0.289 ===\n",
      "train loss:2.0240595744101553\n",
      "train loss:2.0335745801093412\n",
      "train loss:1.936660583355136\n",
      "=== epoch:138, train acc:0.39666666666666667, test acc:0.2893 ===\n",
      "train loss:2.0369204821453533\n",
      "train loss:2.0433764111666113\n",
      "train loss:2.019506242585821\n",
      "=== epoch:139, train acc:0.3933333333333333, test acc:0.2919 ===\n",
      "train loss:2.0668242150132228\n",
      "train loss:2.0781840681728294\n",
      "train loss:2.0371923329764967\n",
      "=== epoch:140, train acc:0.4, test acc:0.2955 ===\n",
      "train loss:2.0335942285485253\n",
      "train loss:2.0630740314004723\n",
      "train loss:2.058051432315632\n",
      "=== epoch:141, train acc:0.4066666666666667, test acc:0.2976 ===\n",
      "train loss:2.0061271804278498\n",
      "train loss:1.98344580828089\n",
      "train loss:2.0612177794353714\n",
      "=== epoch:142, train acc:0.4, test acc:0.2949 ===\n",
      "train loss:2.0145476125078714\n",
      "train loss:1.9841491593221365\n",
      "train loss:2.024195112018703\n",
      "=== epoch:143, train acc:0.4, test acc:0.2947 ===\n",
      "train loss:1.978839731786579\n",
      "train loss:1.9874675200208602\n",
      "train loss:1.956066383117723\n",
      "=== epoch:144, train acc:0.4, test acc:0.2917 ===\n",
      "train loss:2.012819190519785\n",
      "train loss:2.026985996563357\n",
      "train loss:2.033640612420903\n",
      "=== epoch:145, train acc:0.3933333333333333, test acc:0.2902 ===\n",
      "train loss:2.025647845196847\n",
      "train loss:1.965970696130784\n",
      "train loss:2.00092062504431\n",
      "=== epoch:146, train acc:0.41, test acc:0.2961 ===\n",
      "train loss:2.028468819016076\n",
      "train loss:2.0132039101576567\n",
      "train loss:2.003391365593087\n",
      "=== epoch:147, train acc:0.4, test acc:0.2965 ===\n",
      "train loss:1.9962175470255372\n",
      "train loss:1.935728512332612\n",
      "train loss:2.015197213081422\n",
      "=== epoch:148, train acc:0.4033333333333333, test acc:0.2954 ===\n",
      "train loss:2.0385834588444505\n",
      "train loss:1.9817879521726192\n",
      "train loss:1.9692788083507173\n",
      "=== epoch:149, train acc:0.4066666666666667, test acc:0.2973 ===\n",
      "train loss:2.022426828844843\n",
      "train loss:2.0306519687583355\n",
      "train loss:1.9700865931968066\n",
      "=== epoch:150, train acc:0.41, test acc:0.3002 ===\n",
      "train loss:2.017232655611468\n",
      "train loss:1.9827260188219489\n",
      "train loss:2.058256412545696\n",
      "=== epoch:151, train acc:0.4066666666666667, test acc:0.3019 ===\n",
      "train loss:2.033314952761182\n",
      "train loss:2.0163848749912865\n",
      "train loss:1.87205186534147\n",
      "=== epoch:152, train acc:0.41333333333333333, test acc:0.3026 ===\n",
      "train loss:1.8683831974701763\n",
      "train loss:2.0691279140560725\n",
      "train loss:1.9766631663858747\n",
      "=== epoch:153, train acc:0.4166666666666667, test acc:0.3052 ===\n",
      "train loss:2.0105024687456927\n",
      "train loss:1.9629415857373218\n",
      "train loss:2.0044238089268553\n",
      "=== epoch:154, train acc:0.42333333333333334, test acc:0.3076 ===\n",
      "train loss:1.8439274043687996\n",
      "train loss:1.9497652502368794\n",
      "train loss:2.0164524551247673\n",
      "=== epoch:155, train acc:0.42, test acc:0.3116 ===\n",
      "train loss:1.952926470817362\n",
      "train loss:1.934895334042275\n",
      "train loss:1.9913917746305654\n",
      "=== epoch:156, train acc:0.41333333333333333, test acc:0.3127 ===\n",
      "train loss:1.9807493193775227\n",
      "train loss:1.954575985571157\n",
      "train loss:2.0198109900305923\n",
      "=== epoch:157, train acc:0.41333333333333333, test acc:0.3167 ===\n",
      "train loss:1.9598008911931513\n",
      "train loss:2.0545948757454267\n",
      "train loss:1.9462804325127843\n",
      "=== epoch:158, train acc:0.4166666666666667, test acc:0.3141 ===\n",
      "train loss:1.9802271395371602\n",
      "train loss:2.006982276147389\n",
      "train loss:1.9855427349203176\n",
      "=== epoch:159, train acc:0.42, test acc:0.3128 ===\n",
      "train loss:1.8705657509276299\n",
      "train loss:2.006499980992024\n",
      "train loss:1.9078744246691088\n",
      "=== epoch:160, train acc:0.42, test acc:0.3167 ===\n",
      "train loss:1.8698638382962531\n",
      "train loss:1.937897244344482\n",
      "train loss:1.9531544716494023\n",
      "=== epoch:161, train acc:0.4266666666666667, test acc:0.3166 ===\n",
      "train loss:1.9927887197755803\n",
      "train loss:2.0198145667655454\n",
      "train loss:1.9802648300152728\n",
      "=== epoch:162, train acc:0.4266666666666667, test acc:0.3164 ===\n",
      "train loss:2.007784015397544\n",
      "train loss:1.893755124156989\n",
      "train loss:1.9935344213284967\n",
      "=== epoch:163, train acc:0.43, test acc:0.3198 ===\n",
      "train loss:1.966401594018918\n",
      "train loss:1.9106708342316754\n",
      "train loss:1.9071272505619172\n",
      "=== epoch:164, train acc:0.43, test acc:0.3194 ===\n",
      "train loss:1.8535180141758385\n",
      "train loss:1.9352280356039488\n",
      "train loss:1.8673863653146092\n",
      "=== epoch:165, train acc:0.43666666666666665, test acc:0.318 ===\n",
      "train loss:1.8868447730547455\n",
      "train loss:1.8408491664211422\n",
      "train loss:1.8889198517856913\n",
      "=== epoch:166, train acc:0.43, test acc:0.3132 ===\n",
      "train loss:1.9666668743394586\n",
      "train loss:1.9717850109235853\n",
      "train loss:1.842900020308149\n",
      "=== epoch:167, train acc:0.44, test acc:0.3196 ===\n",
      "train loss:1.8820749474629195\n",
      "train loss:2.02363982350884\n",
      "train loss:1.9621493981418214\n",
      "=== epoch:168, train acc:0.45, test acc:0.325 ===\n",
      "train loss:1.8553838977656727\n",
      "train loss:1.9925589911015669\n",
      "train loss:1.9328513140485368\n",
      "=== epoch:169, train acc:0.4533333333333333, test acc:0.3261 ===\n",
      "train loss:1.9038786193692194\n",
      "train loss:1.9077561285649685\n",
      "train loss:1.9173209414789685\n",
      "=== epoch:170, train acc:0.4533333333333333, test acc:0.3311 ===\n",
      "train loss:1.8784287225024061\n",
      "train loss:1.861413876856068\n",
      "train loss:1.997939162772857\n",
      "=== epoch:171, train acc:0.4666666666666667, test acc:0.3346 ===\n",
      "train loss:1.9865650316877366\n",
      "train loss:1.9299344329994903\n",
      "train loss:1.8936034176526197\n",
      "=== epoch:172, train acc:0.47333333333333333, test acc:0.3363 ===\n",
      "train loss:1.926741409979005\n",
      "train loss:1.8686844831365186\n",
      "train loss:1.9012598022558966\n",
      "=== epoch:173, train acc:0.47, test acc:0.3354 ===\n",
      "train loss:1.9735899984803604\n",
      "train loss:1.8655241319551419\n",
      "train loss:1.8893853740370026\n",
      "=== epoch:174, train acc:0.47333333333333333, test acc:0.3373 ===\n",
      "train loss:1.9009174644769928\n",
      "train loss:1.8123133181664135\n",
      "train loss:1.9209411639997989\n",
      "=== epoch:175, train acc:0.48, test acc:0.342 ===\n",
      "train loss:1.9034205779082176\n",
      "train loss:1.9227619940281384\n",
      "train loss:1.8825102666433995\n",
      "=== epoch:176, train acc:0.4866666666666667, test acc:0.3477 ===\n",
      "train loss:1.8877539086303843\n",
      "train loss:1.874298763026883\n",
      "train loss:1.7973637141109982\n",
      "=== epoch:177, train acc:0.4866666666666667, test acc:0.3504 ===\n",
      "train loss:1.7908303965846875\n",
      "train loss:1.8976660558051583\n",
      "train loss:1.9692464558364506\n",
      "=== epoch:178, train acc:0.48333333333333334, test acc:0.3451 ===\n",
      "train loss:1.7828614102552054\n",
      "train loss:1.9521500350709382\n",
      "train loss:1.820981756800706\n",
      "=== epoch:179, train acc:0.48, test acc:0.3444 ===\n",
      "train loss:1.774829494443579\n",
      "train loss:1.8513469049774287\n",
      "train loss:1.9292505013804462\n",
      "=== epoch:180, train acc:0.48333333333333334, test acc:0.3512 ===\n",
      "train loss:1.9695953136639794\n",
      "train loss:1.854177564941326\n",
      "train loss:1.918614924727268\n",
      "=== epoch:181, train acc:0.49333333333333335, test acc:0.3565 ===\n",
      "train loss:1.8724176864134816\n",
      "train loss:1.8730344711229767\n",
      "train loss:1.8393463482430967\n",
      "=== epoch:182, train acc:0.49666666666666665, test acc:0.3606 ===\n",
      "train loss:1.8637505181363208\n",
      "train loss:1.8811284035837827\n",
      "train loss:1.907836198135998\n",
      "=== epoch:183, train acc:0.49666666666666665, test acc:0.3617 ===\n",
      "train loss:1.8329705690282356\n",
      "train loss:1.7813469985083428\n",
      "train loss:1.8265560505321534\n",
      "=== epoch:184, train acc:0.49333333333333335, test acc:0.3606 ===\n",
      "train loss:1.890106416138327\n",
      "train loss:1.9138734118158234\n",
      "train loss:1.7477999769021924\n",
      "=== epoch:185, train acc:0.4866666666666667, test acc:0.3555 ===\n",
      "train loss:1.7920377530695475\n",
      "train loss:1.877162349656204\n",
      "train loss:1.8924636890071826\n",
      "=== epoch:186, train acc:0.49, test acc:0.3577 ===\n",
      "train loss:1.841019886502619\n",
      "train loss:1.8642995888531146\n",
      "train loss:1.8688493797381054\n",
      "=== epoch:187, train acc:0.49333333333333335, test acc:0.3647 ===\n",
      "train loss:1.8590866858071713\n",
      "train loss:1.887918161254919\n",
      "train loss:1.9081160748322226\n",
      "=== epoch:188, train acc:0.5, test acc:0.3662 ===\n",
      "train loss:1.8799341025092804\n",
      "train loss:1.7743399290774853\n",
      "train loss:1.8524584435516531\n",
      "=== epoch:189, train acc:0.5066666666666667, test acc:0.3705 ===\n",
      "train loss:1.7972434871806293\n",
      "train loss:1.6988803011405202\n",
      "train loss:1.903731880864461\n",
      "=== epoch:190, train acc:0.5166666666666667, test acc:0.3766 ===\n",
      "train loss:1.8797192083604997\n",
      "train loss:1.7354981811947119\n",
      "train loss:1.8744292877241013\n",
      "=== epoch:191, train acc:0.52, test acc:0.3783 ===\n",
      "train loss:1.780502173793178\n",
      "train loss:1.746271404441237\n",
      "train loss:1.7809109211835925\n",
      "=== epoch:192, train acc:0.5166666666666667, test acc:0.3797 ===\n",
      "train loss:1.7696588399555853\n",
      "train loss:1.7930532556207255\n",
      "train loss:1.8457411518383728\n",
      "=== epoch:193, train acc:0.52, test acc:0.3804 ===\n",
      "train loss:1.86493623429005\n",
      "train loss:1.7924180602199309\n",
      "train loss:1.8867654588189218\n",
      "=== epoch:194, train acc:0.51, test acc:0.377 ===\n",
      "train loss:1.6633573959894452\n",
      "train loss:1.7825208689496608\n",
      "train loss:1.8286858086652333\n",
      "=== epoch:195, train acc:0.5133333333333333, test acc:0.3812 ===\n",
      "train loss:1.8071111824840365\n",
      "train loss:1.9099720842148964\n",
      "train loss:1.7901749468637573\n",
      "=== epoch:196, train acc:0.5233333333333333, test acc:0.3834 ===\n",
      "train loss:1.7807573641349266\n",
      "train loss:1.8105862250697795\n",
      "train loss:1.865717822946651\n",
      "=== epoch:197, train acc:0.52, test acc:0.3825 ===\n",
      "train loss:1.8539046576481975\n",
      "train loss:1.8942827548821297\n",
      "train loss:1.8219788592252606\n",
      "=== epoch:198, train acc:0.5266666666666666, test acc:0.38 ===\n",
      "train loss:1.6446365515808734\n",
      "train loss:1.8080679389592431\n",
      "train loss:1.7424476075120696\n",
      "=== epoch:199, train acc:0.53, test acc:0.3882 ===\n",
      "train loss:1.8178318026312967\n",
      "train loss:1.82938964367646\n",
      "train loss:1.809944563639896\n",
      "=== epoch:200, train acc:0.53, test acc:0.3951 ===\n",
      "train loss:1.9513165186552879\n",
      "train loss:1.8518764860135257\n",
      "train loss:1.8000084857844607\n",
      "=== epoch:201, train acc:0.5433333333333333, test acc:0.4033 ===\n",
      "train loss:1.800613901375038\n",
      "train loss:1.7602830021536309\n",
      "train loss:1.7807105904243878\n",
      "=== epoch:202, train acc:0.5533333333333333, test acc:0.4071 ===\n",
      "train loss:1.9151223858150244\n",
      "train loss:1.6738019387531884\n",
      "train loss:1.8828780019354914\n",
      "=== epoch:203, train acc:0.56, test acc:0.4137 ===\n",
      "train loss:1.8487139466091822\n",
      "train loss:1.7152306296953188\n",
      "train loss:1.7296690902358076\n",
      "=== epoch:204, train acc:0.5566666666666666, test acc:0.4176 ===\n",
      "train loss:1.6809226779074258\n",
      "train loss:1.7645260609398594\n",
      "train loss:1.8000732697466284\n",
      "=== epoch:205, train acc:0.5566666666666666, test acc:0.4191 ===\n",
      "train loss:1.71367226433898\n",
      "train loss:1.7610556536486823\n",
      "train loss:1.7692980328936028\n",
      "=== epoch:206, train acc:0.5633333333333334, test acc:0.4223 ===\n",
      "train loss:1.7726175413687864\n",
      "train loss:1.7044063285639794\n",
      "train loss:1.8156747497605286\n",
      "=== epoch:207, train acc:0.5633333333333334, test acc:0.4279 ===\n",
      "train loss:1.7076961338398895\n",
      "train loss:1.7569895629122882\n",
      "train loss:1.6564371324293434\n",
      "=== epoch:208, train acc:0.56, test acc:0.4212 ===\n",
      "train loss:1.7610845227836298\n",
      "train loss:1.6878843250255582\n",
      "train loss:1.8161591325642166\n",
      "=== epoch:209, train acc:0.5666666666666667, test acc:0.4229 ===\n",
      "train loss:1.7972610658959263\n",
      "train loss:1.756950923037742\n",
      "train loss:1.805678129829015\n",
      "=== epoch:210, train acc:0.57, test acc:0.422 ===\n",
      "train loss:1.797489451430801\n",
      "train loss:1.7479424344959877\n",
      "train loss:1.7866322310254927\n",
      "=== epoch:211, train acc:0.5766666666666667, test acc:0.4262 ===\n",
      "train loss:1.7621343960155746\n",
      "train loss:1.6882426504334234\n",
      "train loss:1.6526651648177062\n",
      "=== epoch:212, train acc:0.5766666666666667, test acc:0.4309 ===\n",
      "train loss:1.7371472961115262\n",
      "train loss:1.6702972545375343\n",
      "train loss:1.7798861662903733\n",
      "=== epoch:213, train acc:0.57, test acc:0.4414 ===\n",
      "train loss:1.6518358389691639\n",
      "train loss:1.6508075666901711\n",
      "train loss:1.6568811574605318\n",
      "=== epoch:214, train acc:0.5666666666666667, test acc:0.4432 ===\n",
      "train loss:1.6655896227575624\n",
      "train loss:1.6857743793346984\n",
      "train loss:1.6583806279838553\n",
      "=== epoch:215, train acc:0.5733333333333334, test acc:0.4435 ===\n",
      "train loss:1.588020808396668\n",
      "train loss:1.6522343455785908\n",
      "train loss:1.7887114546582479\n",
      "=== epoch:216, train acc:0.5733333333333334, test acc:0.4456 ===\n",
      "train loss:1.634311983969019\n",
      "train loss:1.64927858680471\n",
      "train loss:1.6277893636727987\n",
      "=== epoch:217, train acc:0.5633333333333334, test acc:0.441 ===\n",
      "train loss:1.5169350398713195\n",
      "train loss:1.563311884882998\n",
      "train loss:1.7774180254086205\n",
      "=== epoch:218, train acc:0.57, test acc:0.4419 ===\n",
      "train loss:1.741346285973749\n",
      "train loss:1.668040440487359\n",
      "train loss:1.6769272780783533\n",
      "=== epoch:219, train acc:0.57, test acc:0.4488 ===\n",
      "train loss:1.598012784688211\n",
      "train loss:1.6537103363465804\n",
      "train loss:1.704362024993827\n",
      "=== epoch:220, train acc:0.5766666666666667, test acc:0.4483 ===\n",
      "train loss:1.6976383230432748\n",
      "train loss:1.6462887860562339\n",
      "train loss:1.6109581547617458\n",
      "=== epoch:221, train acc:0.5733333333333334, test acc:0.4425 ===\n",
      "train loss:1.598164383878664\n",
      "train loss:1.5557857921397136\n",
      "train loss:1.6417847317905054\n",
      "=== epoch:222, train acc:0.5733333333333334, test acc:0.4402 ===\n",
      "train loss:1.7674079645654244\n",
      "train loss:1.6977080280807553\n",
      "train loss:1.6564791846809788\n",
      "=== epoch:223, train acc:0.5766666666666667, test acc:0.4435 ===\n",
      "train loss:1.684059388848836\n",
      "train loss:1.5730102228308354\n",
      "train loss:1.6855743555953506\n",
      "=== epoch:224, train acc:0.5766666666666667, test acc:0.4412 ===\n",
      "train loss:1.6468470132447706\n",
      "train loss:1.6808980744203776\n",
      "train loss:1.6784530186482454\n",
      "=== epoch:225, train acc:0.5766666666666667, test acc:0.4471 ===\n",
      "train loss:1.543523282867815\n",
      "train loss:1.6391086204931486\n",
      "train loss:1.6243888875504775\n",
      "=== epoch:226, train acc:0.58, test acc:0.4413 ===\n",
      "train loss:1.7383284508250845\n",
      "train loss:1.5656833756821147\n",
      "train loss:1.6069547892315301\n",
      "=== epoch:227, train acc:0.58, test acc:0.4513 ===\n",
      "train loss:1.6676150036088273\n",
      "train loss:1.6110154594567963\n",
      "train loss:1.6648654497103457\n",
      "=== epoch:228, train acc:0.5766666666666667, test acc:0.4545 ===\n",
      "train loss:1.5858325936302757\n",
      "train loss:1.6369296944735796\n",
      "train loss:1.5848825616938391\n",
      "=== epoch:229, train acc:0.5833333333333334, test acc:0.4538 ===\n",
      "train loss:1.648209480052544\n",
      "train loss:1.629061092296562\n",
      "train loss:1.6224678117887592\n",
      "=== epoch:230, train acc:0.5966666666666667, test acc:0.4536 ===\n",
      "train loss:1.573628574998985\n",
      "train loss:1.6314057147571832\n",
      "train loss:1.6194328828760973\n",
      "=== epoch:231, train acc:0.5933333333333334, test acc:0.4582 ===\n",
      "train loss:1.620306722670666\n",
      "train loss:1.5869996361492342\n",
      "train loss:1.5656572906797004\n",
      "=== epoch:232, train acc:0.5933333333333334, test acc:0.4593 ===\n",
      "train loss:1.6275887533035467\n",
      "train loss:1.586113250855762\n",
      "train loss:1.6394445388149748\n",
      "=== epoch:233, train acc:0.59, test acc:0.4583 ===\n",
      "train loss:1.5028037961502039\n",
      "train loss:1.5104864960409328\n",
      "train loss:1.7199452670014728\n",
      "=== epoch:234, train acc:0.5866666666666667, test acc:0.4623 ===\n",
      "train loss:1.6638510045512362\n",
      "train loss:1.567093738469024\n",
      "train loss:1.6485034294828245\n",
      "=== epoch:235, train acc:0.5866666666666667, test acc:0.4583 ===\n",
      "train loss:1.5900618208990187\n",
      "train loss:1.6436942592224093\n",
      "train loss:1.6367853476497516\n",
      "=== epoch:236, train acc:0.5933333333333334, test acc:0.4589 ===\n",
      "train loss:1.5211914882880913\n",
      "train loss:1.6629434792481976\n",
      "train loss:1.5270310187259601\n",
      "=== epoch:237, train acc:0.6066666666666667, test acc:0.46 ===\n",
      "train loss:1.525350187251077\n",
      "train loss:1.5398100598795503\n",
      "train loss:1.5889937636656464\n",
      "=== epoch:238, train acc:0.6066666666666667, test acc:0.4557 ===\n",
      "train loss:1.4866209885523949\n",
      "train loss:1.4549524098358404\n",
      "train loss:1.6229958996762264\n",
      "=== epoch:239, train acc:0.62, test acc:0.4636 ===\n",
      "train loss:1.6301542866793617\n",
      "train loss:1.4300626249051271\n",
      "train loss:1.5113486043643465\n",
      "=== epoch:240, train acc:0.61, test acc:0.4651 ===\n",
      "train loss:1.5223561378093011\n",
      "train loss:1.6364181564645524\n",
      "train loss:1.5935042272464017\n",
      "=== epoch:241, train acc:0.62, test acc:0.4745 ===\n",
      "train loss:1.4570319709245358\n",
      "train loss:1.6581126460995725\n",
      "train loss:1.5439847531434625\n",
      "=== epoch:242, train acc:0.6166666666666667, test acc:0.4748 ===\n",
      "train loss:1.557286480391799\n",
      "train loss:1.5004288742657568\n",
      "train loss:1.442621725817757\n",
      "=== epoch:243, train acc:0.62, test acc:0.4753 ===\n",
      "train loss:1.4471641806764575\n",
      "train loss:1.662763661161377\n",
      "train loss:1.5040697833640198\n",
      "=== epoch:244, train acc:0.6166666666666667, test acc:0.4828 ===\n",
      "train loss:1.450245397782784\n",
      "train loss:1.4543998236924098\n",
      "train loss:1.564154627028068\n",
      "=== epoch:245, train acc:0.6166666666666667, test acc:0.4853 ===\n",
      "train loss:1.4359129516782698\n",
      "train loss:1.4250935284504491\n",
      "train loss:1.5008671643120304\n",
      "=== epoch:246, train acc:0.6133333333333333, test acc:0.4848 ===\n",
      "train loss:1.4773608520357977\n",
      "train loss:1.466520430805143\n",
      "train loss:1.5026000089743141\n",
      "=== epoch:247, train acc:0.6233333333333333, test acc:0.4855 ===\n",
      "train loss:1.6241953498732378\n",
      "train loss:1.4496925500361504\n",
      "train loss:1.6233812223188082\n",
      "=== epoch:248, train acc:0.63, test acc:0.4891 ===\n",
      "train loss:1.5751715475505117\n",
      "train loss:1.4641459420895955\n",
      "train loss:1.585617732247081\n",
      "=== epoch:249, train acc:0.63, test acc:0.4913 ===\n",
      "train loss:1.5203680976564171\n",
      "train loss:1.6515196432122488\n",
      "train loss:1.5788210147239536\n",
      "=== epoch:250, train acc:0.6266666666666667, test acc:0.4937 ===\n",
      "train loss:1.5764018824933428\n",
      "train loss:1.5641106691777833\n",
      "train loss:1.4030236927900819\n",
      "=== epoch:251, train acc:0.63, test acc:0.4971 ===\n",
      "train loss:1.5838958984029707\n",
      "train loss:1.5683797588035466\n",
      "train loss:1.5058386969103517\n",
      "=== epoch:252, train acc:0.6266666666666667, test acc:0.497 ===\n",
      "train loss:1.4983314815282176\n",
      "train loss:1.4012068854481243\n",
      "train loss:1.5118375859090836\n",
      "=== epoch:253, train acc:0.6266666666666667, test acc:0.4965 ===\n",
      "train loss:1.5057495126403118\n",
      "train loss:1.5275955924568911\n",
      "train loss:1.386025028491916\n",
      "=== epoch:254, train acc:0.63, test acc:0.4991 ===\n",
      "train loss:1.451512496191781\n",
      "train loss:1.4487705873000563\n",
      "train loss:1.537099763086635\n",
      "=== epoch:255, train acc:0.6266666666666667, test acc:0.5002 ===\n",
      "train loss:1.5051709336342278\n",
      "train loss:1.5062301934878832\n",
      "train loss:1.4348950930400721\n",
      "=== epoch:256, train acc:0.6266666666666667, test acc:0.4978 ===\n",
      "train loss:1.389545832803769\n",
      "train loss:1.5558113978280936\n",
      "train loss:1.3760770248445844\n",
      "=== epoch:257, train acc:0.6233333333333333, test acc:0.4991 ===\n",
      "train loss:1.5268653364019082\n",
      "train loss:1.4660402016202496\n",
      "train loss:1.4106457918779924\n",
      "=== epoch:258, train acc:0.6266666666666667, test acc:0.5023 ===\n",
      "train loss:1.5239859557332005\n",
      "train loss:1.5925477110539348\n",
      "train loss:1.349877347296183\n",
      "=== epoch:259, train acc:0.63, test acc:0.4994 ===\n",
      "train loss:1.3864028185209958\n",
      "train loss:1.3807782925209346\n",
      "train loss:1.5617816406641092\n",
      "=== epoch:260, train acc:0.63, test acc:0.4979 ===\n",
      "train loss:1.49394534572343\n",
      "train loss:1.530081870303355\n",
      "train loss:1.409656134832532\n",
      "=== epoch:261, train acc:0.6266666666666667, test acc:0.4997 ===\n",
      "train loss:1.4171612808087364\n",
      "train loss:1.4593644954618004\n",
      "train loss:1.4826780271238003\n",
      "=== epoch:262, train acc:0.6266666666666667, test acc:0.5002 ===\n",
      "train loss:1.344441002758794\n",
      "train loss:1.549068181373322\n",
      "train loss:1.3941518311733363\n",
      "=== epoch:263, train acc:0.6266666666666667, test acc:0.5044 ===\n",
      "train loss:1.489920614279041\n",
      "train loss:1.3906698638079968\n",
      "train loss:1.355319589569716\n",
      "=== epoch:264, train acc:0.6266666666666667, test acc:0.5044 ===\n",
      "train loss:1.405399258134795\n",
      "train loss:1.496437468446866\n",
      "train loss:1.482341908873087\n",
      "=== epoch:265, train acc:0.62, test acc:0.5051 ===\n",
      "train loss:1.3060480815810949\n",
      "train loss:1.3984254110938081\n",
      "train loss:1.3797472439924172\n",
      "=== epoch:266, train acc:0.6233333333333333, test acc:0.506 ===\n",
      "train loss:1.42903836722107\n",
      "train loss:1.4359492949524202\n",
      "train loss:1.3378516146992212\n",
      "=== epoch:267, train acc:0.6333333333333333, test acc:0.5086 ===\n",
      "train loss:1.4865959351373985\n",
      "train loss:1.3614354675465667\n",
      "train loss:1.3935814019547041\n",
      "=== epoch:268, train acc:0.6266666666666667, test acc:0.5007 ===\n",
      "train loss:1.3016907371772612\n",
      "train loss:1.5444843959249281\n",
      "train loss:1.4604700624013407\n",
      "=== epoch:269, train acc:0.6366666666666667, test acc:0.5027 ===\n",
      "train loss:1.3811947078246103\n",
      "train loss:1.3850611820750556\n",
      "train loss:1.3974867011883654\n",
      "=== epoch:270, train acc:0.6366666666666667, test acc:0.5064 ===\n",
      "train loss:1.3854423814443624\n",
      "train loss:1.410237809768833\n",
      "train loss:1.4241408334208976\n",
      "=== epoch:271, train acc:0.64, test acc:0.5091 ===\n",
      "train loss:1.4082787303726036\n",
      "train loss:1.4346938123113409\n",
      "train loss:1.4504464159556683\n",
      "=== epoch:272, train acc:0.64, test acc:0.5125 ===\n",
      "train loss:1.3119971151636785\n",
      "train loss:1.4411437404904346\n",
      "train loss:1.3705884255841372\n",
      "=== epoch:273, train acc:0.6366666666666667, test acc:0.5075 ===\n",
      "train loss:1.3732742546093397\n",
      "train loss:1.334525094426887\n",
      "train loss:1.3340627505285698\n",
      "=== epoch:274, train acc:0.6333333333333333, test acc:0.5079 ===\n",
      "train loss:1.310985621638779\n",
      "train loss:1.5431625624070873\n",
      "train loss:1.4197256621312604\n",
      "=== epoch:275, train acc:0.6366666666666667, test acc:0.5145 ===\n",
      "train loss:1.3019442949562736\n",
      "train loss:1.4142113426323857\n",
      "train loss:1.3013555753637809\n",
      "=== epoch:276, train acc:0.6433333333333333, test acc:0.5185 ===\n",
      "train loss:1.3020379832243116\n",
      "train loss:1.432843513834673\n",
      "train loss:1.314990115399765\n",
      "=== epoch:277, train acc:0.64, test acc:0.5202 ===\n",
      "train loss:1.3379341348279377\n",
      "train loss:1.4112182478180848\n",
      "train loss:1.4259424887951133\n",
      "=== epoch:278, train acc:0.6366666666666667, test acc:0.5224 ===\n",
      "train loss:1.3813538104549266\n",
      "train loss:1.241270852060203\n",
      "train loss:1.2432610029360702\n",
      "=== epoch:279, train acc:0.6366666666666667, test acc:0.5213 ===\n",
      "train loss:1.3262390034133316\n",
      "train loss:1.1351264337469507\n",
      "train loss:1.3380324538839217\n",
      "=== epoch:280, train acc:0.64, test acc:0.5199 ===\n",
      "train loss:1.4076134840735293\n",
      "train loss:1.3330251730566571\n",
      "train loss:1.2847581592799147\n",
      "=== epoch:281, train acc:0.64, test acc:0.5234 ===\n",
      "train loss:1.3879249956944222\n",
      "train loss:1.373160832235726\n",
      "train loss:1.3894219275832023\n",
      "=== epoch:282, train acc:0.6433333333333333, test acc:0.5267 ===\n",
      "train loss:1.3028303851686045\n",
      "train loss:1.3353256165251162\n",
      "train loss:1.28677588076574\n",
      "=== epoch:283, train acc:0.6433333333333333, test acc:0.5277 ===\n",
      "train loss:1.12988373455496\n",
      "train loss:1.3269495363501271\n",
      "train loss:1.1763674694839217\n",
      "=== epoch:284, train acc:0.6466666666666666, test acc:0.5233 ===\n",
      "train loss:1.2347368733220063\n",
      "train loss:1.2125376019870329\n",
      "train loss:1.3789244415255826\n",
      "=== epoch:285, train acc:0.64, test acc:0.5219 ===\n",
      "train loss:1.1845618432160119\n",
      "train loss:1.3477027397159447\n",
      "train loss:1.2429820127665303\n",
      "=== epoch:286, train acc:0.6366666666666667, test acc:0.5183 ===\n",
      "train loss:1.1352318550605092\n",
      "train loss:1.306520698892343\n",
      "train loss:1.175670515928686\n",
      "=== epoch:287, train acc:0.6366666666666667, test acc:0.5231 ===\n",
      "train loss:1.2834858360281416\n",
      "train loss:1.3200164144069897\n",
      "train loss:1.39125002331442\n",
      "=== epoch:288, train acc:0.6433333333333333, test acc:0.531 ===\n",
      "train loss:1.2124070035824486\n",
      "train loss:1.1931254361806838\n",
      "train loss:1.1917018645321196\n",
      "=== epoch:289, train acc:0.6466666666666666, test acc:0.5276 ===\n",
      "train loss:1.1960648918147998\n",
      "train loss:1.3396531935040819\n",
      "train loss:1.4416344613473466\n",
      "=== epoch:290, train acc:0.6533333333333333, test acc:0.5312 ===\n",
      "train loss:1.4347315925076451\n",
      "train loss:1.1716109973829871\n",
      "train loss:1.2738505006049576\n",
      "=== epoch:291, train acc:0.6566666666666666, test acc:0.5383 ===\n",
      "train loss:1.200243580312536\n",
      "train loss:1.3353043048596598\n",
      "train loss:1.175392015809326\n",
      "=== epoch:292, train acc:0.6666666666666666, test acc:0.5451 ===\n",
      "train loss:1.1944890269312602\n",
      "train loss:1.1311513359272167\n",
      "train loss:1.2005808044960862\n",
      "=== epoch:293, train acc:0.6666666666666666, test acc:0.5433 ===\n",
      "train loss:1.2132468939978809\n",
      "train loss:1.061563698447905\n",
      "train loss:1.2203691484489523\n",
      "=== epoch:294, train acc:0.67, test acc:0.5445 ===\n",
      "train loss:1.3056505517085608\n",
      "train loss:1.1628932249748223\n",
      "train loss:1.2164080733691847\n",
      "=== epoch:295, train acc:0.6733333333333333, test acc:0.5481 ===\n",
      "train loss:1.0989854103506218\n",
      "train loss:1.280140975511678\n",
      "train loss:1.2583377824969866\n",
      "=== epoch:296, train acc:0.6666666666666666, test acc:0.5448 ===\n",
      "train loss:1.181118077871788\n",
      "train loss:1.256329725988047\n",
      "train loss:1.0887177095229716\n",
      "=== epoch:297, train acc:0.67, test acc:0.5428 ===\n",
      "train loss:1.0736339998636573\n",
      "train loss:1.2060219886317276\n",
      "train loss:1.3137731867113\n",
      "=== epoch:298, train acc:0.67, test acc:0.5379 ===\n",
      "train loss:1.2876550060330154\n",
      "train loss:1.181664743506746\n",
      "train loss:1.2023255680039748\n",
      "=== epoch:299, train acc:0.67, test acc:0.5363 ===\n",
      "train loss:1.170645522723175\n",
      "train loss:1.185996252067359\n",
      "train loss:1.158560551985263\n",
      "=== epoch:300, train acc:0.6666666666666666, test acc:0.5402 ===\n",
      "train loss:1.191826470732268\n",
      "train loss:1.3590313382129142\n",
      "train loss:1.094173652898088\n",
      "=== epoch:301, train acc:0.6666666666666666, test acc:0.5414 ===\n",
      "train loss:1.0657245608121217\n",
      "train loss:1.0772520964611767\n",
      "train loss:1.1954503134589753\n",
      "=== epoch:302, train acc:0.6666666666666666, test acc:0.5456 ===\n",
      "train loss:1.2337150043283918\n",
      "train loss:1.214054556843392\n",
      "train loss:1.0790437405319753\n",
      "=== epoch:303, train acc:0.68, test acc:0.5465 ===\n",
      "train loss:1.256609726006218\n",
      "train loss:1.1665105020320643\n",
      "train loss:1.1661578198541762\n",
      "=== epoch:304, train acc:0.68, test acc:0.5523 ===\n",
      "train loss:1.298736395466846\n",
      "train loss:1.1395591551646833\n",
      "train loss:1.2061935442565352\n",
      "=== epoch:305, train acc:0.68, test acc:0.5575 ===\n",
      "train loss:1.0456514578038854\n",
      "train loss:1.1698488528540694\n",
      "train loss:1.2346724622290455\n",
      "=== epoch:306, train acc:0.6866666666666666, test acc:0.555 ===\n",
      "train loss:1.046996818975827\n",
      "train loss:1.2464665424456645\n",
      "train loss:1.0748350030773102\n",
      "=== epoch:307, train acc:0.69, test acc:0.5532 ===\n",
      "train loss:1.2501636807794367\n",
      "train loss:1.153305588035868\n",
      "train loss:1.111602595022986\n",
      "=== epoch:308, train acc:0.6866666666666666, test acc:0.5605 ===\n",
      "train loss:1.2101872750804767\n",
      "train loss:1.0493681194868685\n",
      "train loss:1.0891013518922354\n",
      "=== epoch:309, train acc:0.6966666666666667, test acc:0.5573 ===\n",
      "train loss:1.0103569001891142\n",
      "train loss:1.0677287335441727\n",
      "train loss:1.2599344765059244\n",
      "=== epoch:310, train acc:0.6933333333333334, test acc:0.5566 ===\n",
      "train loss:1.1415511744977838\n",
      "train loss:1.1516574823575891\n",
      "train loss:1.2075384554575732\n",
      "=== epoch:311, train acc:0.7, test acc:0.5636 ===\n",
      "train loss:1.109014805337023\n",
      "train loss:1.0929765317659865\n",
      "train loss:0.981863717986254\n",
      "=== epoch:312, train acc:0.6933333333333334, test acc:0.5589 ===\n",
      "train loss:1.0583454558309289\n",
      "train loss:1.0176459291508484\n",
      "train loss:1.057276043940967\n",
      "=== epoch:313, train acc:0.6933333333333334, test acc:0.5602 ===\n",
      "train loss:1.0531153484146143\n",
      "train loss:1.113896773948119\n",
      "train loss:1.154416079595174\n",
      "=== epoch:314, train acc:0.6933333333333334, test acc:0.5618 ===\n",
      "train loss:1.1120999831624394\n",
      "train loss:1.0378217502735714\n",
      "train loss:1.0294560052611885\n",
      "=== epoch:315, train acc:0.6933333333333334, test acc:0.5649 ===\n",
      "train loss:1.1577378402902818\n",
      "train loss:1.0893987553024442\n",
      "train loss:1.1513637681027464\n",
      "=== epoch:316, train acc:0.7033333333333334, test acc:0.567 ===\n",
      "train loss:1.0510851445091633\n",
      "train loss:0.8713477915923349\n",
      "train loss:1.1793923645714495\n",
      "=== epoch:317, train acc:0.6966666666666667, test acc:0.5653 ===\n",
      "train loss:1.0595543032890753\n",
      "train loss:1.1020713275837943\n",
      "train loss:1.0430065161712947\n",
      "=== epoch:318, train acc:0.6966666666666667, test acc:0.5651 ===\n",
      "train loss:1.0994999718188683\n",
      "train loss:1.1055895617332363\n",
      "train loss:1.0306520246199007\n",
      "=== epoch:319, train acc:0.6933333333333334, test acc:0.5675 ===\n",
      "train loss:1.147070298305052\n",
      "train loss:1.1524907010046497\n",
      "train loss:1.032691898867318\n",
      "=== epoch:320, train acc:0.6966666666666667, test acc:0.5721 ===\n",
      "train loss:1.0509431927682646\n",
      "train loss:0.9003305530777446\n",
      "train loss:1.0369241322079767\n",
      "=== epoch:321, train acc:0.71, test acc:0.5688 ===\n",
      "train loss:1.014882206027799\n",
      "train loss:0.8465701788299067\n",
      "train loss:0.977792296192943\n",
      "=== epoch:322, train acc:0.71, test acc:0.5669 ===\n",
      "train loss:1.1489887522855196\n",
      "train loss:1.127982834296278\n",
      "train loss:0.966565426112088\n",
      "=== epoch:323, train acc:0.71, test acc:0.5684 ===\n",
      "train loss:1.0526121181346337\n",
      "train loss:0.96639578016201\n",
      "train loss:1.0092579312892611\n",
      "=== epoch:324, train acc:0.7166666666666667, test acc:0.5687 ===\n",
      "train loss:1.1302583864260587\n",
      "train loss:0.9714233862773232\n",
      "train loss:0.958003035351103\n",
      "=== epoch:325, train acc:0.7133333333333334, test acc:0.5685 ===\n",
      "train loss:1.1056282020304544\n",
      "train loss:1.036633039233016\n",
      "train loss:0.8955077776846402\n",
      "=== epoch:326, train acc:0.71, test acc:0.5726 ===\n",
      "train loss:1.0518452849426365\n",
      "train loss:1.1777655326931433\n",
      "train loss:1.1015529529775734\n",
      "=== epoch:327, train acc:0.7166666666666667, test acc:0.575 ===\n",
      "train loss:1.0119687721387856\n",
      "train loss:1.0787427227651936\n",
      "train loss:0.9846212755581356\n",
      "=== epoch:328, train acc:0.7233333333333334, test acc:0.5755 ===\n",
      "train loss:0.9476008751853034\n",
      "train loss:1.0984140050916404\n",
      "train loss:1.004873680357146\n",
      "=== epoch:329, train acc:0.7233333333333334, test acc:0.5826 ===\n",
      "train loss:1.015427793921565\n",
      "train loss:1.0083759048015477\n",
      "train loss:1.0797846164537515\n",
      "=== epoch:330, train acc:0.7266666666666667, test acc:0.5872 ===\n",
      "train loss:1.007473665055511\n",
      "train loss:0.9894500861221067\n",
      "train loss:0.9769095375239104\n",
      "=== epoch:331, train acc:0.73, test acc:0.5922 ===\n",
      "train loss:1.0365728156827125\n",
      "train loss:1.0063004485398612\n",
      "train loss:0.8848375774304819\n",
      "=== epoch:332, train acc:0.73, test acc:0.5945 ===\n",
      "train loss:0.9681184602227261\n",
      "train loss:0.9142626803984281\n",
      "train loss:0.9934206249725483\n",
      "=== epoch:333, train acc:0.7266666666666667, test acc:0.5943 ===\n",
      "train loss:0.9467889414477285\n",
      "train loss:1.0787067032985997\n",
      "train loss:1.038060844673011\n",
      "=== epoch:334, train acc:0.7366666666666667, test acc:0.5977 ===\n",
      "train loss:1.0084204995197208\n",
      "train loss:1.024228828345853\n",
      "train loss:0.9498046634155779\n",
      "=== epoch:335, train acc:0.74, test acc:0.5963 ===\n",
      "train loss:1.0412872700665192\n",
      "train loss:0.9648538784548557\n",
      "train loss:1.0752575454332598\n",
      "=== epoch:336, train acc:0.74, test acc:0.5971 ===\n",
      "train loss:0.9413354668997322\n",
      "train loss:1.0198401977759006\n",
      "train loss:0.9120001086805261\n",
      "=== epoch:337, train acc:0.7466666666666667, test acc:0.5997 ===\n",
      "train loss:0.8910895118455838\n",
      "train loss:1.0746762280926447\n",
      "train loss:1.0233397835640816\n",
      "=== epoch:338, train acc:0.7433333333333333, test acc:0.5987 ===\n",
      "train loss:0.9140190657662499\n",
      "train loss:0.8739463141389412\n",
      "train loss:0.9768206665149407\n",
      "=== epoch:339, train acc:0.74, test acc:0.6032 ===\n",
      "train loss:0.7769129022576808\n",
      "train loss:0.8382763623367182\n",
      "train loss:0.9203588759869982\n",
      "=== epoch:340, train acc:0.7433333333333333, test acc:0.5987 ===\n",
      "train loss:0.9213753205028707\n",
      "train loss:0.9214059388497787\n",
      "train loss:0.9468081212837146\n",
      "=== epoch:341, train acc:0.7433333333333333, test acc:0.6 ===\n",
      "train loss:0.8921963274169208\n",
      "train loss:0.9745137806467052\n",
      "train loss:1.0288965377758088\n",
      "=== epoch:342, train acc:0.7433333333333333, test acc:0.6015 ===\n",
      "train loss:0.9022802293549331\n",
      "train loss:0.9263890991067395\n",
      "train loss:0.8713926512757563\n",
      "=== epoch:343, train acc:0.7433333333333333, test acc:0.5978 ===\n",
      "train loss:0.7973966199468735\n",
      "train loss:0.8856633452150198\n",
      "train loss:0.9470643741156135\n",
      "=== epoch:344, train acc:0.7366666666666667, test acc:0.6005 ===\n",
      "train loss:0.8555577753469751\n",
      "train loss:0.864966007681166\n",
      "train loss:0.9703471239811274\n",
      "=== epoch:345, train acc:0.74, test acc:0.6055 ===\n",
      "train loss:0.9413631769449775\n",
      "train loss:0.9203985853351034\n",
      "train loss:0.9353043551880689\n",
      "=== epoch:346, train acc:0.7433333333333333, test acc:0.6068 ===\n",
      "train loss:0.9217701786216931\n",
      "train loss:0.8361466421862599\n",
      "train loss:0.9513609105528406\n",
      "=== epoch:347, train acc:0.7466666666666667, test acc:0.6061 ===\n",
      "train loss:1.023631035994922\n",
      "train loss:0.8256751004974991\n",
      "train loss:0.855154831907449\n",
      "=== epoch:348, train acc:0.75, test acc:0.6088 ===\n",
      "train loss:0.9850301395204584\n",
      "train loss:0.878645028411342\n",
      "train loss:0.8354092670496097\n",
      "=== epoch:349, train acc:0.7533333333333333, test acc:0.6113 ===\n",
      "train loss:0.9864512521779012\n",
      "train loss:0.8057477561180976\n",
      "train loss:0.928232439325895\n",
      "=== epoch:350, train acc:0.7533333333333333, test acc:0.61 ===\n",
      "train loss:0.8255312991688659\n",
      "train loss:0.7855953369367772\n",
      "train loss:0.8652949356112251\n",
      "=== epoch:351, train acc:0.75, test acc:0.6116 ===\n",
      "train loss:0.8149199412845618\n",
      "train loss:0.9250483923163338\n",
      "train loss:0.7746201929190129\n",
      "=== epoch:352, train acc:0.75, test acc:0.6111 ===\n",
      "train loss:0.9098253445240622\n",
      "train loss:0.7939786401956033\n",
      "train loss:0.8064521092311542\n",
      "=== epoch:353, train acc:0.7466666666666667, test acc:0.609 ===\n",
      "train loss:0.8994749622800541\n",
      "train loss:0.8059149219230705\n",
      "train loss:0.993799035584058\n",
      "=== epoch:354, train acc:0.7533333333333333, test acc:0.611 ===\n",
      "train loss:1.0441530524128106\n",
      "train loss:1.0260538689392027\n",
      "train loss:0.8744064690471456\n",
      "=== epoch:355, train acc:0.76, test acc:0.6175 ===\n",
      "train loss:0.7990675725332733\n",
      "train loss:0.7614138017576324\n",
      "train loss:0.6880092887955551\n",
      "=== epoch:356, train acc:0.75, test acc:0.6147 ===\n",
      "train loss:0.9485878653881759\n",
      "train loss:0.8572688812027073\n",
      "train loss:0.8501813929088066\n",
      "=== epoch:357, train acc:0.75, test acc:0.6169 ===\n",
      "train loss:0.8322287748804884\n",
      "train loss:0.8507963268669709\n",
      "train loss:0.7964503441059989\n",
      "=== epoch:358, train acc:0.75, test acc:0.6162 ===\n",
      "train loss:0.8531427120112202\n",
      "train loss:0.8440918643694337\n",
      "train loss:0.8571427817703318\n",
      "=== epoch:359, train acc:0.76, test acc:0.6195 ===\n",
      "train loss:0.8584452501105754\n",
      "train loss:0.8857225770003379\n",
      "train loss:0.8553879392121168\n",
      "=== epoch:360, train acc:0.7633333333333333, test acc:0.6232 ===\n",
      "train loss:0.7696562717600431\n",
      "train loss:0.8146682484369799\n",
      "train loss:0.8897026560615836\n",
      "=== epoch:361, train acc:0.76, test acc:0.6217 ===\n",
      "train loss:0.9172625492328075\n",
      "train loss:0.8431649682431093\n",
      "train loss:0.7963614232345616\n",
      "=== epoch:362, train acc:0.77, test acc:0.6227 ===\n",
      "train loss:0.7924463158051195\n",
      "train loss:0.740913528649721\n",
      "train loss:0.6839959214412619\n",
      "=== epoch:363, train acc:0.7666666666666667, test acc:0.6213 ===\n",
      "train loss:0.9202147014355995\n",
      "train loss:0.76145774466419\n",
      "train loss:0.8638868781451747\n",
      "=== epoch:364, train acc:0.7633333333333333, test acc:0.6209 ===\n",
      "train loss:0.9396771679670188\n",
      "train loss:0.7649212853025044\n",
      "train loss:0.8216576698386412\n",
      "=== epoch:365, train acc:0.7633333333333333, test acc:0.6199 ===\n",
      "train loss:0.8555092428143477\n",
      "train loss:0.8486937381969204\n",
      "train loss:0.9400944771107065\n",
      "=== epoch:366, train acc:0.76, test acc:0.6176 ===\n",
      "train loss:0.8026528918865484\n",
      "train loss:0.9330521699657688\n",
      "train loss:0.7364547690294084\n",
      "=== epoch:367, train acc:0.77, test acc:0.6227 ===\n",
      "train loss:0.8471046256457746\n",
      "train loss:0.895505606372836\n",
      "train loss:0.8239493469285378\n",
      "=== epoch:368, train acc:0.7666666666666667, test acc:0.6277 ===\n",
      "train loss:0.7880440015413037\n",
      "train loss:0.7861443107644881\n",
      "train loss:0.8757871009170348\n",
      "=== epoch:369, train acc:0.77, test acc:0.6321 ===\n",
      "train loss:0.8038592616247577\n",
      "train loss:0.7270608257040854\n",
      "train loss:0.7079997398765981\n",
      "=== epoch:370, train acc:0.78, test acc:0.6285 ===\n",
      "train loss:0.8677673112561078\n",
      "train loss:0.816328662381112\n",
      "train loss:0.7893863005463598\n",
      "=== epoch:371, train acc:0.7666666666666667, test acc:0.6269 ===\n",
      "train loss:0.8664053028350053\n",
      "train loss:0.8848840276547262\n",
      "train loss:0.8826746532688107\n",
      "=== epoch:372, train acc:0.7766666666666666, test acc:0.6331 ===\n",
      "train loss:0.9907189141026034\n",
      "train loss:0.770992241654695\n",
      "train loss:0.884712269671752\n",
      "=== epoch:373, train acc:0.7833333333333333, test acc:0.6397 ===\n",
      "train loss:0.7039110284478372\n",
      "train loss:0.8577019475583887\n",
      "train loss:0.7678352465385891\n",
      "=== epoch:374, train acc:0.7833333333333333, test acc:0.6336 ===\n",
      "train loss:0.8064438473348444\n",
      "train loss:0.87838288171492\n",
      "train loss:0.8384825786469244\n",
      "=== epoch:375, train acc:0.7833333333333333, test acc:0.6372 ===\n",
      "train loss:0.8083591848324341\n",
      "train loss:0.7857015575087313\n",
      "train loss:0.8817884562566591\n",
      "=== epoch:376, train acc:0.7833333333333333, test acc:0.6376 ===\n",
      "train loss:0.7711109923113152\n",
      "train loss:0.8079971295685325\n",
      "train loss:0.8945272189747187\n",
      "=== epoch:377, train acc:0.7866666666666666, test acc:0.642 ===\n",
      "train loss:0.928086059197256\n",
      "train loss:0.8491957115577066\n",
      "train loss:0.759820062983463\n",
      "=== epoch:378, train acc:0.7933333333333333, test acc:0.6432 ===\n",
      "train loss:0.6681891836440915\n",
      "train loss:0.6627908770188148\n",
      "train loss:0.7226498518137398\n",
      "=== epoch:379, train acc:0.7866666666666666, test acc:0.6426 ===\n",
      "train loss:0.8561706660053098\n",
      "train loss:0.7926145083839464\n",
      "train loss:0.9107325059318575\n",
      "=== epoch:380, train acc:0.7966666666666666, test acc:0.6487 ===\n",
      "train loss:0.706468489709324\n",
      "train loss:0.7326505199918071\n",
      "train loss:0.792159598372444\n",
      "=== epoch:381, train acc:0.7933333333333333, test acc:0.644 ===\n",
      "train loss:0.7672601287073683\n",
      "train loss:0.7007826450085077\n",
      "train loss:0.6193418170314043\n",
      "=== epoch:382, train acc:0.7866666666666666, test acc:0.6396 ===\n",
      "train loss:0.7216968529318448\n",
      "train loss:0.8037640073421707\n",
      "train loss:0.7200849894193692\n",
      "=== epoch:383, train acc:0.79, test acc:0.6364 ===\n",
      "train loss:0.8673734886589068\n",
      "train loss:0.7540489619772341\n",
      "train loss:0.9761043854854844\n",
      "=== epoch:384, train acc:0.79, test acc:0.6417 ===\n",
      "train loss:0.8307614770452209\n",
      "train loss:0.8420887459177867\n",
      "train loss:0.8017547908526254\n",
      "=== epoch:385, train acc:0.79, test acc:0.6442 ===\n",
      "train loss:0.7830431900032714\n",
      "train loss:0.7335726528022692\n",
      "train loss:0.7542686986696637\n",
      "=== epoch:386, train acc:0.8, test acc:0.6478 ===\n",
      "train loss:0.7639086955018959\n",
      "train loss:0.7841393919439968\n",
      "train loss:0.7071659574539549\n",
      "=== epoch:387, train acc:0.8, test acc:0.6478 ===\n",
      "train loss:0.6105465274895804\n",
      "train loss:0.7986124616020197\n",
      "train loss:0.8695136899828796\n",
      "=== epoch:388, train acc:0.7966666666666666, test acc:0.6445 ===\n",
      "train loss:0.6774579421528832\n",
      "train loss:0.7870288640436237\n",
      "train loss:0.7757967328243176\n",
      "=== epoch:389, train acc:0.8033333333333333, test acc:0.648 ===\n",
      "train loss:0.7197626840488648\n",
      "train loss:0.7061987089145869\n",
      "train loss:0.5753722951172326\n",
      "=== epoch:390, train acc:0.7933333333333333, test acc:0.646 ===\n",
      "train loss:0.693973899538774\n",
      "train loss:0.7810932383453277\n",
      "train loss:0.7538238850114475\n",
      "=== epoch:391, train acc:0.7933333333333333, test acc:0.6462 ===\n",
      "train loss:0.6377617770694737\n",
      "train loss:0.7846269016849529\n",
      "train loss:0.7539213908231497\n",
      "=== epoch:392, train acc:0.7933333333333333, test acc:0.6472 ===\n",
      "train loss:0.7467769226049118\n",
      "train loss:0.7466745672922807\n",
      "train loss:0.8098738271358299\n",
      "=== epoch:393, train acc:0.8, test acc:0.6541 ===\n",
      "train loss:0.7594591352271758\n",
      "train loss:0.735744228303522\n",
      "train loss:0.6703271164401678\n",
      "=== epoch:394, train acc:0.8066666666666666, test acc:0.6538 ===\n",
      "train loss:0.6443308757473128\n",
      "train loss:0.7665720565373966\n",
      "train loss:0.6399550340236414\n",
      "=== epoch:395, train acc:0.8033333333333333, test acc:0.6556 ===\n",
      "train loss:0.6997676189341868\n",
      "train loss:0.7297364116354546\n",
      "train loss:0.7304341594229409\n",
      "=== epoch:396, train acc:0.7966666666666666, test acc:0.6526 ===\n",
      "train loss:0.6765023821648228\n",
      "train loss:0.7355859008477735\n",
      "train loss:0.7443180467426096\n",
      "=== epoch:397, train acc:0.8033333333333333, test acc:0.6533 ===\n",
      "train loss:0.7641085239539791\n",
      "train loss:0.7143373301475962\n",
      "train loss:0.5919810841085926\n",
      "=== epoch:398, train acc:0.8066666666666666, test acc:0.6536 ===\n",
      "train loss:0.6348640413278934\n",
      "train loss:0.7750570681128106\n",
      "train loss:0.6605685017189881\n",
      "=== epoch:399, train acc:0.8033333333333333, test acc:0.6523 ===\n",
      "train loss:0.786671663629482\n",
      "train loss:0.704600076199967\n",
      "train loss:0.6820788137164243\n",
      "=== epoch:400, train acc:0.8066666666666666, test acc:0.6543 ===\n",
      "train loss:0.6512372534373679\n",
      "train loss:0.6453618662034134\n",
      "train loss:0.7025870847118285\n",
      "=== epoch:401, train acc:0.7966666666666666, test acc:0.6519 ===\n",
      "train loss:0.6349937903867626\n",
      "train loss:0.6830393542741566\n",
      "train loss:0.7429329102847817\n",
      "=== epoch:402, train acc:0.7933333333333333, test acc:0.6519 ===\n",
      "train loss:0.49400281777574073\n",
      "train loss:0.7790614431613292\n",
      "train loss:0.6863805974569717\n",
      "=== epoch:403, train acc:0.8033333333333333, test acc:0.6517 ===\n",
      "train loss:0.6743798877317829\n",
      "train loss:0.7318586181597513\n",
      "train loss:0.74890387130892\n",
      "=== epoch:404, train acc:0.8033333333333333, test acc:0.6545 ===\n",
      "train loss:0.6697835078644949\n",
      "train loss:0.6444175718494989\n",
      "train loss:0.6969884345140609\n",
      "=== epoch:405, train acc:0.81, test acc:0.6601 ===\n",
      "train loss:0.5601814914899003\n",
      "train loss:0.637881933391086\n",
      "train loss:0.5854413570982129\n",
      "=== epoch:406, train acc:0.8066666666666666, test acc:0.658 ===\n",
      "train loss:0.7370921933763793\n",
      "train loss:0.7065468456309121\n",
      "train loss:0.6627986557865618\n",
      "=== epoch:407, train acc:0.8066666666666666, test acc:0.6592 ===\n",
      "train loss:0.6071514937067023\n",
      "train loss:0.5917279009755427\n",
      "train loss:0.7053261142574803\n",
      "=== epoch:408, train acc:0.8066666666666666, test acc:0.659 ===\n",
      "train loss:0.6324944226605527\n",
      "train loss:0.680043315630494\n",
      "train loss:0.6335922691592543\n",
      "=== epoch:409, train acc:0.8, test acc:0.6548 ===\n",
      "train loss:0.7677392335539984\n",
      "train loss:0.8574781407681158\n",
      "train loss:0.6969846009863001\n",
      "=== epoch:410, train acc:0.8066666666666666, test acc:0.6561 ===\n",
      "train loss:0.654354668465845\n",
      "train loss:0.6874837587846713\n",
      "train loss:0.5830116208986696\n",
      "=== epoch:411, train acc:0.81, test acc:0.6561 ===\n",
      "train loss:0.7167046742115696\n",
      "train loss:0.7395969257210728\n",
      "train loss:0.6391762783468176\n",
      "=== epoch:412, train acc:0.8033333333333333, test acc:0.6515 ===\n",
      "train loss:0.6611179819543251\n",
      "train loss:0.7338859889852872\n",
      "train loss:0.7575802309604077\n",
      "=== epoch:413, train acc:0.8166666666666667, test acc:0.6609 ===\n",
      "train loss:0.7230592095877121\n",
      "train loss:0.562249942322545\n",
      "train loss:0.6485667560220613\n",
      "=== epoch:414, train acc:0.8166666666666667, test acc:0.6649 ===\n",
      "train loss:0.6833519107925937\n",
      "train loss:0.5591291110441697\n",
      "train loss:0.7066989324986913\n",
      "=== epoch:415, train acc:0.8233333333333334, test acc:0.6621 ===\n",
      "train loss:0.5647954102047329\n",
      "train loss:0.6590108442702737\n",
      "train loss:0.5758222231425554\n",
      "=== epoch:416, train acc:0.82, test acc:0.6581 ===\n",
      "train loss:0.5864401979491515\n",
      "train loss:0.6953352404592195\n",
      "train loss:0.6733360639070414\n",
      "=== epoch:417, train acc:0.8233333333333334, test acc:0.6633 ===\n",
      "train loss:0.6089935431854978\n",
      "train loss:0.6049591420403396\n",
      "train loss:0.730772710277222\n",
      "=== epoch:418, train acc:0.8233333333333334, test acc:0.664 ===\n",
      "train loss:0.6809426954151234\n",
      "train loss:0.7315821271557954\n",
      "train loss:0.5469383434103979\n",
      "=== epoch:419, train acc:0.82, test acc:0.6646 ===\n",
      "train loss:0.6116992712157535\n",
      "train loss:0.6333115344036013\n",
      "train loss:0.6030534780273293\n",
      "=== epoch:420, train acc:0.82, test acc:0.6653 ===\n",
      "train loss:0.6020609718139037\n",
      "train loss:0.586002822942322\n",
      "train loss:0.6138861075533852\n",
      "=== epoch:421, train acc:0.82, test acc:0.6678 ===\n",
      "train loss:0.557531275650786\n",
      "train loss:0.5911123728596095\n",
      "train loss:0.7450004600833187\n",
      "=== epoch:422, train acc:0.82, test acc:0.664 ===\n",
      "train loss:0.6379545930620718\n",
      "train loss:0.7425500727293571\n",
      "train loss:0.5141146839611115\n",
      "=== epoch:423, train acc:0.8166666666666667, test acc:0.6615 ===\n",
      "train loss:0.7769224691504855\n",
      "train loss:0.5552122863874701\n",
      "train loss:0.6583342281803688\n",
      "=== epoch:424, train acc:0.8333333333333334, test acc:0.6699 ===\n",
      "train loss:0.6565538130901178\n",
      "train loss:0.6638700110747322\n",
      "train loss:0.631643524019507\n",
      "=== epoch:425, train acc:0.8366666666666667, test acc:0.6728 ===\n",
      "train loss:0.512903128795348\n",
      "train loss:0.6010464520638417\n",
      "train loss:0.597934634924612\n",
      "=== epoch:426, train acc:0.84, test acc:0.6714 ===\n",
      "train loss:0.6245156797847863\n",
      "train loss:0.6644102149927598\n",
      "train loss:0.713564308716331\n",
      "=== epoch:427, train acc:0.84, test acc:0.6726 ===\n",
      "train loss:0.5823823217621585\n",
      "train loss:0.6273493738341687\n",
      "train loss:0.56683863527556\n",
      "=== epoch:428, train acc:0.8466666666666667, test acc:0.6789 ===\n",
      "train loss:0.6190550641647993\n",
      "train loss:0.5857652251541987\n",
      "train loss:0.5863129276063822\n",
      "=== epoch:429, train acc:0.8466666666666667, test acc:0.6802 ===\n",
      "train loss:0.5233760857564874\n",
      "train loss:0.48616974432190807\n",
      "train loss:0.5733603087228281\n",
      "=== epoch:430, train acc:0.8433333333333334, test acc:0.6734 ===\n",
      "train loss:0.5502778995210403\n",
      "train loss:0.5903828560228785\n",
      "train loss:0.6449377107326987\n",
      "=== epoch:431, train acc:0.8433333333333334, test acc:0.6727 ===\n",
      "train loss:0.5073126144514183\n",
      "train loss:0.6560876269130803\n",
      "train loss:0.6511641457070806\n",
      "=== epoch:432, train acc:0.84, test acc:0.672 ===\n",
      "train loss:0.5714591083438755\n",
      "train loss:0.5784852928104409\n",
      "train loss:0.6945804366995233\n",
      "=== epoch:433, train acc:0.8466666666666667, test acc:0.675 ===\n",
      "train loss:0.6021648036800233\n",
      "train loss:0.545469387612036\n",
      "train loss:0.5521205251236162\n",
      "=== epoch:434, train acc:0.8433333333333334, test acc:0.681 ===\n",
      "train loss:0.5462248900986206\n",
      "train loss:0.5574912034950682\n",
      "train loss:0.6479402149279201\n",
      "=== epoch:435, train acc:0.8433333333333334, test acc:0.6852 ===\n",
      "train loss:0.5921550864000308\n",
      "train loss:0.5947641721315413\n",
      "train loss:0.5391084457482157\n",
      "=== epoch:436, train acc:0.8466666666666667, test acc:0.6812 ===\n",
      "train loss:0.5480953204240224\n",
      "train loss:0.6001729469111188\n",
      "train loss:0.536280901770975\n",
      "=== epoch:437, train acc:0.8466666666666667, test acc:0.6789 ===\n",
      "train loss:0.5594443503297462\n",
      "train loss:0.6597444648087089\n",
      "train loss:0.46963004193029595\n",
      "=== epoch:438, train acc:0.8466666666666667, test acc:0.6801 ===\n",
      "train loss:0.5988972063654363\n",
      "train loss:0.5773515981551381\n",
      "train loss:0.48787486498719695\n",
      "=== epoch:439, train acc:0.8466666666666667, test acc:0.6794 ===\n",
      "train loss:0.5493121776333761\n",
      "train loss:0.5769074674738921\n",
      "train loss:0.5922543539868169\n",
      "=== epoch:440, train acc:0.85, test acc:0.6758 ===\n",
      "train loss:0.5595904672223173\n",
      "train loss:0.594366013343251\n",
      "train loss:0.510282839604164\n",
      "=== epoch:441, train acc:0.8566666666666667, test acc:0.6794 ===\n",
      "train loss:0.6307834032767687\n",
      "train loss:0.5450204057823008\n",
      "train loss:0.5406752181431896\n",
      "=== epoch:442, train acc:0.8566666666666667, test acc:0.6885 ===\n",
      "train loss:0.48865533246810444\n",
      "train loss:0.5022124903793798\n",
      "train loss:0.536340739790802\n",
      "=== epoch:443, train acc:0.8533333333333334, test acc:0.6902 ===\n",
      "train loss:0.39325757786877097\n",
      "train loss:0.5025372202195502\n",
      "train loss:0.4361184973323209\n",
      "=== epoch:444, train acc:0.8466666666666667, test acc:0.6885 ===\n",
      "train loss:0.5139012971827968\n",
      "train loss:0.6453266250843338\n",
      "train loss:0.5142939239055505\n",
      "=== epoch:445, train acc:0.8566666666666667, test acc:0.6858 ===\n",
      "train loss:0.455555019531346\n",
      "train loss:0.5956866097723208\n",
      "train loss:0.631561422079825\n",
      "=== epoch:446, train acc:0.8533333333333334, test acc:0.6852 ===\n",
      "train loss:0.4087303607520083\n",
      "train loss:0.5080935762727846\n",
      "train loss:0.5788540206055661\n",
      "=== epoch:447, train acc:0.8533333333333334, test acc:0.6825 ===\n",
      "train loss:0.5477277721790712\n",
      "train loss:0.5400045706346627\n",
      "train loss:0.6903708884430411\n",
      "=== epoch:448, train acc:0.86, test acc:0.688 ===\n",
      "train loss:0.5971295193944748\n",
      "train loss:0.4929958960605335\n",
      "train loss:0.43029401402674167\n",
      "=== epoch:449, train acc:0.8666666666666667, test acc:0.691 ===\n",
      "train loss:0.4134943366199994\n",
      "train loss:0.49460776400730017\n",
      "train loss:0.4361448167253744\n",
      "=== epoch:450, train acc:0.8666666666666667, test acc:0.6882 ===\n",
      "train loss:0.5259019562857411\n",
      "train loss:0.4587287765193943\n",
      "train loss:0.5365453468878351\n",
      "=== epoch:451, train acc:0.8666666666666667, test acc:0.6853 ===\n",
      "train loss:0.5144275516106719\n",
      "train loss:0.5099240897503976\n",
      "train loss:0.4735846298249095\n",
      "=== epoch:452, train acc:0.8633333333333333, test acc:0.6907 ===\n",
      "train loss:0.5659707774448725\n",
      "train loss:0.5611875231192607\n",
      "train loss:0.5335425528500743\n",
      "=== epoch:453, train acc:0.8733333333333333, test acc:0.69 ===\n",
      "train loss:0.641663191868858\n",
      "train loss:0.6929331620853649\n",
      "train loss:0.4910769549705744\n",
      "=== epoch:454, train acc:0.87, test acc:0.6937 ===\n",
      "train loss:0.5550051479091871\n",
      "train loss:0.520278681275752\n",
      "train loss:0.5056915737994481\n",
      "=== epoch:455, train acc:0.8766666666666667, test acc:0.6969 ===\n",
      "train loss:0.5029129498303895\n",
      "train loss:0.425586055893366\n",
      "train loss:0.5030080142961427\n",
      "=== epoch:456, train acc:0.8733333333333333, test acc:0.6957 ===\n",
      "train loss:0.5161931231280732\n",
      "train loss:0.5045364310666398\n",
      "train loss:0.5058049409090694\n",
      "=== epoch:457, train acc:0.87, test acc:0.6988 ===\n",
      "train loss:0.5415885809891883\n",
      "train loss:0.49629260737980035\n",
      "train loss:0.5700324867646145\n",
      "=== epoch:458, train acc:0.8766666666666667, test acc:0.6974 ===\n",
      "train loss:0.40651999865923505\n",
      "train loss:0.48877203191219193\n",
      "train loss:0.5102598063646702\n",
      "=== epoch:459, train acc:0.8733333333333333, test acc:0.6975 ===\n",
      "train loss:0.40020264865441413\n",
      "train loss:0.41876500202269895\n",
      "train loss:0.43400322872733876\n",
      "=== epoch:460, train acc:0.8733333333333333, test acc:0.696 ===\n",
      "train loss:0.41659126200307095\n",
      "train loss:0.5368946297160402\n",
      "train loss:0.46437986471101206\n",
      "=== epoch:461, train acc:0.8766666666666667, test acc:0.6994 ===\n",
      "train loss:0.576084600069078\n",
      "train loss:0.45842074661336274\n",
      "train loss:0.41787345569618384\n",
      "=== epoch:462, train acc:0.8733333333333333, test acc:0.6992 ===\n",
      "train loss:0.44581925905455644\n",
      "train loss:0.51183971063936\n",
      "train loss:0.48995172215243626\n",
      "=== epoch:463, train acc:0.8733333333333333, test acc:0.6964 ===\n",
      "train loss:0.5026998019927551\n",
      "train loss:0.5345156589588133\n",
      "train loss:0.3943580465986792\n",
      "=== epoch:464, train acc:0.8733333333333333, test acc:0.6965 ===\n",
      "train loss:0.44086805323962297\n",
      "train loss:0.4410432447748884\n",
      "train loss:0.49788574946844016\n",
      "=== epoch:465, train acc:0.8733333333333333, test acc:0.6976 ===\n",
      "train loss:0.5022349061608999\n",
      "train loss:0.4252114795736157\n",
      "train loss:0.4718761883962703\n",
      "=== epoch:466, train acc:0.8733333333333333, test acc:0.6981 ===\n",
      "train loss:0.44785719622083064\n",
      "train loss:0.5424064789864297\n",
      "train loss:0.4427484359591473\n",
      "=== epoch:467, train acc:0.87, test acc:0.6956 ===\n",
      "train loss:0.419119422534783\n",
      "train loss:0.442861397209685\n",
      "train loss:0.5416634351106056\n",
      "=== epoch:468, train acc:0.8766666666666667, test acc:0.6976 ===\n",
      "train loss:0.527163696226297\n",
      "train loss:0.49876866925315605\n",
      "train loss:0.5515841700088387\n",
      "=== epoch:469, train acc:0.8833333333333333, test acc:0.7002 ===\n",
      "train loss:0.4598892271257596\n",
      "train loss:0.4471630626478574\n",
      "train loss:0.4557328958834351\n",
      "=== epoch:470, train acc:0.8766666666666667, test acc:0.6986 ===\n",
      "train loss:0.36876797453752674\n",
      "train loss:0.4619836542067272\n",
      "train loss:0.36745751437171675\n",
      "=== epoch:471, train acc:0.8766666666666667, test acc:0.6992 ===\n",
      "train loss:0.4459964566087484\n",
      "train loss:0.4234209318414408\n",
      "train loss:0.3754775518884065\n",
      "=== epoch:472, train acc:0.88, test acc:0.695 ===\n",
      "train loss:0.40930689917695573\n",
      "train loss:0.5309186384253894\n",
      "train loss:0.5365225074589212\n",
      "=== epoch:473, train acc:0.88, test acc:0.6973 ===\n",
      "train loss:0.4766215330512912\n",
      "train loss:0.46472887990315803\n",
      "train loss:0.48022333755977037\n",
      "=== epoch:474, train acc:0.8866666666666667, test acc:0.6978 ===\n",
      "train loss:0.39469658014988396\n",
      "train loss:0.43817537228311776\n",
      "train loss:0.4776648968161188\n",
      "=== epoch:475, train acc:0.8766666666666667, test acc:0.6989 ===\n",
      "train loss:0.4920964847721646\n",
      "train loss:0.5111892092433908\n",
      "train loss:0.4043992293900826\n",
      "=== epoch:476, train acc:0.89, test acc:0.7026 ===\n",
      "train loss:0.48843223712551853\n",
      "train loss:0.48609115542010906\n",
      "train loss:0.47167619488194473\n",
      "=== epoch:477, train acc:0.89, test acc:0.7016 ===\n",
      "train loss:0.3654542861676422\n",
      "train loss:0.4783243042378876\n",
      "train loss:0.44961139743019296\n",
      "=== epoch:478, train acc:0.89, test acc:0.6977 ===\n",
      "train loss:0.4546714474015381\n",
      "train loss:0.5146345720962819\n",
      "train loss:0.48971412593644287\n",
      "=== epoch:479, train acc:0.8933333333333333, test acc:0.7056 ===\n",
      "train loss:0.4031668228516195\n",
      "train loss:0.36465028842340835\n",
      "train loss:0.42621645856489826\n",
      "=== epoch:480, train acc:0.8933333333333333, test acc:0.702 ===\n",
      "train loss:0.45973085745041564\n",
      "train loss:0.4613638780524094\n",
      "train loss:0.4801243673974819\n",
      "=== epoch:481, train acc:0.89, test acc:0.7011 ===\n",
      "train loss:0.356595876420157\n",
      "train loss:0.5156634474643639\n",
      "train loss:0.4411580168931558\n",
      "=== epoch:482, train acc:0.8966666666666666, test acc:0.7033 ===\n",
      "train loss:0.3893085870743997\n",
      "train loss:0.3592567049044705\n",
      "train loss:0.3691308778840146\n",
      "=== epoch:483, train acc:0.89, test acc:0.7005 ===\n",
      "train loss:0.352380272873257\n",
      "train loss:0.3873392037819415\n",
      "train loss:0.5070589508762224\n",
      "=== epoch:484, train acc:0.8966666666666666, test acc:0.7032 ===\n",
      "train loss:0.4348183577290296\n",
      "train loss:0.4647106375972281\n",
      "train loss:0.40861959939879045\n",
      "=== epoch:485, train acc:0.8933333333333333, test acc:0.7029 ===\n",
      "train loss:0.4554093587350125\n",
      "train loss:0.4214615497155485\n",
      "train loss:0.417438256098285\n",
      "=== epoch:486, train acc:0.8933333333333333, test acc:0.7033 ===\n",
      "train loss:0.4150111733958433\n",
      "train loss:0.4251636699171438\n",
      "train loss:0.38981874249738235\n",
      "=== epoch:487, train acc:0.8966666666666666, test acc:0.7045 ===\n",
      "train loss:0.45645335282500965\n",
      "train loss:0.3394278752891027\n",
      "train loss:0.43759576193171623\n",
      "=== epoch:488, train acc:0.9, test acc:0.7045 ===\n",
      "train loss:0.41059350514023985\n",
      "train loss:0.44331527666925213\n",
      "train loss:0.3832856980221001\n",
      "=== epoch:489, train acc:0.9, test acc:0.7055 ===\n",
      "train loss:0.4163343046426286\n",
      "train loss:0.3468013173820587\n",
      "train loss:0.44994580051937694\n",
      "=== epoch:490, train acc:0.8933333333333333, test acc:0.7057 ===\n",
      "train loss:0.4271492707476427\n",
      "train loss:0.39170575349866465\n",
      "train loss:0.42761126850079895\n",
      "=== epoch:491, train acc:0.8966666666666666, test acc:0.7084 ===\n",
      "train loss:0.328021474356677\n",
      "train loss:0.4090625058211175\n",
      "train loss:0.4337913831380609\n",
      "=== epoch:492, train acc:0.8833333333333333, test acc:0.7019 ===\n",
      "train loss:0.44016497307099406\n",
      "train loss:0.3715523193241328\n",
      "train loss:0.471453486281119\n",
      "=== epoch:493, train acc:0.9, test acc:0.7056 ===\n",
      "train loss:0.38247114548095484\n",
      "train loss:0.3529689250726767\n",
      "train loss:0.41634807068365687\n",
      "=== epoch:494, train acc:0.8966666666666666, test acc:0.706 ===\n",
      "train loss:0.421292418575667\n",
      "train loss:0.4376016903280135\n",
      "train loss:0.3792554165325415\n",
      "=== epoch:495, train acc:0.9033333333333333, test acc:0.7087 ===\n",
      "train loss:0.31904512234985416\n",
      "train loss:0.4995035368231621\n",
      "train loss:0.4062446411068231\n",
      "=== epoch:496, train acc:0.9, test acc:0.7105 ===\n",
      "train loss:0.3695996310711927\n",
      "train loss:0.39464042456077236\n",
      "train loss:0.4029377788624066\n",
      "=== epoch:497, train acc:0.9033333333333333, test acc:0.7115 ===\n",
      "train loss:0.3106423310358778\n",
      "train loss:0.4365734626395982\n",
      "train loss:0.39205365152247185\n",
      "=== epoch:498, train acc:0.9033333333333333, test acc:0.7119 ===\n",
      "train loss:0.3450389101465565\n",
      "train loss:0.4795643406422242\n",
      "train loss:0.3379352257753068\n",
      "=== epoch:499, train acc:0.9066666666666666, test acc:0.7127 ===\n",
      "train loss:0.314765835176461\n",
      "train loss:0.2972002717968103\n",
      "train loss:0.40842074709367593\n",
      "=== epoch:500, train acc:0.9066666666666666, test acc:0.7112 ===\n",
      "train loss:0.3854616866608284\n",
      "train loss:0.3245787340145359\n",
      "train loss:0.4483591166868174\n",
      "=== epoch:501, train acc:0.9066666666666666, test acc:0.7146 ===\n",
      "train loss:0.445278310333134\n",
      "train loss:0.35039853450725983\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.7159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.1746862545614447\n",
      "train loss:2.136586076316587\n",
      "train loss:2.159939629586974\n",
      "=== epoch:112, train acc:0.22666666666666666, test acc:0.1989 ===\n",
      "train loss:2.1622848732392086\n",
      "train loss:2.1511714065552554\n",
      "train loss:2.211690732786596\n",
      "=== epoch:113, train acc:0.23, test acc:0.2012 ===\n",
      "train loss:2.1458988990194188\n",
      "train loss:2.1251276683415226\n",
      "train loss:2.1799116439700272\n",
      "=== epoch:114, train acc:0.22666666666666666, test acc:0.1968 ===\n",
      "train loss:2.1423206910390893\n",
      "train loss:2.131840443671775\n",
      "train loss:2.1620105225788238\n",
      "=== epoch:115, train acc:0.22333333333333333, test acc:0.1943 ===\n",
      "train loss:2.1398826827168054\n",
      "train loss:2.1559771575281004\n",
      "train loss:2.0927422881290165\n",
      "=== epoch:116, train acc:0.22666666666666666, test acc:0.1944 ===\n",
      "train loss:2.159385474358367\n",
      "train loss:2.169514667102211\n",
      "train loss:2.1473972387289453\n",
      "=== epoch:117, train acc:0.22666666666666666, test acc:0.1931 ===\n",
      "train loss:2.203271331625566\n",
      "train loss:2.193610326774537\n",
      "train loss:2.1832788614293275\n",
      "=== epoch:118, train acc:0.23666666666666666, test acc:0.1984 ===\n",
      "train loss:2.1775165869327675\n",
      "train loss:2.129338171699144\n",
      "train loss:2.121205987895985\n",
      "=== epoch:119, train acc:0.23666666666666666, test acc:0.1971 ===\n",
      "train loss:2.1928322490058014\n",
      "train loss:2.1215719911115385\n",
      "train loss:2.1941820944508286\n",
      "=== epoch:120, train acc:0.23666666666666666, test acc:0.2006 ===\n",
      "train loss:2.1477310792460242\n",
      "train loss:2.198094541369502\n",
      "train loss:2.1129249882146492\n",
      "=== epoch:121, train acc:0.23333333333333334, test acc:0.2035 ===\n",
      "train loss:2.1702350984241083\n",
      "train loss:2.1506010553617965\n",
      "train loss:2.140415336359643\n",
      "=== epoch:122, train acc:0.24, test acc:0.2063 ===\n",
      "train loss:2.1532370872833506\n",
      "train loss:2.2198190841622414\n",
      "train loss:2.1321217503321797\n",
      "=== epoch:123, train acc:0.24333333333333335, test acc:0.2091 ===\n",
      "train loss:2.0895143087554695\n",
      "train loss:2.1587916469703403\n",
      "train loss:2.0739339461565316\n",
      "=== epoch:124, train acc:0.24, test acc:0.2091 ===\n",
      "train loss:2.166014474097235\n",
      "train loss:2.1474911448541847\n",
      "train loss:2.1385439029045026\n",
      "=== epoch:125, train acc:0.24, test acc:0.2127 ===\n",
      "train loss:2.1864934271230156\n",
      "train loss:2.1654193956802485\n",
      "train loss:2.131207290001629\n",
      "=== epoch:126, train acc:0.24666666666666667, test acc:0.2145 ===\n",
      "train loss:2.078964253880431\n",
      "train loss:2.0865777852031147\n",
      "train loss:2.1407836811382084\n",
      "=== epoch:127, train acc:0.24666666666666667, test acc:0.2126 ===\n",
      "train loss:2.1503145228191802\n",
      "train loss:2.082374143634125\n",
      "train loss:2.147496402812586\n",
      "=== epoch:128, train acc:0.24666666666666667, test acc:0.2137 ===\n",
      "train loss:2.1552281748079443\n",
      "train loss:2.143510221730199\n",
      "train loss:2.0851556086626415\n",
      "=== epoch:129, train acc:0.24666666666666667, test acc:0.214 ===\n",
      "train loss:2.1644256054148903\n",
      "train loss:2.157827541730362\n",
      "train loss:2.0763185640906787\n",
      "=== epoch:130, train acc:0.25, test acc:0.217 ===\n",
      "train loss:2.1162456898863393\n",
      "train loss:2.130917062109755\n",
      "train loss:2.1209072277535057\n",
      "=== epoch:131, train acc:0.25, test acc:0.2151 ===\n",
      "train loss:2.1426373863095787\n",
      "train loss:2.119060091030779\n",
      "train loss:2.1255033561778074\n",
      "=== epoch:132, train acc:0.25333333333333335, test acc:0.2171 ===\n",
      "train loss:2.121799879297478\n",
      "train loss:2.0819366560309844\n",
      "train loss:2.107829283897225\n",
      "=== epoch:133, train acc:0.25333333333333335, test acc:0.2166 ===\n",
      "train loss:2.1040284303784578\n",
      "train loss:2.1284986780057675\n",
      "train loss:2.1494617414218746\n",
      "=== epoch:134, train acc:0.25333333333333335, test acc:0.2186 ===\n",
      "train loss:2.149896737808335\n",
      "train loss:2.096333607190689\n",
      "train loss:2.126193504961112\n",
      "=== epoch:135, train acc:0.25666666666666665, test acc:0.2229 ===\n",
      "train loss:2.076254605628448\n",
      "train loss:2.121133904866898\n",
      "train loss:2.1041840516138244\n",
      "=== epoch:136, train acc:0.25666666666666665, test acc:0.2236 ===\n",
      "train loss:2.1635019354156877\n",
      "train loss:2.107878135145862\n",
      "train loss:2.1003209788745805\n",
      "=== epoch:137, train acc:0.26, test acc:0.2258 ===\n",
      "train loss:2.146641069853678\n",
      "train loss:2.0776787569175332\n",
      "train loss:2.084145816639141\n",
      "=== epoch:138, train acc:0.2633333333333333, test acc:0.2279 ===\n",
      "train loss:2.0535550117818047\n",
      "train loss:2.074948084460846\n",
      "train loss:2.0978625114885805\n",
      "=== epoch:139, train acc:0.2633333333333333, test acc:0.2287 ===\n",
      "train loss:2.0698741260436084\n",
      "train loss:2.103489102091836\n",
      "train loss:2.079063855264369\n",
      "=== epoch:140, train acc:0.26666666666666666, test acc:0.2299 ===\n",
      "train loss:2.106584913389094\n",
      "train loss:2.0652323392800964\n",
      "train loss:2.1307663639978456\n",
      "=== epoch:141, train acc:0.27666666666666667, test acc:0.2332 ===\n",
      "train loss:2.067040317310058\n",
      "train loss:2.0787158262114254\n",
      "train loss:2.070801058128392\n",
      "=== epoch:142, train acc:0.27666666666666667, test acc:0.2346 ===\n",
      "train loss:2.0805520675628317\n",
      "train loss:2.0921030078325673\n",
      "train loss:2.0630564998005334\n",
      "=== epoch:143, train acc:0.27666666666666667, test acc:0.2365 ===\n",
      "train loss:2.138417221604962\n",
      "train loss:2.102716423517529\n",
      "train loss:2.1062255934233747\n",
      "=== epoch:144, train acc:0.27666666666666667, test acc:0.2401 ===\n",
      "train loss:2.0775329797303583\n",
      "train loss:2.109063158960206\n",
      "train loss:2.1518424449009714\n",
      "=== epoch:145, train acc:0.2866666666666667, test acc:0.2426 ===\n",
      "train loss:2.099762940389623\n",
      "train loss:2.071467657387703\n",
      "train loss:2.0696830346213186\n",
      "=== epoch:146, train acc:0.2866666666666667, test acc:0.2464 ===\n",
      "train loss:2.0669908861558945\n",
      "train loss:2.0307345915405204\n",
      "train loss:2.030143157796328\n",
      "=== epoch:147, train acc:0.2833333333333333, test acc:0.2443 ===\n",
      "train loss:2.139105175903868\n",
      "train loss:2.166760897285856\n",
      "train loss:2.0761039529105894\n",
      "=== epoch:148, train acc:0.29333333333333333, test acc:0.2469 ===\n",
      "train loss:2.0298796807262525\n",
      "train loss:2.091860843538227\n",
      "train loss:2.1004190652187145\n",
      "=== epoch:149, train acc:0.2966666666666667, test acc:0.2484 ===\n",
      "train loss:2.115726845356628\n",
      "train loss:2.069164598174078\n",
      "train loss:2.0706478559967794\n",
      "=== epoch:150, train acc:0.2966666666666667, test acc:0.2487 ===\n",
      "train loss:2.117185283744844\n",
      "train loss:2.0354999119310757\n",
      "train loss:2.0498203570992435\n",
      "=== epoch:151, train acc:0.30333333333333334, test acc:0.2538 ===\n",
      "train loss:2.0289083268731654\n",
      "train loss:1.957255086030448\n",
      "train loss:2.044718213001382\n",
      "=== epoch:152, train acc:0.30333333333333334, test acc:0.2519 ===\n",
      "train loss:2.104533266870011\n",
      "train loss:2.0073732452819772\n",
      "train loss:2.014428990841464\n",
      "=== epoch:153, train acc:0.30333333333333334, test acc:0.252 ===\n",
      "train loss:1.9738050950815338\n",
      "train loss:1.9929849036285676\n",
      "train loss:2.0616650070688425\n",
      "=== epoch:154, train acc:0.30333333333333334, test acc:0.2508 ===\n",
      "train loss:2.0786972376630275\n",
      "train loss:1.9944859781972326\n",
      "train loss:2.0472370633373904\n",
      "=== epoch:155, train acc:0.30333333333333334, test acc:0.2516 ===\n",
      "train loss:2.052091999076464\n",
      "train loss:2.026389882366773\n",
      "train loss:1.979528630488664\n",
      "=== epoch:156, train acc:0.30333333333333334, test acc:0.2507 ===\n",
      "train loss:2.040791151987156\n",
      "train loss:1.9950858031846954\n",
      "train loss:2.0202396561968197\n",
      "=== epoch:157, train acc:0.3, test acc:0.2502 ===\n",
      "train loss:1.971526127853012\n",
      "train loss:1.9772814686553106\n",
      "train loss:1.9826111984077528\n",
      "=== epoch:158, train acc:0.30333333333333334, test acc:0.2509 ===\n",
      "train loss:2.0657204990344415\n",
      "train loss:1.9947255598412985\n",
      "train loss:2.0699729432706904\n",
      "=== epoch:159, train acc:0.31, test acc:0.2542 ===\n",
      "train loss:1.9969951192625488\n",
      "train loss:2.0080069398869376\n",
      "train loss:2.013242610193045\n",
      "=== epoch:160, train acc:0.30666666666666664, test acc:0.2553 ===\n",
      "train loss:2.019621496689204\n",
      "train loss:2.030065939835073\n",
      "train loss:1.9850205358769863\n",
      "=== epoch:161, train acc:0.32, test acc:0.2577 ===\n",
      "train loss:2.0597074236238995\n",
      "train loss:2.008174044994053\n",
      "train loss:2.0007385106301943\n",
      "=== epoch:162, train acc:0.3233333333333333, test acc:0.2599 ===\n",
      "train loss:1.9294008376737137\n",
      "train loss:2.1057384909435295\n",
      "train loss:2.02875306150199\n",
      "=== epoch:163, train acc:0.33, test acc:0.262 ===\n",
      "train loss:2.030089459256083\n",
      "train loss:2.0713096453322204\n",
      "train loss:2.0258523055781192\n",
      "=== epoch:164, train acc:0.3466666666666667, test acc:0.2682 ===\n",
      "train loss:2.011751225018937\n",
      "train loss:2.062095142918614\n",
      "train loss:2.0094007188081817\n",
      "=== epoch:165, train acc:0.35, test acc:0.2712 ===\n",
      "train loss:1.9648016397030628\n",
      "train loss:2.0343728675432975\n",
      "train loss:1.940247130891782\n",
      "=== epoch:166, train acc:0.3433333333333333, test acc:0.2706 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.9937108663268237\n",
      "train loss:1.921259131380019\n",
      "train loss:2.0104681231380477\n",
      "=== epoch:167, train acc:0.3566666666666667, test acc:0.2736 ===\n",
      "train loss:1.9434860143105186\n",
      "train loss:2.00443109294844\n",
      "train loss:2.029383336575174\n",
      "=== epoch:168, train acc:0.36, test acc:0.2779 ===\n",
      "train loss:2.013337890706357\n",
      "train loss:1.9655787081043676\n",
      "train loss:2.0644763180820305\n",
      "=== epoch:169, train acc:0.36666666666666664, test acc:0.2847 ===\n",
      "train loss:2.0333110644015338\n",
      "train loss:1.9779266974277223\n",
      "train loss:1.9772278176390754\n",
      "=== epoch:170, train acc:0.38333333333333336, test acc:0.2879 ===\n",
      "train loss:1.993404098025747\n",
      "train loss:1.9401895387379775\n",
      "train loss:1.9948905384392348\n",
      "=== epoch:171, train acc:0.3933333333333333, test acc:0.2913 ===\n",
      "train loss:1.9624315097695844\n",
      "train loss:1.9005818052882018\n",
      "train loss:1.9004462409423817\n",
      "=== epoch:172, train acc:0.3933333333333333, test acc:0.2923 ===\n",
      "train loss:1.9275588679105098\n",
      "train loss:2.0505998165073014\n",
      "train loss:1.9418114675705556\n",
      "=== epoch:173, train acc:0.4, test acc:0.2928 ===\n",
      "train loss:2.043282645157527\n",
      "train loss:2.0162460657986414\n",
      "train loss:1.8349487186056834\n",
      "=== epoch:174, train acc:0.4033333333333333, test acc:0.2963 ===\n",
      "train loss:2.004927144974861\n",
      "train loss:1.9729170544179437\n",
      "train loss:1.8966689044789253\n",
      "=== epoch:175, train acc:0.41, test acc:0.297 ===\n",
      "train loss:2.0352664179347233\n",
      "train loss:1.9512646848681678\n",
      "train loss:1.9532488033063313\n",
      "=== epoch:176, train acc:0.4066666666666667, test acc:0.2997 ===\n",
      "train loss:1.9805666899093655\n",
      "train loss:1.9725432749657943\n",
      "train loss:1.9297065903468793\n",
      "=== epoch:177, train acc:0.42, test acc:0.3046 ===\n",
      "train loss:1.9282795817025267\n",
      "train loss:1.9538570127671513\n",
      "train loss:2.012449862552167\n",
      "=== epoch:178, train acc:0.43, test acc:0.3089 ===\n",
      "train loss:2.0076077905392227\n",
      "train loss:2.011481432236041\n",
      "train loss:2.0175182846253805\n",
      "=== epoch:179, train acc:0.4266666666666667, test acc:0.3103 ===\n",
      "train loss:1.872117124808307\n",
      "train loss:1.9882299990105077\n",
      "train loss:1.9125846145483087\n",
      "=== epoch:180, train acc:0.42333333333333334, test acc:0.3074 ===\n",
      "train loss:1.9262932881850536\n",
      "train loss:1.971044580554256\n",
      "train loss:1.9220840228473428\n",
      "=== epoch:181, train acc:0.4266666666666667, test acc:0.3071 ===\n",
      "train loss:1.9473319044058557\n",
      "train loss:1.9181176933528865\n",
      "train loss:2.0051621649046765\n",
      "=== epoch:182, train acc:0.43333333333333335, test acc:0.3103 ===\n",
      "train loss:2.0397836916609977\n",
      "train loss:1.9837591415086582\n",
      "train loss:1.9638199836975148\n",
      "=== epoch:183, train acc:0.43666666666666665, test acc:0.3184 ===\n",
      "train loss:1.9822920057919804\n",
      "train loss:1.9783603186630616\n",
      "train loss:1.9978894017581468\n",
      "=== epoch:184, train acc:0.44, test acc:0.322 ===\n",
      "train loss:1.9161382548798886\n",
      "train loss:1.9393018793739203\n",
      "train loss:1.9586570487103507\n",
      "=== epoch:185, train acc:0.43666666666666665, test acc:0.3224 ===\n",
      "train loss:1.9385645034721253\n",
      "train loss:1.8995002722183696\n",
      "train loss:1.9677346248504994\n",
      "=== epoch:186, train acc:0.43333333333333335, test acc:0.3198 ===\n",
      "train loss:1.9410646156950002\n",
      "train loss:1.90013970753254\n",
      "train loss:1.9302370417772472\n",
      "=== epoch:187, train acc:0.44, test acc:0.3205 ===\n",
      "train loss:1.9458861818783537\n",
      "train loss:1.8497932944767586\n",
      "train loss:1.8729816188802033\n",
      "=== epoch:188, train acc:0.44333333333333336, test acc:0.3222 ===\n",
      "train loss:1.8895768755943418\n",
      "train loss:1.90818344399923\n",
      "train loss:1.8073618998475218\n",
      "=== epoch:189, train acc:0.44333333333333336, test acc:0.3221 ===\n",
      "train loss:1.9004420578095678\n",
      "train loss:1.929711534441898\n",
      "train loss:1.9228521932137708\n",
      "=== epoch:190, train acc:0.44333333333333336, test acc:0.3242 ===\n",
      "train loss:1.9217161841508272\n",
      "train loss:2.0099656563269126\n",
      "train loss:2.0488506790756156\n",
      "=== epoch:191, train acc:0.4533333333333333, test acc:0.3312 ===\n",
      "train loss:1.8089944457778915\n",
      "train loss:1.8994462819204918\n",
      "train loss:1.950615024632261\n",
      "=== epoch:192, train acc:0.46, test acc:0.3322 ===\n",
      "train loss:1.8996735105933846\n",
      "train loss:1.871900205535495\n",
      "train loss:1.935829093397204\n",
      "=== epoch:193, train acc:0.47, test acc:0.3393 ===\n",
      "train loss:1.8930327715891169\n",
      "train loss:1.9154486922886687\n",
      "train loss:1.919829783936089\n",
      "=== epoch:194, train acc:0.47, test acc:0.34 ===\n",
      "train loss:1.90538355478917\n",
      "train loss:1.89732472232833\n",
      "train loss:1.825851000673663\n",
      "=== epoch:195, train acc:0.47, test acc:0.3369 ===\n",
      "train loss:1.8805985126386744\n",
      "train loss:1.8991380321079157\n",
      "train loss:1.910469337869919\n",
      "=== epoch:196, train acc:0.47, test acc:0.3358 ===\n",
      "train loss:1.8691228183824091\n",
      "train loss:1.8996711703036695\n",
      "train loss:1.8973666051903373\n",
      "=== epoch:197, train acc:0.4633333333333333, test acc:0.3343 ===\n",
      "train loss:1.8421550418388863\n",
      "train loss:1.9065533801257886\n",
      "train loss:1.825564025157078\n",
      "=== epoch:198, train acc:0.45666666666666667, test acc:0.3327 ===\n",
      "train loss:1.8531602174244435\n",
      "train loss:1.9892396975143034\n",
      "train loss:1.8694621434745309\n",
      "=== epoch:199, train acc:0.4666666666666667, test acc:0.3374 ===\n",
      "train loss:1.8869484602214448\n",
      "train loss:1.8495658044367775\n",
      "train loss:1.7883999352239868\n",
      "=== epoch:200, train acc:0.46, test acc:0.3355 ===\n",
      "train loss:1.860660158824051\n",
      "train loss:1.9202010199351738\n",
      "train loss:1.83550579886284\n",
      "=== epoch:201, train acc:0.47333333333333333, test acc:0.3372 ===\n",
      "train loss:1.9300105759509438\n",
      "train loss:1.8748564354899477\n",
      "train loss:1.835086852577503\n",
      "=== epoch:202, train acc:0.47333333333333333, test acc:0.34 ===\n",
      "train loss:1.8178376472054212\n",
      "train loss:1.8610900347158406\n",
      "train loss:1.8629840315387856\n",
      "=== epoch:203, train acc:0.45666666666666667, test acc:0.3361 ===\n",
      "train loss:1.8623961307324601\n",
      "train loss:1.8660041807944991\n",
      "train loss:1.8596926072946416\n",
      "=== epoch:204, train acc:0.4533333333333333, test acc:0.3358 ===\n",
      "train loss:1.8391993771996378\n",
      "train loss:1.8679544489114859\n",
      "train loss:1.9007219480511026\n",
      "=== epoch:205, train acc:0.4666666666666667, test acc:0.3387 ===\n",
      "train loss:1.869822637573847\n",
      "train loss:1.7977037108528475\n",
      "train loss:1.8270597397833257\n",
      "=== epoch:206, train acc:0.47, test acc:0.3412 ===\n",
      "train loss:1.869524809399539\n",
      "train loss:1.8877756635255851\n",
      "train loss:1.9420844924080811\n",
      "=== epoch:207, train acc:0.4766666666666667, test acc:0.3436 ===\n",
      "train loss:1.8249541833644813\n",
      "train loss:1.7447787859187804\n",
      "train loss:1.8412325053875436\n",
      "=== epoch:208, train acc:0.47333333333333333, test acc:0.3428 ===\n",
      "train loss:1.934348659246108\n",
      "train loss:1.857479604800038\n",
      "train loss:1.7552610022404393\n",
      "=== epoch:209, train acc:0.47333333333333333, test acc:0.3468 ===\n",
      "train loss:1.706645047734703\n",
      "train loss:1.809886220710397\n",
      "train loss:1.73085912839703\n",
      "=== epoch:210, train acc:0.47, test acc:0.3456 ===\n",
      "train loss:1.8703408127568593\n",
      "train loss:1.8753379951711444\n",
      "train loss:1.8426884020548864\n",
      "=== epoch:211, train acc:0.4866666666666667, test acc:0.3514 ===\n",
      "train loss:1.822394348400858\n",
      "train loss:1.8036311136359282\n",
      "train loss:1.8214012422201058\n",
      "=== epoch:212, train acc:0.48, test acc:0.3524 ===\n",
      "train loss:1.8747372004645928\n",
      "train loss:1.8344035876631337\n",
      "train loss:1.8360092137193362\n",
      "=== epoch:213, train acc:0.48333333333333334, test acc:0.3536 ===\n",
      "train loss:1.832094187648741\n",
      "train loss:1.9520973240686406\n",
      "train loss:1.7841268326616537\n",
      "=== epoch:214, train acc:0.5033333333333333, test acc:0.3589 ===\n",
      "train loss:1.7407913039238097\n",
      "train loss:1.8173458630517851\n",
      "train loss:1.8799227538784424\n",
      "=== epoch:215, train acc:0.5, test acc:0.3643 ===\n",
      "train loss:1.7872247746967762\n",
      "train loss:1.8263673413562025\n",
      "train loss:1.8467973094060568\n",
      "=== epoch:216, train acc:0.5066666666666667, test acc:0.3646 ===\n",
      "train loss:1.5969801566434176\n",
      "train loss:1.8574366053716236\n",
      "train loss:1.8460418134866226\n",
      "=== epoch:217, train acc:0.5033333333333333, test acc:0.3679 ===\n",
      "train loss:1.7575294108631536\n",
      "train loss:1.7073071256654198\n",
      "train loss:1.8319650476997298\n",
      "=== epoch:218, train acc:0.5033333333333333, test acc:0.3646 ===\n",
      "train loss:1.7573860961182683\n",
      "train loss:1.7041145701760891\n",
      "train loss:1.8121082285341228\n",
      "=== epoch:219, train acc:0.5066666666666667, test acc:0.3673 ===\n",
      "train loss:1.9680718980490834\n",
      "train loss:1.7960844028388332\n",
      "train loss:1.8057381364942764\n",
      "=== epoch:220, train acc:0.51, test acc:0.375 ===\n",
      "train loss:1.7805751024411018\n",
      "train loss:1.8386104342303913\n",
      "train loss:1.866324654373146\n",
      "=== epoch:221, train acc:0.5166666666666667, test acc:0.3834 ===\n",
      "train loss:1.7666124735020927\n",
      "train loss:1.7765257086051767\n",
      "train loss:1.681608293183824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:222, train acc:0.5133333333333333, test acc:0.376 ===\n",
      "train loss:1.8077473183460164\n",
      "train loss:1.7126032269194238\n",
      "train loss:1.8054375302809214\n",
      "=== epoch:223, train acc:0.51, test acc:0.3809 ===\n",
      "train loss:1.7755506423388971\n",
      "train loss:1.627206785769497\n",
      "train loss:1.738750038499662\n",
      "=== epoch:224, train acc:0.5166666666666667, test acc:0.3834 ===\n",
      "train loss:1.785582479218195\n",
      "train loss:1.7080378382351007\n",
      "train loss:1.672305766370735\n",
      "=== epoch:225, train acc:0.51, test acc:0.3811 ===\n",
      "train loss:1.5767432481383852\n",
      "train loss:1.7559077975116026\n",
      "train loss:1.8024388391759854\n",
      "=== epoch:226, train acc:0.51, test acc:0.377 ===\n",
      "train loss:1.7899947033066423\n",
      "train loss:1.7029053647246184\n",
      "train loss:1.693345721908313\n",
      "=== epoch:227, train acc:0.5133333333333333, test acc:0.3817 ===\n",
      "train loss:1.76148622813521\n",
      "train loss:1.7775201112145096\n",
      "train loss:1.7345518692982806\n",
      "=== epoch:228, train acc:0.5133333333333333, test acc:0.3864 ===\n",
      "train loss:1.767274874207856\n",
      "train loss:1.6343420333264962\n",
      "train loss:1.6422640474664965\n",
      "=== epoch:229, train acc:0.5066666666666667, test acc:0.3811 ===\n",
      "train loss:1.7012931660654302\n",
      "train loss:1.641539121278912\n",
      "train loss:1.7048648201536043\n",
      "=== epoch:230, train acc:0.5166666666666667, test acc:0.3881 ===\n",
      "train loss:1.8895411520156336\n",
      "train loss:1.7143933175693604\n",
      "train loss:1.7789798931645913\n",
      "=== epoch:231, train acc:0.5166666666666667, test acc:0.3924 ===\n",
      "train loss:1.7890789067339954\n",
      "train loss:1.8522457387684512\n",
      "train loss:1.6268659270863557\n",
      "=== epoch:232, train acc:0.53, test acc:0.4018 ===\n",
      "train loss:1.7304930849454823\n",
      "train loss:1.7725069724707598\n",
      "train loss:1.6945252346509927\n",
      "=== epoch:233, train acc:0.54, test acc:0.4066 ===\n",
      "train loss:1.735902156723463\n",
      "train loss:1.759844112068184\n",
      "train loss:1.6176505961969954\n",
      "=== epoch:234, train acc:0.5333333333333333, test acc:0.4061 ===\n",
      "train loss:1.6811174112969138\n",
      "train loss:1.6206861274407012\n",
      "train loss:1.7657968524990937\n",
      "=== epoch:235, train acc:0.54, test acc:0.4071 ===\n",
      "train loss:1.6944727540268136\n",
      "train loss:1.6512950983073242\n",
      "train loss:1.7034669112745828\n",
      "=== epoch:236, train acc:0.5466666666666666, test acc:0.4106 ===\n",
      "train loss:1.7015819435925164\n",
      "train loss:1.700879631620429\n",
      "train loss:1.753257684319293\n",
      "=== epoch:237, train acc:0.5333333333333333, test acc:0.4126 ===\n",
      "train loss:1.6899749437570497\n",
      "train loss:1.6762454148228394\n",
      "train loss:1.6578768759518965\n",
      "=== epoch:238, train acc:0.5366666666666666, test acc:0.4141 ===\n",
      "train loss:1.7457357899170591\n",
      "train loss:1.7402058491189283\n",
      "train loss:1.6636684215060868\n",
      "=== epoch:239, train acc:0.54, test acc:0.4155 ===\n",
      "train loss:1.7659538546429063\n",
      "train loss:1.7715999849172313\n",
      "train loss:1.7052694459593443\n",
      "=== epoch:240, train acc:0.55, test acc:0.4222 ===\n",
      "train loss:1.6849450729170954\n",
      "train loss:1.6863523307574106\n",
      "train loss:1.6963187965091342\n",
      "=== epoch:241, train acc:0.5566666666666666, test acc:0.4297 ===\n",
      "train loss:1.7409375412233854\n",
      "train loss:1.7092633017250143\n",
      "train loss:1.6613626152402865\n",
      "=== epoch:242, train acc:0.55, test acc:0.4278 ===\n",
      "train loss:1.7042766841842296\n",
      "train loss:1.6855735969885302\n",
      "train loss:1.6701959145073775\n",
      "=== epoch:243, train acc:0.54, test acc:0.423 ===\n",
      "train loss:1.5662528030397451\n",
      "train loss:1.6042106734710504\n",
      "train loss:1.6879445142464036\n",
      "=== epoch:244, train acc:0.54, test acc:0.4219 ===\n",
      "train loss:1.7185163024238594\n",
      "train loss:1.640736449576586\n",
      "train loss:1.6278857662312272\n",
      "=== epoch:245, train acc:0.54, test acc:0.4202 ===\n",
      "train loss:1.7241101898017595\n",
      "train loss:1.6301535106902014\n",
      "train loss:1.6096463799195901\n",
      "=== epoch:246, train acc:0.5566666666666666, test acc:0.423 ===\n",
      "train loss:1.7565491426176862\n",
      "train loss:1.6652199331040247\n",
      "train loss:1.7305237150666068\n",
      "=== epoch:247, train acc:0.5533333333333333, test acc:0.4299 ===\n",
      "train loss:1.5596396713656215\n",
      "train loss:1.6990123482901802\n",
      "train loss:1.6347295013003478\n",
      "=== epoch:248, train acc:0.55, test acc:0.4261 ===\n",
      "train loss:1.7189593761855175\n",
      "train loss:1.7257313843250788\n",
      "train loss:1.7411469567680526\n",
      "=== epoch:249, train acc:0.5533333333333333, test acc:0.4338 ===\n",
      "train loss:1.6438226942278138\n",
      "train loss:1.5843545729097128\n",
      "train loss:1.6878107355609058\n",
      "=== epoch:250, train acc:0.5533333333333333, test acc:0.4362 ===\n",
      "train loss:1.6860858769468479\n",
      "train loss:1.6458438514456644\n",
      "train loss:1.713277772981277\n",
      "=== epoch:251, train acc:0.5533333333333333, test acc:0.4416 ===\n",
      "train loss:1.587209910062292\n",
      "train loss:1.5978088212452326\n",
      "train loss:1.5602171848192157\n",
      "=== epoch:252, train acc:0.56, test acc:0.4456 ===\n",
      "train loss:1.5551097365983464\n",
      "train loss:1.6212126144793522\n",
      "train loss:1.6243584365310266\n",
      "=== epoch:253, train acc:0.5566666666666666, test acc:0.4457 ===\n",
      "train loss:1.6589105856068076\n",
      "train loss:1.6611070927671503\n",
      "train loss:1.727112786647077\n",
      "=== epoch:254, train acc:0.56, test acc:0.4478 ===\n",
      "train loss:1.5820603694715913\n",
      "train loss:1.6235555481367743\n",
      "train loss:1.6036473538187095\n",
      "=== epoch:255, train acc:0.56, test acc:0.4485 ===\n",
      "train loss:1.5244011676329619\n",
      "train loss:1.4260811667189395\n",
      "train loss:1.623909365705222\n",
      "=== epoch:256, train acc:0.56, test acc:0.4467 ===\n",
      "train loss:1.574885199799884\n",
      "train loss:1.4798669284096193\n",
      "train loss:1.6416000649689488\n",
      "=== epoch:257, train acc:0.56, test acc:0.4509 ===\n",
      "train loss:1.513542520720432\n",
      "train loss:1.5639822031922832\n",
      "train loss:1.5431152043286755\n",
      "=== epoch:258, train acc:0.5566666666666666, test acc:0.4501 ===\n",
      "train loss:1.6608789049918797\n",
      "train loss:1.4815744342101664\n",
      "train loss:1.6284311437477224\n",
      "=== epoch:259, train acc:0.5766666666666667, test acc:0.458 ===\n",
      "train loss:1.578026104551983\n",
      "train loss:1.5143459698936612\n",
      "train loss:1.5420079234385573\n",
      "=== epoch:260, train acc:0.5666666666666667, test acc:0.4611 ===\n",
      "train loss:1.467308225776656\n",
      "train loss:1.540578148599183\n",
      "train loss:1.4869545021136765\n",
      "=== epoch:261, train acc:0.5633333333333334, test acc:0.4607 ===\n",
      "train loss:1.652751228350843\n",
      "train loss:1.5065410377820112\n",
      "train loss:1.5258318141981777\n",
      "=== epoch:262, train acc:0.56, test acc:0.4615 ===\n",
      "train loss:1.5085999087794866\n",
      "train loss:1.691295848984557\n",
      "train loss:1.5797407013054607\n",
      "=== epoch:263, train acc:0.5733333333333334, test acc:0.468 ===\n",
      "train loss:1.4017571419332417\n",
      "train loss:1.6041199967830957\n",
      "train loss:1.4946689513785163\n",
      "=== epoch:264, train acc:0.5733333333333334, test acc:0.4677 ===\n",
      "train loss:1.6998292393767198\n",
      "train loss:1.676506497468356\n",
      "train loss:1.6259941878189588\n",
      "=== epoch:265, train acc:0.5766666666666667, test acc:0.4754 ===\n",
      "train loss:1.490167587986483\n",
      "train loss:1.601973385926461\n",
      "train loss:1.535853981025663\n",
      "=== epoch:266, train acc:0.5866666666666667, test acc:0.4788 ===\n",
      "train loss:1.4283137910834256\n",
      "train loss:1.4934072908720133\n",
      "train loss:1.6636511637265503\n",
      "=== epoch:267, train acc:0.59, test acc:0.4812 ===\n",
      "train loss:1.4743924327430875\n",
      "train loss:1.5533093769239406\n",
      "train loss:1.5531413734678943\n",
      "=== epoch:268, train acc:0.59, test acc:0.4811 ===\n",
      "train loss:1.6291192666227587\n",
      "train loss:1.5811905005088223\n",
      "train loss:1.5261717886624415\n",
      "=== epoch:269, train acc:0.59, test acc:0.4844 ===\n",
      "train loss:1.54198603430266\n",
      "train loss:1.5676564491742253\n",
      "train loss:1.5962596659269348\n",
      "=== epoch:270, train acc:0.59, test acc:0.4858 ===\n",
      "train loss:1.6188885708844531\n",
      "train loss:1.4587981538524248\n",
      "train loss:1.6663054975333063\n",
      "=== epoch:271, train acc:0.6066666666666667, test acc:0.4937 ===\n",
      "train loss:1.5418689503085878\n",
      "train loss:1.6543760507951675\n",
      "train loss:1.5347102064480254\n",
      "=== epoch:272, train acc:0.6, test acc:0.4951 ===\n",
      "train loss:1.4603810419321335\n",
      "train loss:1.526034618916918\n",
      "train loss:1.5327522047217579\n",
      "=== epoch:273, train acc:0.6066666666666667, test acc:0.4966 ===\n",
      "train loss:1.54177633307209\n",
      "train loss:1.5930613788452828\n",
      "train loss:1.5806851396356887\n",
      "=== epoch:274, train acc:0.62, test acc:0.4974 ===\n",
      "train loss:1.3915642913125894\n",
      "train loss:1.4313202836223429\n",
      "train loss:1.3553027587991715\n",
      "=== epoch:275, train acc:0.61, test acc:0.4956 ===\n",
      "train loss:1.4498197338437493\n",
      "train loss:1.4768906154607644\n",
      "train loss:1.412036118673219\n",
      "=== epoch:276, train acc:0.6233333333333333, test acc:0.501 ===\n",
      "train loss:1.6367896437728233\n",
      "train loss:1.5027948913789044\n",
      "train loss:1.462787161580863\n",
      "=== epoch:277, train acc:0.63, test acc:0.5038 ===\n",
      "train loss:1.5959535339225495\n",
      "train loss:1.5577319279340005\n",
      "train loss:1.4516828930208576\n",
      "=== epoch:278, train acc:0.6366666666666667, test acc:0.5083 ===\n",
      "train loss:1.5595812611555073\n",
      "train loss:1.548186652328552\n",
      "train loss:1.589334997700067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:279, train acc:0.6333333333333333, test acc:0.5096 ===\n",
      "train loss:1.4553105622873341\n",
      "train loss:1.4703993521865493\n",
      "train loss:1.3020288371242774\n",
      "=== epoch:280, train acc:0.6266666666666667, test acc:0.5071 ===\n",
      "train loss:1.4452016116611823\n",
      "train loss:1.5008828204217528\n",
      "train loss:1.536011674168106\n",
      "=== epoch:281, train acc:0.6266666666666667, test acc:0.5063 ===\n",
      "train loss:1.4774701689295902\n",
      "train loss:1.5517365376215657\n",
      "train loss:1.5931491782862768\n",
      "=== epoch:282, train acc:0.6266666666666667, test acc:0.5129 ===\n",
      "train loss:1.424044889538591\n",
      "train loss:1.5577489771101556\n",
      "train loss:1.4534816654515823\n",
      "=== epoch:283, train acc:0.6266666666666667, test acc:0.5149 ===\n",
      "train loss:1.3895973129686618\n",
      "train loss:1.5438646029334044\n",
      "train loss:1.4260139922615174\n",
      "=== epoch:284, train acc:0.6266666666666667, test acc:0.5166 ===\n",
      "train loss:1.5145380853154555\n",
      "train loss:1.3327760049570188\n",
      "train loss:1.3505158370507269\n",
      "=== epoch:285, train acc:0.6233333333333333, test acc:0.5157 ===\n",
      "train loss:1.5000325851342293\n",
      "train loss:1.4190113440277576\n",
      "train loss:1.457108976508914\n",
      "=== epoch:286, train acc:0.6266666666666667, test acc:0.5173 ===\n",
      "train loss:1.4489097894371248\n",
      "train loss:1.4903054088042058\n",
      "train loss:1.3829805398472035\n",
      "=== epoch:287, train acc:0.6266666666666667, test acc:0.5184 ===\n",
      "train loss:1.4379440612876937\n",
      "train loss:1.442247513150469\n",
      "train loss:1.3942216493537065\n",
      "=== epoch:288, train acc:0.6366666666666667, test acc:0.5206 ===\n",
      "train loss:1.477876366171961\n",
      "train loss:1.3292419074841428\n",
      "train loss:1.4383474085278758\n",
      "=== epoch:289, train acc:0.6333333333333333, test acc:0.5188 ===\n",
      "train loss:1.4474861972547424\n",
      "train loss:1.592215960396953\n",
      "train loss:1.3771149462003782\n",
      "=== epoch:290, train acc:0.6466666666666666, test acc:0.5216 ===\n",
      "train loss:1.411560564248323\n",
      "train loss:1.43686854635212\n",
      "train loss:1.460102571664828\n",
      "=== epoch:291, train acc:0.6466666666666666, test acc:0.5232 ===\n",
      "train loss:1.4921590685775348\n",
      "train loss:1.445163468186879\n",
      "train loss:1.3495402876832336\n",
      "=== epoch:292, train acc:0.6433333333333333, test acc:0.5232 ===\n",
      "train loss:1.455340930606291\n",
      "train loss:1.3523802614822125\n",
      "train loss:1.3420076733703568\n",
      "=== epoch:293, train acc:0.6433333333333333, test acc:0.5253 ===\n",
      "train loss:1.2659415718157385\n",
      "train loss:1.183128708300532\n",
      "train loss:1.226532926197722\n",
      "=== epoch:294, train acc:0.6466666666666666, test acc:0.5235 ===\n",
      "train loss:1.2865705500653133\n",
      "train loss:1.3187778104657522\n",
      "train loss:1.3680951327099562\n",
      "=== epoch:295, train acc:0.64, test acc:0.5228 ===\n",
      "train loss:1.3619782340113162\n",
      "train loss:1.3302484515108963\n",
      "train loss:1.3913262907369588\n",
      "=== epoch:296, train acc:0.6433333333333333, test acc:0.5259 ===\n",
      "train loss:1.4949617509875197\n",
      "train loss:1.4131518674903818\n",
      "train loss:1.3565958476933302\n",
      "=== epoch:297, train acc:0.64, test acc:0.5261 ===\n",
      "train loss:1.2329657698473375\n",
      "train loss:1.2685285528345362\n",
      "train loss:1.331318243639174\n",
      "=== epoch:298, train acc:0.6466666666666666, test acc:0.5266 ===\n",
      "train loss:1.4572919729158569\n",
      "train loss:1.2994155618637293\n",
      "train loss:1.4092441854148898\n",
      "=== epoch:299, train acc:0.6466666666666666, test acc:0.531 ===\n",
      "train loss:1.1992382098316323\n",
      "train loss:1.3897641489524617\n",
      "train loss:1.3473542684533217\n",
      "=== epoch:300, train acc:0.6466666666666666, test acc:0.5285 ===\n",
      "train loss:1.2655536051249152\n",
      "train loss:1.4555307194004272\n",
      "train loss:1.4098315446518024\n",
      "=== epoch:301, train acc:0.6466666666666666, test acc:0.5281 ===\n",
      "train loss:1.3734766399449354\n",
      "train loss:1.2088179290346939\n",
      "train loss:1.348177708554732\n",
      "=== epoch:302, train acc:0.6466666666666666, test acc:0.5282 ===\n",
      "train loss:1.3134407630102531\n",
      "train loss:1.4339966277118206\n",
      "train loss:1.4336500458171662\n",
      "=== epoch:303, train acc:0.6433333333333333, test acc:0.5317 ===\n",
      "train loss:1.2811793858061253\n",
      "train loss:1.276626378036971\n",
      "train loss:1.2944204317726968\n",
      "=== epoch:304, train acc:0.65, test acc:0.5357 ===\n",
      "train loss:1.4197074463918253\n",
      "train loss:1.2239227649909794\n",
      "train loss:1.4065005718906765\n",
      "=== epoch:305, train acc:0.65, test acc:0.5394 ===\n",
      "train loss:1.2147940935084218\n",
      "train loss:1.304323520267043\n",
      "train loss:1.2547481981464792\n",
      "=== epoch:306, train acc:0.66, test acc:0.5401 ===\n",
      "train loss:1.2280621162574257\n",
      "train loss:1.348926291845099\n",
      "train loss:1.189421407998718\n",
      "=== epoch:307, train acc:0.6633333333333333, test acc:0.544 ===\n",
      "train loss:1.2331093984700379\n",
      "train loss:1.2990226438336694\n",
      "train loss:1.3223862024988013\n",
      "=== epoch:308, train acc:0.67, test acc:0.5448 ===\n",
      "train loss:1.254749361378746\n",
      "train loss:1.2192611824708555\n",
      "train loss:1.2247882873518772\n",
      "=== epoch:309, train acc:0.6566666666666666, test acc:0.5427 ===\n",
      "train loss:1.1997919440468234\n",
      "train loss:1.250351832213198\n",
      "train loss:1.288040059914418\n",
      "=== epoch:310, train acc:0.66, test acc:0.5394 ===\n",
      "train loss:1.2468328533729476\n",
      "train loss:1.2640019784173198\n",
      "train loss:1.2711138927969068\n",
      "=== epoch:311, train acc:0.6566666666666666, test acc:0.5377 ===\n",
      "train loss:1.303677232948963\n",
      "train loss:1.2340026404394628\n",
      "train loss:1.234579884657696\n",
      "=== epoch:312, train acc:0.6566666666666666, test acc:0.5367 ===\n",
      "train loss:1.2727419675884237\n",
      "train loss:1.3280132987285755\n",
      "train loss:1.2974298274660392\n",
      "=== epoch:313, train acc:0.6566666666666666, test acc:0.5347 ===\n",
      "train loss:1.2794183033092188\n",
      "train loss:1.3098229654965903\n",
      "train loss:1.2413457973545028\n",
      "=== epoch:314, train acc:0.66, test acc:0.5404 ===\n",
      "train loss:1.2971877704882955\n",
      "train loss:1.0999699863622923\n",
      "train loss:1.354504503789874\n",
      "=== epoch:315, train acc:0.66, test acc:0.5406 ===\n",
      "train loss:1.239045495099138\n",
      "train loss:1.1630797055507593\n",
      "train loss:1.1919572410174901\n",
      "=== epoch:316, train acc:0.65, test acc:0.5395 ===\n",
      "train loss:1.277763293022727\n",
      "train loss:1.192779058960879\n",
      "train loss:1.2374942775312021\n",
      "=== epoch:317, train acc:0.66, test acc:0.544 ===\n",
      "train loss:1.0684235450650847\n",
      "train loss:1.1821766071331228\n",
      "train loss:1.2687452126867753\n",
      "=== epoch:318, train acc:0.66, test acc:0.5447 ===\n",
      "train loss:1.2290490537024958\n",
      "train loss:1.069681854449805\n",
      "train loss:1.1944689266943598\n",
      "=== epoch:319, train acc:0.6633333333333333, test acc:0.5469 ===\n",
      "train loss:1.1245986709785731\n",
      "train loss:1.3023247341810222\n",
      "train loss:1.2862769132673286\n",
      "=== epoch:320, train acc:0.67, test acc:0.5482 ===\n",
      "train loss:1.2653507532703017\n",
      "train loss:1.3006981876331773\n",
      "train loss:1.1879256888767626\n",
      "=== epoch:321, train acc:0.6733333333333333, test acc:0.5539 ===\n",
      "train loss:1.1094998471501112\n",
      "train loss:1.2176062755789676\n",
      "train loss:1.3360931316557794\n",
      "=== epoch:322, train acc:0.6833333333333333, test acc:0.5564 ===\n",
      "train loss:1.1686516484584673\n",
      "train loss:1.181505185417371\n",
      "train loss:1.1262631748614043\n",
      "=== epoch:323, train acc:0.6833333333333333, test acc:0.5633 ===\n",
      "train loss:1.0848697712737014\n",
      "train loss:1.167440760617158\n",
      "train loss:1.249551322170732\n",
      "=== epoch:324, train acc:0.6833333333333333, test acc:0.563 ===\n",
      "train loss:1.2333907871074856\n",
      "train loss:1.0695808860655096\n",
      "train loss:1.2089450913556208\n",
      "=== epoch:325, train acc:0.6966666666666667, test acc:0.5669 ===\n",
      "train loss:1.3378032057825147\n",
      "train loss:1.1463193657198383\n",
      "train loss:1.1570809390004486\n",
      "=== epoch:326, train acc:0.7066666666666667, test acc:0.5689 ===\n",
      "train loss:1.053169613718103\n",
      "train loss:1.0431273237590468\n",
      "train loss:1.1353737482194826\n",
      "=== epoch:327, train acc:0.72, test acc:0.5715 ===\n",
      "train loss:1.1392442904023548\n",
      "train loss:1.0843784685827205\n",
      "train loss:1.1565781523416003\n",
      "=== epoch:328, train acc:0.71, test acc:0.5757 ===\n",
      "train loss:1.0390075487021282\n",
      "train loss:1.1882734387241494\n",
      "train loss:1.2025533742022254\n",
      "=== epoch:329, train acc:0.7166666666666667, test acc:0.5748 ===\n",
      "train loss:1.1288566662099253\n",
      "train loss:1.1654377932084696\n",
      "train loss:1.1754957948873415\n",
      "=== epoch:330, train acc:0.72, test acc:0.5765 ===\n",
      "train loss:1.3638951312737746\n",
      "train loss:1.18182289280782\n",
      "train loss:1.17327425905078\n",
      "=== epoch:331, train acc:0.71, test acc:0.5747 ===\n",
      "train loss:1.1854794178079497\n",
      "train loss:1.1192411214041835\n",
      "train loss:1.166966244864156\n",
      "=== epoch:332, train acc:0.72, test acc:0.5749 ===\n",
      "train loss:1.2235557721616914\n",
      "train loss:1.2074504305781346\n",
      "train loss:1.0435512046459055\n",
      "=== epoch:333, train acc:0.7233333333333334, test acc:0.5783 ===\n",
      "train loss:1.183320110636405\n",
      "train loss:1.0642508598136224\n",
      "train loss:1.0201563651051802\n",
      "=== epoch:334, train acc:0.7266666666666667, test acc:0.5818 ===\n",
      "train loss:0.9475192401853195\n",
      "train loss:1.0881706003126896\n",
      "train loss:1.2079916213875344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:335, train acc:0.7266666666666667, test acc:0.5844 ===\n",
      "train loss:1.1086115105737449\n",
      "train loss:1.2061339179495203\n",
      "train loss:1.0649039249102175\n",
      "=== epoch:336, train acc:0.73, test acc:0.5857 ===\n",
      "train loss:1.061871159851841\n",
      "train loss:1.0633906646288716\n",
      "train loss:1.014919393506745\n",
      "=== epoch:337, train acc:0.7266666666666667, test acc:0.5848 ===\n",
      "train loss:1.1307494382480572\n",
      "train loss:1.0925488798293346\n",
      "train loss:1.187800586325223\n",
      "=== epoch:338, train acc:0.7333333333333333, test acc:0.5891 ===\n",
      "train loss:1.0894950777992432\n",
      "train loss:1.087525399401003\n",
      "train loss:1.1564140391377757\n",
      "=== epoch:339, train acc:0.7366666666666667, test acc:0.5934 ===\n",
      "train loss:0.9923674010248227\n",
      "train loss:1.170829632597962\n",
      "train loss:1.0435852876975773\n",
      "=== epoch:340, train acc:0.7333333333333333, test acc:0.5928 ===\n",
      "train loss:1.112583167037923\n",
      "train loss:1.18471431339261\n",
      "train loss:1.1139717777435643\n",
      "=== epoch:341, train acc:0.7433333333333333, test acc:0.5966 ===\n",
      "train loss:0.9891523642718982\n",
      "train loss:1.1068694777023353\n",
      "train loss:1.1294244645092057\n",
      "=== epoch:342, train acc:0.75, test acc:0.5978 ===\n",
      "train loss:1.123578926578312\n",
      "train loss:1.1042466588923117\n",
      "train loss:1.1434601152444563\n",
      "=== epoch:343, train acc:0.7533333333333333, test acc:0.6043 ===\n",
      "train loss:1.0501689696054743\n",
      "train loss:1.075296581412152\n",
      "train loss:1.0363390897979463\n",
      "=== epoch:344, train acc:0.7533333333333333, test acc:0.6041 ===\n",
      "train loss:0.8859362014659264\n",
      "train loss:1.0090259769746133\n",
      "train loss:1.0532098502877394\n",
      "=== epoch:345, train acc:0.7566666666666667, test acc:0.599 ===\n",
      "train loss:1.071263600282387\n",
      "train loss:1.1259556594138846\n",
      "train loss:1.0790741539686315\n",
      "=== epoch:346, train acc:0.7566666666666667, test acc:0.5986 ===\n",
      "train loss:0.9623270705851581\n",
      "train loss:0.9481837713227034\n",
      "train loss:1.1184577682245216\n",
      "=== epoch:347, train acc:0.76, test acc:0.5975 ===\n",
      "train loss:1.0065305352975091\n",
      "train loss:1.0107689958664183\n",
      "train loss:1.0643673100524005\n",
      "=== epoch:348, train acc:0.7633333333333333, test acc:0.6041 ===\n",
      "train loss:1.0643957887822166\n",
      "train loss:0.9792969423887815\n",
      "train loss:1.0236008891553245\n",
      "=== epoch:349, train acc:0.76, test acc:0.6054 ===\n",
      "train loss:1.065254072001334\n",
      "train loss:1.0097050998082961\n",
      "train loss:1.0039476113010513\n",
      "=== epoch:350, train acc:0.7533333333333333, test acc:0.6014 ===\n",
      "train loss:1.0972411188394597\n",
      "train loss:0.9533000982796566\n",
      "train loss:1.0224566705548095\n",
      "=== epoch:351, train acc:0.76, test acc:0.6059 ===\n",
      "train loss:1.031458338096757\n",
      "train loss:1.008475776946907\n",
      "train loss:0.9452192763893253\n",
      "=== epoch:352, train acc:0.75, test acc:0.6036 ===\n",
      "train loss:0.9169325430822886\n",
      "train loss:0.9160556092221028\n",
      "train loss:1.0130319792208897\n",
      "=== epoch:353, train acc:0.7533333333333333, test acc:0.6011 ===\n",
      "train loss:0.9247295097473939\n",
      "train loss:1.0293247553956142\n",
      "train loss:1.0285289247407556\n",
      "=== epoch:354, train acc:0.7633333333333333, test acc:0.6012 ===\n",
      "train loss:0.9696572888378061\n",
      "train loss:0.9191474911250294\n",
      "train loss:1.1263509617832637\n",
      "=== epoch:355, train acc:0.7533333333333333, test acc:0.6033 ===\n",
      "train loss:1.0331572194068182\n",
      "train loss:0.9632209864203527\n",
      "train loss:0.9133008900464799\n",
      "=== epoch:356, train acc:0.76, test acc:0.6076 ===\n",
      "train loss:1.0325116851580036\n",
      "train loss:0.9066326945104793\n",
      "train loss:0.9690064726598522\n",
      "=== epoch:357, train acc:0.7533333333333333, test acc:0.6022 ===\n",
      "train loss:1.0258979384486042\n",
      "train loss:1.017122170372742\n",
      "train loss:0.8690979778959063\n",
      "=== epoch:358, train acc:0.7566666666666667, test acc:0.6058 ===\n",
      "train loss:0.9992421399493636\n",
      "train loss:0.7959089757995019\n",
      "train loss:0.9136677571511603\n",
      "=== epoch:359, train acc:0.76, test acc:0.6071 ===\n",
      "train loss:1.0513543873876967\n",
      "train loss:0.9767245492840495\n",
      "train loss:1.010831018334971\n",
      "=== epoch:360, train acc:0.7633333333333333, test acc:0.6074 ===\n",
      "train loss:0.97870387864416\n",
      "train loss:0.9625810336467076\n",
      "train loss:1.05457901411191\n",
      "=== epoch:361, train acc:0.77, test acc:0.6078 ===\n",
      "train loss:1.0408278640918724\n",
      "train loss:1.0986759542374942\n",
      "train loss:0.9963189906430856\n",
      "=== epoch:362, train acc:0.7733333333333333, test acc:0.6107 ===\n",
      "train loss:0.8370853410543104\n",
      "train loss:0.8620970526938456\n",
      "train loss:0.9623993215389882\n",
      "=== epoch:363, train acc:0.77, test acc:0.6097 ===\n",
      "train loss:0.9942889306480961\n",
      "train loss:0.9055602589421263\n",
      "train loss:0.8744641398655304\n",
      "=== epoch:364, train acc:0.78, test acc:0.6151 ===\n",
      "train loss:0.9008704752882275\n",
      "train loss:0.9799664381892818\n",
      "train loss:0.9911853246679558\n",
      "=== epoch:365, train acc:0.7766666666666666, test acc:0.6176 ===\n",
      "train loss:0.9588029228445558\n",
      "train loss:0.9646862414862306\n",
      "train loss:0.9261032476751292\n",
      "=== epoch:366, train acc:0.78, test acc:0.6179 ===\n",
      "train loss:1.0017705048374888\n",
      "train loss:0.7769163512025966\n",
      "train loss:0.9548442599198569\n",
      "=== epoch:367, train acc:0.76, test acc:0.6144 ===\n",
      "train loss:1.0726977264913644\n",
      "train loss:0.9909188424967341\n",
      "train loss:0.8237105122296887\n",
      "=== epoch:368, train acc:0.77, test acc:0.614 ===\n",
      "train loss:0.9241030549658464\n",
      "train loss:0.8329180484837599\n",
      "train loss:0.9626332133588223\n",
      "=== epoch:369, train acc:0.78, test acc:0.6175 ===\n",
      "train loss:0.9360978043213949\n",
      "train loss:0.7988734686593076\n",
      "train loss:0.9125608425678093\n",
      "=== epoch:370, train acc:0.7833333333333333, test acc:0.6177 ===\n",
      "train loss:0.8981308157394123\n",
      "train loss:0.823169616267386\n",
      "train loss:0.9231452925082716\n",
      "=== epoch:371, train acc:0.78, test acc:0.6159 ===\n",
      "train loss:0.841043433830223\n",
      "train loss:0.8485542340538926\n",
      "train loss:0.8056409599556588\n",
      "=== epoch:372, train acc:0.7866666666666666, test acc:0.616 ===\n",
      "train loss:0.8327710176247198\n",
      "train loss:0.9509424654916425\n",
      "train loss:0.9308055239487478\n",
      "=== epoch:373, train acc:0.78, test acc:0.6197 ===\n",
      "train loss:0.8873562855403029\n",
      "train loss:0.9861209499559463\n",
      "train loss:0.8412418910983241\n",
      "=== epoch:374, train acc:0.7866666666666666, test acc:0.6221 ===\n",
      "train loss:0.9774280104882337\n",
      "train loss:0.8059231724413175\n",
      "train loss:0.8759524793749024\n",
      "=== epoch:375, train acc:0.79, test acc:0.6215 ===\n",
      "train loss:0.934922132012492\n",
      "train loss:0.7879731475988961\n",
      "train loss:0.8317602960352167\n",
      "=== epoch:376, train acc:0.7833333333333333, test acc:0.6221 ===\n",
      "train loss:0.9470174156865826\n",
      "train loss:0.8174437449971134\n",
      "train loss:0.8685714528641948\n",
      "=== epoch:377, train acc:0.7966666666666666, test acc:0.6229 ===\n",
      "train loss:0.8656727585326077\n",
      "train loss:0.8151168671307387\n",
      "train loss:0.8428655846662125\n",
      "=== epoch:378, train acc:0.7833333333333333, test acc:0.6227 ===\n",
      "train loss:0.8882980056466504\n",
      "train loss:0.8026388278095312\n",
      "train loss:0.7026199806298823\n",
      "=== epoch:379, train acc:0.79, test acc:0.6265 ===\n",
      "train loss:0.8122101045411069\n",
      "train loss:0.9338473498823615\n",
      "train loss:0.8093222034131214\n",
      "=== epoch:380, train acc:0.7866666666666666, test acc:0.627 ===\n",
      "train loss:0.9589022126558895\n",
      "train loss:0.8505885460926002\n",
      "train loss:0.7693729998475146\n",
      "=== epoch:381, train acc:0.7833333333333333, test acc:0.6257 ===\n",
      "train loss:0.8297181063639356\n",
      "train loss:0.858329025456383\n",
      "train loss:0.9039748345536573\n",
      "=== epoch:382, train acc:0.79, test acc:0.6241 ===\n",
      "train loss:0.8425727753931785\n",
      "train loss:0.8422863760762556\n",
      "train loss:0.8140094974983266\n",
      "=== epoch:383, train acc:0.79, test acc:0.6256 ===\n",
      "train loss:0.810591371613248\n",
      "train loss:0.7574321029594084\n",
      "train loss:0.9027972629439235\n",
      "=== epoch:384, train acc:0.7833333333333333, test acc:0.6278 ===\n",
      "train loss:0.734621385222784\n",
      "train loss:0.6938760130793485\n",
      "train loss:0.8524233134079258\n",
      "=== epoch:385, train acc:0.7833333333333333, test acc:0.6276 ===\n",
      "train loss:0.87850641422083\n",
      "train loss:0.8273136935719927\n",
      "train loss:0.803977889171011\n",
      "=== epoch:386, train acc:0.79, test acc:0.6281 ===\n",
      "train loss:0.9312704720246485\n",
      "train loss:0.8116911488975166\n",
      "train loss:0.7249385566775259\n",
      "=== epoch:387, train acc:0.7966666666666666, test acc:0.632 ===\n",
      "train loss:0.810445221531863\n",
      "train loss:0.8423128979767744\n",
      "train loss:0.7569826930565137\n",
      "=== epoch:388, train acc:0.79, test acc:0.6344 ===\n",
      "train loss:0.7841105945925456\n",
      "train loss:0.7639869020870623\n",
      "train loss:0.6927145204032371\n",
      "=== epoch:389, train acc:0.7866666666666666, test acc:0.6303 ===\n",
      "train loss:0.822972336888993\n",
      "train loss:0.8434149659475041\n",
      "train loss:0.7652391230864992\n",
      "=== epoch:390, train acc:0.7866666666666666, test acc:0.6299 ===\n",
      "train loss:0.8288314550925184\n",
      "train loss:0.7523038772504513\n",
      "train loss:0.6748987735629645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:391, train acc:0.7966666666666666, test acc:0.6346 ===\n",
      "train loss:0.8387246959959167\n",
      "train loss:0.8600942761972129\n",
      "train loss:0.806419903046344\n",
      "=== epoch:392, train acc:0.8033333333333333, test acc:0.6335 ===\n",
      "train loss:0.7919734646971618\n",
      "train loss:0.7932213532586122\n",
      "train loss:0.7028086342497035\n",
      "=== epoch:393, train acc:0.7933333333333333, test acc:0.6348 ===\n",
      "train loss:0.7472566888501526\n",
      "train loss:0.7477722283698338\n",
      "train loss:0.8033277422630631\n",
      "=== epoch:394, train acc:0.79, test acc:0.6357 ===\n",
      "train loss:0.7430699813351339\n",
      "train loss:0.7098941029299004\n",
      "train loss:0.6824353645249143\n",
      "=== epoch:395, train acc:0.79, test acc:0.6366 ===\n",
      "train loss:0.7481745593223416\n",
      "train loss:0.6578571584743149\n",
      "train loss:0.6385118616342254\n",
      "=== epoch:396, train acc:0.7866666666666666, test acc:0.635 ===\n",
      "train loss:0.7489731054447694\n",
      "train loss:0.9066579961582956\n",
      "train loss:0.6519780113682242\n",
      "=== epoch:397, train acc:0.7966666666666666, test acc:0.638 ===\n",
      "train loss:0.782244847230315\n",
      "train loss:0.6557117716747591\n",
      "train loss:0.7287609016547633\n",
      "=== epoch:398, train acc:0.79, test acc:0.6361 ===\n",
      "train loss:0.6947491262048396\n",
      "train loss:0.7259352965246344\n",
      "train loss:0.6990465634052709\n",
      "=== epoch:399, train acc:0.7933333333333333, test acc:0.6359 ===\n",
      "train loss:0.8504124796905308\n",
      "train loss:0.6323671002947536\n",
      "train loss:0.7680466585842981\n",
      "=== epoch:400, train acc:0.8033333333333333, test acc:0.6363 ===\n",
      "train loss:0.7633899591418135\n",
      "train loss:0.8510452379224382\n",
      "train loss:0.6416826743780204\n",
      "=== epoch:401, train acc:0.81, test acc:0.6398 ===\n",
      "train loss:0.6787212666102724\n",
      "train loss:0.6490887392100211\n",
      "train loss:0.6596630133274678\n",
      "=== epoch:402, train acc:0.8066666666666666, test acc:0.6411 ===\n",
      "train loss:0.7923157194437458\n",
      "train loss:0.7425828772394237\n",
      "train loss:0.7067451805323239\n",
      "=== epoch:403, train acc:0.8066666666666666, test acc:0.6418 ===\n",
      "train loss:0.7333642156078475\n",
      "train loss:0.6591099602605378\n",
      "train loss:0.8067099534305932\n",
      "=== epoch:404, train acc:0.8, test acc:0.6416 ===\n",
      "train loss:0.6634250282995482\n",
      "train loss:0.6409415503932604\n",
      "train loss:0.7699392477912538\n",
      "=== epoch:405, train acc:0.8033333333333333, test acc:0.6414 ===\n",
      "train loss:0.6740744583045872\n",
      "train loss:0.6759331427501261\n",
      "train loss:0.664100284592128\n",
      "=== epoch:406, train acc:0.8066666666666666, test acc:0.6398 ===\n",
      "train loss:0.5655526756065783\n",
      "train loss:0.7632964966347775\n",
      "train loss:0.6202688223139875\n",
      "=== epoch:407, train acc:0.8033333333333333, test acc:0.6399 ===\n",
      "train loss:0.5181901433973917\n",
      "train loss:0.6219285701223028\n",
      "train loss:0.581440434003658\n",
      "=== epoch:408, train acc:0.8, test acc:0.6368 ===\n",
      "train loss:0.6671748558579546\n",
      "train loss:0.6266304443981471\n",
      "train loss:0.7291181019304248\n",
      "=== epoch:409, train acc:0.8, test acc:0.6407 ===\n",
      "train loss:0.6927565373575871\n",
      "train loss:0.7702083367929042\n",
      "train loss:0.7507676242192077\n",
      "=== epoch:410, train acc:0.8033333333333333, test acc:0.6438 ===\n",
      "train loss:0.7895398476460797\n",
      "train loss:0.7010973613367508\n",
      "train loss:0.7777171744415896\n",
      "=== epoch:411, train acc:0.7966666666666666, test acc:0.6438 ===\n",
      "train loss:0.6337553738695285\n",
      "train loss:0.7109560541740536\n",
      "train loss:0.7532629321775217\n",
      "=== epoch:412, train acc:0.8066666666666666, test acc:0.6454 ===\n",
      "train loss:0.7486993319187006\n",
      "train loss:0.6252506870102675\n",
      "train loss:0.561684315765982\n",
      "=== epoch:413, train acc:0.81, test acc:0.6483 ===\n",
      "train loss:0.5629244415712947\n",
      "train loss:0.6659171520155489\n",
      "train loss:0.7271852511849566\n",
      "=== epoch:414, train acc:0.8133333333333334, test acc:0.6492 ===\n",
      "train loss:0.5790159870220343\n",
      "train loss:0.689606097390829\n",
      "train loss:0.6343505799595097\n",
      "=== epoch:415, train acc:0.8133333333333334, test acc:0.6489 ===\n",
      "train loss:0.6532318596789598\n",
      "train loss:0.811300213552022\n",
      "train loss:0.6366718471909772\n",
      "=== epoch:416, train acc:0.81, test acc:0.6489 ===\n",
      "train loss:0.703890438488867\n",
      "train loss:0.7333804473881466\n",
      "train loss:0.7050901887020192\n",
      "=== epoch:417, train acc:0.8066666666666666, test acc:0.6488 ===\n",
      "train loss:0.7440040228850249\n",
      "train loss:0.7058833010976356\n",
      "train loss:0.7051167333676096\n",
      "=== epoch:418, train acc:0.8, test acc:0.651 ===\n",
      "train loss:0.7287708669244359\n",
      "train loss:0.7197708020537017\n",
      "train loss:0.5569643733510722\n",
      "=== epoch:419, train acc:0.8133333333333334, test acc:0.6532 ===\n",
      "train loss:0.6361730100407843\n",
      "train loss:0.6880336672963544\n",
      "train loss:0.7175999570468343\n",
      "=== epoch:420, train acc:0.8133333333333334, test acc:0.6527 ===\n",
      "train loss:0.7347185244855275\n",
      "train loss:0.7185363939152702\n",
      "train loss:0.6526472552057356\n",
      "=== epoch:421, train acc:0.8266666666666667, test acc:0.6556 ===\n",
      "train loss:0.7217659547645993\n",
      "train loss:0.6756985828390062\n",
      "train loss:0.6947261996309099\n",
      "=== epoch:422, train acc:0.82, test acc:0.6555 ===\n",
      "train loss:0.5789645204772672\n",
      "train loss:0.6401332497777246\n",
      "train loss:0.5387803719440453\n",
      "=== epoch:423, train acc:0.82, test acc:0.6537 ===\n",
      "train loss:0.5739533107717841\n",
      "train loss:0.587403251839635\n",
      "train loss:0.49968678486956686\n",
      "=== epoch:424, train acc:0.82, test acc:0.656 ===\n",
      "train loss:0.6887903602764404\n",
      "train loss:0.6867241183033689\n",
      "train loss:0.8551913085454125\n",
      "=== epoch:425, train acc:0.8266666666666667, test acc:0.6577 ===\n",
      "train loss:0.626241342119245\n",
      "train loss:0.6844740216822963\n",
      "train loss:0.6432937948805189\n",
      "=== epoch:426, train acc:0.8266666666666667, test acc:0.6577 ===\n",
      "train loss:0.5817133207759321\n",
      "train loss:0.4960255915069544\n",
      "train loss:0.5030790141179076\n",
      "=== epoch:427, train acc:0.82, test acc:0.6583 ===\n",
      "train loss:0.6040095644930108\n",
      "train loss:0.6313649754867627\n",
      "train loss:0.6012140551052859\n",
      "=== epoch:428, train acc:0.8233333333333334, test acc:0.6583 ===\n",
      "train loss:0.6304475263760071\n",
      "train loss:0.5669782362527193\n",
      "train loss:0.5540959936520337\n",
      "=== epoch:429, train acc:0.82, test acc:0.6574 ===\n",
      "train loss:0.5708196790844127\n",
      "train loss:0.6253518665607035\n",
      "train loss:0.5841353842141769\n",
      "=== epoch:430, train acc:0.8266666666666667, test acc:0.6584 ===\n",
      "train loss:0.6517769574460707\n",
      "train loss:0.578159121945633\n",
      "train loss:0.5805570810386979\n",
      "=== epoch:431, train acc:0.8166666666666667, test acc:0.6545 ===\n",
      "train loss:0.5920755492456025\n",
      "train loss:0.5584007617671913\n",
      "train loss:0.5823906719340151\n",
      "=== epoch:432, train acc:0.8233333333333334, test acc:0.6582 ===\n",
      "train loss:0.6861395818111566\n",
      "train loss:0.6931551524431849\n",
      "train loss:0.5435578330753591\n",
      "=== epoch:433, train acc:0.83, test acc:0.6605 ===\n",
      "train loss:0.4898902857748538\n",
      "train loss:0.5649868814002397\n",
      "train loss:0.6667511310878642\n",
      "=== epoch:434, train acc:0.83, test acc:0.6574 ===\n",
      "train loss:0.5868676832263923\n",
      "train loss:0.6223520236166563\n",
      "train loss:0.6523424385597443\n",
      "=== epoch:435, train acc:0.8266666666666667, test acc:0.6566 ===\n",
      "train loss:0.4918533995944013\n",
      "train loss:0.6172734716044929\n",
      "train loss:0.5823961854064044\n",
      "=== epoch:436, train acc:0.83, test acc:0.6609 ===\n",
      "train loss:0.5896388361786921\n",
      "train loss:0.5551885876928874\n",
      "train loss:0.6014154002299466\n",
      "=== epoch:437, train acc:0.8333333333333334, test acc:0.6631 ===\n",
      "train loss:0.5242329536570406\n",
      "train loss:0.6382171907092133\n",
      "train loss:0.5945681180627601\n",
      "=== epoch:438, train acc:0.8333333333333334, test acc:0.6626 ===\n",
      "train loss:0.5488361191119128\n",
      "train loss:0.47552087668371196\n",
      "train loss:0.5196760286804663\n",
      "=== epoch:439, train acc:0.84, test acc:0.6636 ===\n",
      "train loss:0.6554116236320847\n",
      "train loss:0.7182046031861863\n",
      "train loss:0.7045500742486961\n",
      "=== epoch:440, train acc:0.8466666666666667, test acc:0.6656 ===\n",
      "train loss:0.6034987283663328\n",
      "train loss:0.5715579913215543\n",
      "train loss:0.612163954225225\n",
      "=== epoch:441, train acc:0.8533333333333334, test acc:0.6693 ===\n",
      "train loss:0.5128325300323043\n",
      "train loss:0.5941151262494858\n",
      "train loss:0.6216917193968782\n",
      "=== epoch:442, train acc:0.85, test acc:0.6688 ===\n",
      "train loss:0.6241177838817019\n",
      "train loss:0.5712127319575654\n",
      "train loss:0.5821743824654981\n",
      "=== epoch:443, train acc:0.8433333333333334, test acc:0.667 ===\n",
      "train loss:0.620292492238982\n",
      "train loss:0.5890956935879609\n",
      "train loss:0.5385317588559739\n",
      "=== epoch:444, train acc:0.8533333333333334, test acc:0.6702 ===\n",
      "train loss:0.6424479596321281\n",
      "train loss:0.6666741214222303\n",
      "train loss:0.387790079686156\n",
      "=== epoch:445, train acc:0.85, test acc:0.6691 ===\n",
      "train loss:0.5694589494293993\n",
      "train loss:0.4429267134895129\n",
      "train loss:0.637130662966363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:446, train acc:0.8533333333333334, test acc:0.6697 ===\n",
      "train loss:0.6328191598757669\n",
      "train loss:0.6205318896046795\n",
      "train loss:0.5255056981953764\n",
      "=== epoch:447, train acc:0.8533333333333334, test acc:0.6722 ===\n",
      "train loss:0.6256147251486358\n",
      "train loss:0.5749479241920499\n",
      "train loss:0.5683955240214742\n",
      "=== epoch:448, train acc:0.8533333333333334, test acc:0.6744 ===\n",
      "train loss:0.5894827136767241\n",
      "train loss:0.48726576935719373\n",
      "train loss:0.5359766627368466\n",
      "=== epoch:449, train acc:0.8566666666666667, test acc:0.6731 ===\n",
      "train loss:0.5250407798785119\n",
      "train loss:0.4321894438574627\n",
      "train loss:0.542166731978522\n",
      "=== epoch:450, train acc:0.86, test acc:0.6751 ===\n",
      "train loss:0.4280952105852267\n",
      "train loss:0.5601847036820028\n",
      "train loss:0.4529248469311055\n",
      "=== epoch:451, train acc:0.8566666666666667, test acc:0.6748 ===\n",
      "train loss:0.5569119369999169\n",
      "train loss:0.4703057221831612\n",
      "train loss:0.5115218034477433\n",
      "=== epoch:452, train acc:0.8533333333333334, test acc:0.6742 ===\n",
      "train loss:0.5022923140427724\n",
      "train loss:0.4795954959863416\n",
      "train loss:0.4923893931248476\n",
      "=== epoch:453, train acc:0.8533333333333334, test acc:0.6746 ===\n",
      "train loss:0.3626789830567369\n",
      "train loss:0.5591269827636774\n",
      "train loss:0.4994460226962085\n",
      "=== epoch:454, train acc:0.8566666666666667, test acc:0.6754 ===\n",
      "train loss:0.5324457579023106\n",
      "train loss:0.5966540761467977\n",
      "train loss:0.5718453929804902\n",
      "=== epoch:455, train acc:0.86, test acc:0.6781 ===\n",
      "train loss:0.6713432665494794\n",
      "train loss:0.6504922455237611\n",
      "train loss:0.6023821565291596\n",
      "=== epoch:456, train acc:0.8633333333333333, test acc:0.6784 ===\n",
      "train loss:0.6416141331153945\n",
      "train loss:0.5395492670185191\n",
      "train loss:0.4320212257391931\n",
      "=== epoch:457, train acc:0.8566666666666667, test acc:0.6795 ===\n",
      "train loss:0.5000263619204335\n",
      "train loss:0.5254863106807393\n",
      "train loss:0.5479477926352244\n",
      "=== epoch:458, train acc:0.86, test acc:0.6768 ===\n",
      "train loss:0.45380167093721335\n",
      "train loss:0.5616325228334778\n",
      "train loss:0.493974781835378\n",
      "=== epoch:459, train acc:0.8566666666666667, test acc:0.6799 ===\n",
      "train loss:0.5247844106503821\n",
      "train loss:0.4894675019734883\n",
      "train loss:0.5754071977681423\n",
      "=== epoch:460, train acc:0.8566666666666667, test acc:0.6766 ===\n",
      "train loss:0.4842654777441347\n",
      "train loss:0.5668776266644535\n",
      "train loss:0.48705898498488104\n",
      "=== epoch:461, train acc:0.8633333333333333, test acc:0.6749 ===\n",
      "train loss:0.5681030931288641\n",
      "train loss:0.5864444312776206\n",
      "train loss:0.6158997805930644\n",
      "=== epoch:462, train acc:0.8633333333333333, test acc:0.6763 ===\n",
      "train loss:0.4659219343043317\n",
      "train loss:0.5711748521770749\n",
      "train loss:0.5660197587321598\n",
      "=== epoch:463, train acc:0.8566666666666667, test acc:0.6777 ===\n",
      "train loss:0.4806336607212661\n",
      "train loss:0.49686642313499774\n",
      "train loss:0.5035646828990823\n",
      "=== epoch:464, train acc:0.8633333333333333, test acc:0.6803 ===\n",
      "train loss:0.6297288137208927\n",
      "train loss:0.5242711930416163\n",
      "train loss:0.3609954758938471\n",
      "=== epoch:465, train acc:0.8566666666666667, test acc:0.6827 ===\n",
      "train loss:0.4226342346667483\n",
      "train loss:0.5111775705796741\n",
      "train loss:0.4943973019851064\n",
      "=== epoch:466, train acc:0.86, test acc:0.68 ===\n",
      "train loss:0.42746295219438707\n",
      "train loss:0.4910128602059264\n",
      "train loss:0.44986809623482615\n",
      "=== epoch:467, train acc:0.8633333333333333, test acc:0.6826 ===\n",
      "train loss:0.48826830827836715\n",
      "train loss:0.5501032238732553\n",
      "train loss:0.5502328186636182\n",
      "=== epoch:468, train acc:0.8633333333333333, test acc:0.6828 ===\n",
      "train loss:0.5006229613019495\n",
      "train loss:0.4706442953872206\n",
      "train loss:0.4687220895925154\n",
      "=== epoch:469, train acc:0.8633333333333333, test acc:0.6829 ===\n",
      "train loss:0.4525160087797083\n",
      "train loss:0.480212337171372\n",
      "train loss:0.4001800532748877\n",
      "=== epoch:470, train acc:0.8633333333333333, test acc:0.6845 ===\n",
      "train loss:0.4483872562486104\n",
      "train loss:0.5495516756197592\n",
      "train loss:0.47857893705438537\n",
      "=== epoch:471, train acc:0.8633333333333333, test acc:0.682 ===\n",
      "train loss:0.4084987514616048\n",
      "train loss:0.5102685404389374\n",
      "train loss:0.4687776750509966\n",
      "=== epoch:472, train acc:0.8666666666666667, test acc:0.6837 ===\n",
      "train loss:0.4122213003603889\n",
      "train loss:0.30630987429733314\n",
      "train loss:0.46652570380087377\n",
      "=== epoch:473, train acc:0.87, test acc:0.6828 ===\n",
      "train loss:0.4594424922346233\n",
      "train loss:0.3995773531745852\n",
      "train loss:0.4941090685354423\n",
      "=== epoch:474, train acc:0.87, test acc:0.6818 ===\n",
      "train loss:0.5381142858950146\n",
      "train loss:0.5308228381442307\n",
      "train loss:0.47621870725968357\n",
      "=== epoch:475, train acc:0.8766666666666667, test acc:0.6842 ===\n",
      "train loss:0.4577243180045075\n",
      "train loss:0.5189434323171774\n",
      "train loss:0.4592315729384614\n",
      "=== epoch:476, train acc:0.88, test acc:0.6847 ===\n",
      "train loss:0.45968571827233645\n",
      "train loss:0.412895486796388\n",
      "train loss:0.44967823955093805\n",
      "=== epoch:477, train acc:0.8633333333333333, test acc:0.6848 ===\n",
      "train loss:0.490656280632299\n",
      "train loss:0.4661074930866112\n",
      "train loss:0.4845045396293872\n",
      "=== epoch:478, train acc:0.8666666666666667, test acc:0.6875 ===\n",
      "train loss:0.4563143938529493\n",
      "train loss:0.5532553149904887\n",
      "train loss:0.46020487781554176\n",
      "=== epoch:479, train acc:0.8766666666666667, test acc:0.6874 ===\n",
      "train loss:0.5011328002432718\n",
      "train loss:0.40648292755505433\n",
      "train loss:0.482760699134009\n",
      "=== epoch:480, train acc:0.8766666666666667, test acc:0.6856 ===\n",
      "train loss:0.5688231718430082\n",
      "train loss:0.4227855876150759\n",
      "train loss:0.4157039903272563\n",
      "=== epoch:481, train acc:0.8766666666666667, test acc:0.6883 ===\n",
      "train loss:0.46979752946117637\n",
      "train loss:0.38121751634042406\n",
      "train loss:0.4969966586360763\n",
      "=== epoch:482, train acc:0.87, test acc:0.6885 ===\n",
      "train loss:0.4135469221912724\n",
      "train loss:0.42275728807353047\n",
      "train loss:0.5622021934778022\n",
      "=== epoch:483, train acc:0.8733333333333333, test acc:0.6867 ===\n",
      "train loss:0.5260763952972959\n",
      "train loss:0.47365244528254413\n",
      "train loss:0.4387415166055304\n",
      "=== epoch:484, train acc:0.8766666666666667, test acc:0.6896 ===\n",
      "train loss:0.40202841081991986\n",
      "train loss:0.46584133741654166\n",
      "train loss:0.4125717375889646\n",
      "=== epoch:485, train acc:0.88, test acc:0.688 ===\n",
      "train loss:0.39420209991113386\n",
      "train loss:0.46773741964893156\n",
      "train loss:0.4725198794915956\n",
      "=== epoch:486, train acc:0.8666666666666667, test acc:0.6881 ===\n",
      "train loss:0.4565000186183142\n",
      "train loss:0.3651884071256991\n",
      "train loss:0.3352577866928843\n",
      "=== epoch:487, train acc:0.8733333333333333, test acc:0.6877 ===\n",
      "train loss:0.4342603131629374\n",
      "train loss:0.5074300820150666\n",
      "train loss:0.41955727072628074\n",
      "=== epoch:488, train acc:0.8733333333333333, test acc:0.6899 ===\n",
      "train loss:0.5037136564219903\n",
      "train loss:0.4983832497015954\n",
      "train loss:0.46556360852468404\n",
      "=== epoch:489, train acc:0.8766666666666667, test acc:0.691 ===\n",
      "train loss:0.3540822161203077\n",
      "train loss:0.4200879850418793\n",
      "train loss:0.436197940819307\n",
      "=== epoch:490, train acc:0.8766666666666667, test acc:0.6912 ===\n",
      "train loss:0.4678198471967868\n",
      "train loss:0.3998079803381195\n",
      "train loss:0.3998923048031598\n",
      "=== epoch:491, train acc:0.8766666666666667, test acc:0.6891 ===\n",
      "train loss:0.4814813932430361\n",
      "train loss:0.4667429883510054\n",
      "train loss:0.33120863530671035\n",
      "=== epoch:492, train acc:0.8833333333333333, test acc:0.6905 ===\n",
      "train loss:0.4009420685657686\n",
      "train loss:0.36415424248505274\n",
      "train loss:0.4220363318177281\n",
      "=== epoch:493, train acc:0.8866666666666667, test acc:0.6921 ===\n",
      "train loss:0.4588851918798933\n",
      "train loss:0.5115423003465172\n",
      "train loss:0.5621369564404248\n",
      "=== epoch:494, train acc:0.88, test acc:0.6928 ===\n",
      "train loss:0.5111849228171015\n",
      "train loss:0.3980530454816175\n",
      "train loss:0.5439547983234992\n",
      "=== epoch:495, train acc:0.8833333333333333, test acc:0.6923 ===\n",
      "train loss:0.44609262227047297\n",
      "train loss:0.4796206786005586\n",
      "train loss:0.4444528806929819\n",
      "=== epoch:496, train acc:0.8833333333333333, test acc:0.6917 ===\n",
      "train loss:0.3611347958002685\n",
      "train loss:0.5121592265283892\n",
      "train loss:0.5083402039679038\n",
      "=== epoch:497, train acc:0.8866666666666667, test acc:0.6935 ===\n",
      "train loss:0.4689116032401601\n",
      "train loss:0.3904128124192554\n",
      "train loss:0.3909950588238463\n",
      "=== epoch:498, train acc:0.8833333333333333, test acc:0.6937 ===\n",
      "train loss:0.41813089938706943\n",
      "train loss:0.5532960625930098\n",
      "train loss:0.5159273109049177\n",
      "=== epoch:499, train acc:0.8833333333333333, test acc:0.6959 ===\n",
      "train loss:0.4995186198126701\n",
      "train loss:0.4269667689300337\n",
      "train loss:0.3332656226496371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:500, train acc:0.88, test acc:0.693 ===\n",
      "train loss:0.4874956883760057\n",
      "train loss:0.4187831161338169\n",
      "train loss:0.42088449505943615\n",
      "=== epoch:501, train acc:0.8833333333333333, test acc:0.694 ===\n",
      "train loss:0.4510592070462852\n",
      "train loss:0.3408937702564198\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.696\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "# use_dropout = False  # 드롭아웃을 쓰지 않을 때는 False\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "# num_epochs = 301\n",
    "num_epochs = 501\n",
    "# num_epochs = 1001\n",
    "# num_epochs = 1501\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=num_epochs, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc3eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, color='k', marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, color='r', marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.03)\n",
    "plt.legend(loc='upper left')\n",
    "# plt.legend(loc='lower right')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395bca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
