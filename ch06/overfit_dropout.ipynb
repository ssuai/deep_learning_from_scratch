{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958bd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load overfit_dropout.py\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "def box_off():\n",
    "    ax=plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90788d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.320631098914397\n",
      "=== epoch:1, train acc:0.10666666666666667, test acc:0.1205 ===\n",
      "train loss:2.3149336854206073\n",
      "train loss:2.297650500882185\n",
      "train loss:2.30119198286045\n",
      "=== epoch:2, train acc:0.10666666666666667, test acc:0.1211 ===\n",
      "train loss:2.3425110216037304\n",
      "train loss:2.3180855626968837\n",
      "train loss:2.297491186430444\n",
      "=== epoch:3, train acc:0.10333333333333333, test acc:0.119 ===\n",
      "train loss:2.3088538168971207\n",
      "train loss:2.320121401599766\n",
      "train loss:2.3165716619531254\n",
      "=== epoch:4, train acc:0.10666666666666667, test acc:0.1206 ===\n",
      "train loss:2.29568868507946\n",
      "train loss:2.2928093682534585\n",
      "train loss:2.321622686283053\n",
      "=== epoch:5, train acc:0.10666666666666667, test acc:0.1211 ===\n",
      "train loss:2.298292616000218\n",
      "train loss:2.3018701399387393\n",
      "train loss:2.305369863739413\n",
      "=== epoch:6, train acc:0.10666666666666667, test acc:0.1212 ===\n",
      "train loss:2.3011278612558925\n",
      "train loss:2.2963239726637124\n",
      "train loss:2.3229283371280167\n",
      "=== epoch:7, train acc:0.11, test acc:0.1224 ===\n",
      "train loss:2.3076534840387644\n",
      "train loss:2.3101870720806916\n",
      "train loss:2.3092404348454116\n",
      "=== epoch:8, train acc:0.10666666666666667, test acc:0.123 ===\n",
      "train loss:2.2968143219271\n",
      "train loss:2.3038653902969624\n",
      "train loss:2.3021719982051785\n",
      "=== epoch:9, train acc:0.10666666666666667, test acc:0.1237 ===\n",
      "train loss:2.3195853576713734\n",
      "train loss:2.299321740419983\n",
      "train loss:2.2931741082903048\n",
      "=== epoch:10, train acc:0.10333333333333333, test acc:0.1236 ===\n",
      "train loss:2.3010502816860168\n",
      "train loss:2.287959076618138\n",
      "train loss:2.317651826267915\n",
      "=== epoch:11, train acc:0.10333333333333333, test acc:0.1236 ===\n",
      "train loss:2.295196360592878\n",
      "train loss:2.3141822157416763\n",
      "train loss:2.305122652482166\n",
      "=== epoch:12, train acc:0.10333333333333333, test acc:0.125 ===\n",
      "train loss:2.2908543856663655\n",
      "train loss:2.3103629500079372\n",
      "train loss:2.3097748360115027\n",
      "=== epoch:13, train acc:0.11, test acc:0.1245 ===\n",
      "train loss:2.302970789624678\n",
      "train loss:2.2850206325964946\n",
      "train loss:2.294496871360131\n",
      "=== epoch:14, train acc:0.12, test acc:0.1283 ===\n",
      "train loss:2.2776759096061827\n",
      "train loss:2.2877976160573366\n",
      "train loss:2.307948593692256\n",
      "=== epoch:15, train acc:0.11666666666666667, test acc:0.13 ===\n",
      "train loss:2.2949152943334306\n",
      "train loss:2.3006030590404993\n",
      "train loss:2.2988923035644797\n",
      "=== epoch:16, train acc:0.12666666666666668, test acc:0.1316 ===\n",
      "train loss:2.3173213758509372\n",
      "train loss:2.2958275627542553\n",
      "train loss:2.2954133500824967\n",
      "=== epoch:17, train acc:0.12666666666666668, test acc:0.1329 ===\n",
      "train loss:2.292086803215178\n",
      "train loss:2.288386849677357\n",
      "train loss:2.2832325913455374\n",
      "=== epoch:18, train acc:0.13666666666666666, test acc:0.136 ===\n",
      "train loss:2.280243214260695\n",
      "train loss:2.289802176078344\n",
      "train loss:2.2903479905525232\n",
      "=== epoch:19, train acc:0.14, test acc:0.1399 ===\n",
      "train loss:2.279747583595646\n",
      "train loss:2.274589597712643\n",
      "train loss:2.291943712231444\n",
      "=== epoch:20, train acc:0.13666666666666666, test acc:0.1408 ===\n",
      "train loss:2.281057350870485\n",
      "train loss:2.2902880987539054\n",
      "train loss:2.280386372203155\n",
      "=== epoch:21, train acc:0.14333333333333334, test acc:0.1424 ===\n",
      "train loss:2.285928705164596\n",
      "train loss:2.282434606372045\n",
      "train loss:2.278811182513038\n",
      "=== epoch:22, train acc:0.14333333333333334, test acc:0.1442 ===\n",
      "train loss:2.3017262072756823\n",
      "train loss:2.2880838661348055\n",
      "train loss:2.273027926414652\n",
      "=== epoch:23, train acc:0.14333333333333334, test acc:0.149 ===\n",
      "train loss:2.2751461777308215\n",
      "train loss:2.288491666713572\n",
      "train loss:2.2842113099061137\n",
      "=== epoch:24, train acc:0.15, test acc:0.1524 ===\n",
      "train loss:2.2779810574393218\n",
      "train loss:2.2829100852115944\n",
      "train loss:2.2865749764358467\n",
      "=== epoch:25, train acc:0.16, test acc:0.1548 ===\n",
      "train loss:2.27077834413755\n",
      "train loss:2.2788262586162884\n",
      "train loss:2.2807858806857144\n",
      "=== epoch:26, train acc:0.16, test acc:0.1577 ===\n",
      "train loss:2.279968632350327\n",
      "train loss:2.3022370363232336\n",
      "train loss:2.2774227959815594\n",
      "=== epoch:27, train acc:0.16333333333333333, test acc:0.1582 ===\n",
      "train loss:2.274587059278094\n",
      "train loss:2.295408802050859\n",
      "train loss:2.2867395628050646\n",
      "=== epoch:28, train acc:0.16666666666666666, test acc:0.1583 ===\n",
      "train loss:2.279211921700193\n",
      "train loss:2.269732248649153\n",
      "train loss:2.2652305351331727\n",
      "=== epoch:29, train acc:0.17, test acc:0.1595 ===\n",
      "train loss:2.28064918250637\n",
      "train loss:2.290538849789865\n",
      "train loss:2.258874213090296\n",
      "=== epoch:30, train acc:0.16333333333333333, test acc:0.1573 ===\n",
      "train loss:2.2867715379669526\n",
      "train loss:2.2721884859422703\n",
      "train loss:2.2854464025758405\n",
      "=== epoch:31, train acc:0.17, test acc:0.1562 ===\n",
      "train loss:2.2826343154482927\n",
      "train loss:2.2892113697445646\n",
      "train loss:2.272959989003914\n",
      "=== epoch:32, train acc:0.16333333333333333, test acc:0.1549 ===\n",
      "train loss:2.2797594035013806\n",
      "train loss:2.2661298026297834\n",
      "train loss:2.265514283204879\n",
      "=== epoch:33, train acc:0.16333333333333333, test acc:0.1557 ===\n",
      "train loss:2.2696506521022983\n",
      "train loss:2.265926783337321\n",
      "train loss:2.273749180256218\n",
      "=== epoch:34, train acc:0.16333333333333333, test acc:0.161 ===\n",
      "train loss:2.278144397728673\n",
      "train loss:2.271801623373283\n",
      "train loss:2.2721296723279494\n",
      "=== epoch:35, train acc:0.16666666666666666, test acc:0.1604 ===\n",
      "train loss:2.2876586280332596\n",
      "train loss:2.2895825651180375\n",
      "train loss:2.2854933244149125\n",
      "=== epoch:36, train acc:0.17333333333333334, test acc:0.1603 ===\n",
      "train loss:2.2642555327385283\n",
      "train loss:2.25667306107619\n",
      "train loss:2.274329765620368\n",
      "=== epoch:37, train acc:0.16666666666666666, test acc:0.1603 ===\n",
      "train loss:2.2730082354308276\n",
      "train loss:2.2774863366968656\n",
      "train loss:2.273692234694739\n",
      "=== epoch:38, train acc:0.17, test acc:0.1622 ===\n",
      "train loss:2.275193760481368\n",
      "train loss:2.2675036980556325\n",
      "train loss:2.2618036140482314\n",
      "=== epoch:39, train acc:0.18666666666666668, test acc:0.1624 ===\n",
      "train loss:2.2759277758965415\n",
      "train loss:2.2861026812633156\n",
      "train loss:2.2633967732564253\n",
      "=== epoch:40, train acc:0.17, test acc:0.1568 ===\n",
      "train loss:2.2823332649982775\n",
      "train loss:2.26488491971546\n",
      "train loss:2.264845857530672\n",
      "=== epoch:41, train acc:0.18, test acc:0.1591 ===\n",
      "train loss:2.2709873409514754\n",
      "train loss:2.282595916427947\n",
      "train loss:2.2820909144561377\n",
      "=== epoch:42, train acc:0.17666666666666667, test acc:0.1612 ===\n",
      "train loss:2.2635455096707733\n",
      "train loss:2.258527862280123\n",
      "train loss:2.258672221480588\n",
      "=== epoch:43, train acc:0.17666666666666667, test acc:0.1599 ===\n",
      "train loss:2.267272061597549\n",
      "train loss:2.2487199866370027\n",
      "train loss:2.2462907115068935\n",
      "=== epoch:44, train acc:0.17333333333333334, test acc:0.1582 ===\n",
      "train loss:2.251082177029262\n",
      "train loss:2.258679561038682\n",
      "train loss:2.2793109047303646\n",
      "=== epoch:45, train acc:0.17, test acc:0.162 ===\n",
      "train loss:2.2666417175423224\n",
      "train loss:2.262920837967913\n",
      "train loss:2.2530856346766828\n",
      "=== epoch:46, train acc:0.18666666666666668, test acc:0.1707 ===\n",
      "train loss:2.2628631682120086\n",
      "train loss:2.2431633234452586\n",
      "train loss:2.2739832194831124\n",
      "=== epoch:47, train acc:0.18666666666666668, test acc:0.1701 ===\n",
      "train loss:2.2485041793164164\n",
      "train loss:2.2628542301287737\n",
      "train loss:2.2629870495124838\n",
      "=== epoch:48, train acc:0.19666666666666666, test acc:0.1768 ===\n",
      "train loss:2.2708628081635713\n",
      "train loss:2.257367195437216\n",
      "train loss:2.265763334281351\n",
      "=== epoch:49, train acc:0.20333333333333334, test acc:0.1767 ===\n",
      "train loss:2.2716297601764253\n",
      "train loss:2.274475866949638\n",
      "train loss:2.253503584885932\n",
      "=== epoch:50, train acc:0.20333333333333334, test acc:0.177 ===\n",
      "train loss:2.2627324671226847\n",
      "train loss:2.268836131248297\n",
      "train loss:2.2448838100190125\n",
      "=== epoch:51, train acc:0.2, test acc:0.1746 ===\n",
      "train loss:2.257946936614331\n",
      "train loss:2.2628481654256527\n",
      "train loss:2.2767156428775492\n",
      "=== epoch:52, train acc:0.20333333333333334, test acc:0.1765 ===\n",
      "train loss:2.2586849167147376\n",
      "train loss:2.2533313325911113\n",
      "train loss:2.25480061257173\n",
      "=== epoch:53, train acc:0.2, test acc:0.1794 ===\n",
      "train loss:2.265556663434791\n",
      "train loss:2.267600539243147\n",
      "train loss:2.2543683357540636\n",
      "=== epoch:54, train acc:0.22333333333333333, test acc:0.1847 ===\n",
      "train loss:2.2640187543200474\n",
      "train loss:2.247073037500188\n",
      "train loss:2.2580789389816434\n",
      "=== epoch:55, train acc:0.23333333333333334, test acc:0.1883 ===\n",
      "train loss:2.2574153696074246\n",
      "train loss:2.2537570846562196\n",
      "train loss:2.250861827944208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:56, train acc:0.22666666666666666, test acc:0.1911 ===\n",
      "train loss:2.262551351970067\n",
      "train loss:2.25361570688831\n",
      "train loss:2.2416274386126562\n",
      "=== epoch:57, train acc:0.24, test acc:0.1986 ===\n",
      "train loss:2.249022534840588\n",
      "train loss:2.2439070448279113\n",
      "train loss:2.239599940777946\n",
      "=== epoch:58, train acc:0.23, test acc:0.1983 ===\n",
      "train loss:2.277768814205555\n",
      "train loss:2.2574742151116767\n",
      "train loss:2.2603860972951804\n",
      "=== epoch:59, train acc:0.23, test acc:0.1998 ===\n",
      "train loss:2.2545811080204388\n",
      "train loss:2.2600284214938835\n",
      "train loss:2.2512010154955884\n",
      "=== epoch:60, train acc:0.23333333333333334, test acc:0.1991 ===\n",
      "train loss:2.2602191115069066\n",
      "train loss:2.249598421353541\n",
      "train loss:2.2517424249093256\n",
      "=== epoch:61, train acc:0.22666666666666666, test acc:0.1999 ===\n",
      "train loss:2.2602459396508046\n",
      "train loss:2.236480986680886\n",
      "train loss:2.2564781485550656\n",
      "=== epoch:62, train acc:0.22333333333333333, test acc:0.1974 ===\n",
      "train loss:2.229842784934723\n",
      "train loss:2.2570464026970605\n",
      "train loss:2.257549215876418\n",
      "=== epoch:63, train acc:0.21333333333333335, test acc:0.1961 ===\n",
      "train loss:2.241262615401864\n",
      "train loss:2.2603991274887165\n",
      "train loss:2.2382249231976474\n",
      "=== epoch:64, train acc:0.22333333333333333, test acc:0.197 ===\n",
      "train loss:2.2608725468583195\n",
      "train loss:2.2334631427181955\n",
      "train loss:2.2538178648643363\n",
      "=== epoch:65, train acc:0.22333333333333333, test acc:0.1998 ===\n",
      "train loss:2.231326264454679\n",
      "train loss:2.2229499852733072\n",
      "train loss:2.2521323333383036\n",
      "=== epoch:66, train acc:0.22333333333333333, test acc:0.1976 ===\n",
      "train loss:2.242641616456417\n",
      "train loss:2.2456660768970864\n",
      "train loss:2.2482217300865703\n",
      "=== epoch:67, train acc:0.21666666666666667, test acc:0.1967 ===\n",
      "train loss:2.2306166406107066\n",
      "train loss:2.239350680372086\n",
      "train loss:2.255882452503765\n",
      "=== epoch:68, train acc:0.22, test acc:0.1961 ===\n",
      "train loss:2.2252890477506724\n",
      "train loss:2.238509708606119\n",
      "train loss:2.22813280665584\n",
      "=== epoch:69, train acc:0.21, test acc:0.1959 ===\n",
      "train loss:2.2553367885293345\n",
      "train loss:2.248010526887777\n",
      "train loss:2.245077692377359\n",
      "=== epoch:70, train acc:0.21333333333333335, test acc:0.2003 ===\n",
      "train loss:2.2357197386540304\n",
      "train loss:2.2662671228573434\n",
      "train loss:2.2468868732573317\n",
      "=== epoch:71, train acc:0.22666666666666666, test acc:0.2034 ===\n",
      "train loss:2.2347067237858824\n",
      "train loss:2.2459118536654925\n",
      "train loss:2.2465509942361526\n",
      "=== epoch:72, train acc:0.23333333333333334, test acc:0.2053 ===\n",
      "train loss:2.226551046503939\n",
      "train loss:2.2455299682366365\n",
      "train loss:2.226867091068867\n",
      "=== epoch:73, train acc:0.22, test acc:0.2063 ===\n",
      "train loss:2.2514127364056233\n",
      "train loss:2.243929012347013\n",
      "train loss:2.271352300986259\n",
      "=== epoch:74, train acc:0.22333333333333333, test acc:0.2066 ===\n",
      "train loss:2.2369702862658567\n",
      "train loss:2.221729057565789\n",
      "train loss:2.2242769713811334\n",
      "=== epoch:75, train acc:0.21666666666666667, test acc:0.2035 ===\n",
      "train loss:2.244905271766435\n",
      "train loss:2.2114091200456065\n",
      "train loss:2.259776918520529\n",
      "=== epoch:76, train acc:0.22, test acc:0.2052 ===\n",
      "train loss:2.236622561883759\n",
      "train loss:2.2551627312188374\n",
      "train loss:2.255812205782785\n",
      "=== epoch:77, train acc:0.23, test acc:0.2091 ===\n",
      "train loss:2.2248684584133818\n",
      "train loss:2.242966629398167\n",
      "train loss:2.245593449862745\n",
      "=== epoch:78, train acc:0.23, test acc:0.2106 ===\n",
      "train loss:2.216738104252146\n",
      "train loss:2.251662137197014\n",
      "train loss:2.2351377923227456\n",
      "=== epoch:79, train acc:0.23, test acc:0.2093 ===\n",
      "train loss:2.2446361546509834\n",
      "train loss:2.214887312298048\n",
      "train loss:2.21444862366107\n",
      "=== epoch:80, train acc:0.22666666666666666, test acc:0.2079 ===\n",
      "train loss:2.1975422240486093\n",
      "train loss:2.21103295951795\n",
      "train loss:2.2196068805096694\n",
      "=== epoch:81, train acc:0.22666666666666666, test acc:0.2063 ===\n",
      "train loss:2.214492424751747\n",
      "train loss:2.2325572430299445\n",
      "train loss:2.2250141473546114\n",
      "=== epoch:82, train acc:0.22666666666666666, test acc:0.2073 ===\n",
      "train loss:2.230687647998559\n",
      "train loss:2.2192812173283443\n",
      "train loss:2.223932014272979\n",
      "=== epoch:83, train acc:0.22666666666666666, test acc:0.2065 ===\n",
      "train loss:2.234205386252347\n",
      "train loss:2.2210678303617675\n",
      "train loss:2.230798361512008\n",
      "=== epoch:84, train acc:0.22666666666666666, test acc:0.2079 ===\n",
      "train loss:2.2097940653451245\n",
      "train loss:2.2090333972824627\n",
      "train loss:2.1930938078764433\n",
      "=== epoch:85, train acc:0.22666666666666666, test acc:0.2081 ===\n",
      "train loss:2.2271063447275052\n",
      "train loss:2.2107513682117537\n",
      "train loss:2.2302745712710266\n",
      "=== epoch:86, train acc:0.23, test acc:0.2092 ===\n",
      "train loss:2.225665083573151\n",
      "train loss:2.2028467114842645\n",
      "train loss:2.228327043744067\n",
      "=== epoch:87, train acc:0.22333333333333333, test acc:0.2074 ===\n",
      "train loss:2.2476650283755832\n",
      "train loss:2.2079465676152936\n",
      "train loss:2.2263910813354446\n",
      "=== epoch:88, train acc:0.22666666666666666, test acc:0.21 ===\n",
      "train loss:2.236718576852278\n",
      "train loss:2.199862531847826\n",
      "train loss:2.2348959024581663\n",
      "=== epoch:89, train acc:0.23333333333333334, test acc:0.2125 ===\n",
      "train loss:2.2072995788528256\n",
      "train loss:2.226343882910377\n",
      "train loss:2.215587828108887\n",
      "=== epoch:90, train acc:0.24333333333333335, test acc:0.2149 ===\n",
      "train loss:2.2154618782314923\n",
      "train loss:2.1941910420034128\n",
      "train loss:2.193519267436117\n",
      "=== epoch:91, train acc:0.23666666666666666, test acc:0.2129 ===\n",
      "train loss:2.220149378365692\n",
      "train loss:2.210072776407585\n",
      "train loss:2.204168120320935\n",
      "=== epoch:92, train acc:0.23333333333333334, test acc:0.2116 ===\n",
      "train loss:2.2246493931077946\n",
      "train loss:2.2215925825343974\n",
      "train loss:2.212546745153005\n",
      "=== epoch:93, train acc:0.23, test acc:0.2096 ===\n",
      "train loss:2.226570666464496\n",
      "train loss:2.2228593710704443\n",
      "train loss:2.2107829593619703\n",
      "=== epoch:94, train acc:0.23, test acc:0.2099 ===\n",
      "train loss:2.197812166996048\n",
      "train loss:2.1987719273384783\n",
      "train loss:2.2051399668467813\n",
      "=== epoch:95, train acc:0.22666666666666666, test acc:0.2081 ===\n",
      "train loss:2.183819888444834\n",
      "train loss:2.1939427925154464\n",
      "train loss:2.1816348039125497\n",
      "=== epoch:96, train acc:0.22666666666666666, test acc:0.2058 ===\n",
      "train loss:2.2203897734095706\n",
      "train loss:2.217213069800575\n",
      "train loss:2.2615478834223772\n",
      "=== epoch:97, train acc:0.22666666666666666, test acc:0.2085 ===\n",
      "train loss:2.1880105169537125\n",
      "train loss:2.204483165382786\n",
      "train loss:2.1761098602305338\n",
      "=== epoch:98, train acc:0.22666666666666666, test acc:0.2058 ===\n",
      "train loss:2.2235025072231474\n",
      "train loss:2.212494337450772\n",
      "train loss:2.217866086174077\n",
      "=== epoch:99, train acc:0.22666666666666666, test acc:0.2077 ===\n",
      "train loss:2.213002747680981\n",
      "train loss:2.2140581845577385\n",
      "train loss:2.1939996414013643\n",
      "=== epoch:100, train acc:0.22666666666666666, test acc:0.2071 ===\n",
      "train loss:2.216243136634975\n",
      "train loss:2.215071728039779\n",
      "train loss:2.1447356907216046\n",
      "=== epoch:101, train acc:0.22333333333333333, test acc:0.2067 ===\n",
      "train loss:2.181911615086534\n",
      "train loss:2.1672222370047005\n",
      "train loss:2.1944481713261053\n",
      "=== epoch:102, train acc:0.22666666666666666, test acc:0.2062 ===\n",
      "train loss:2.19302135591277\n",
      "train loss:2.198609990084516\n",
      "train loss:2.2299584498508453\n",
      "=== epoch:103, train acc:0.23, test acc:0.2074 ===\n",
      "train loss:2.166366390258396\n",
      "train loss:2.199151522804206\n",
      "train loss:2.183930474861813\n",
      "=== epoch:104, train acc:0.22666666666666666, test acc:0.2042 ===\n",
      "train loss:2.187312719459481\n",
      "train loss:2.1770513897144133\n",
      "train loss:2.1802202046541876\n",
      "=== epoch:105, train acc:0.23333333333333334, test acc:0.2042 ===\n",
      "train loss:2.220003847077595\n",
      "train loss:2.1846508944701153\n",
      "train loss:2.173153946874672\n",
      "=== epoch:106, train acc:0.23333333333333334, test acc:0.2074 ===\n",
      "train loss:2.198386333550081\n",
      "train loss:2.1829000899747877\n",
      "train loss:2.194213083323034\n",
      "=== epoch:107, train acc:0.23666666666666666, test acc:0.2088 ===\n",
      "train loss:2.168585314110913\n",
      "train loss:2.168549342518768\n",
      "train loss:2.1702997207806147\n",
      "=== epoch:108, train acc:0.24333333333333335, test acc:0.2076 ===\n",
      "train loss:2.1654759230953493\n",
      "train loss:2.189508389111367\n",
      "train loss:2.1727578392689804\n",
      "=== epoch:109, train acc:0.23666666666666666, test acc:0.2049 ===\n",
      "train loss:2.170123892096185\n",
      "train loss:2.1529992370142814\n",
      "train loss:2.1229331173526527\n",
      "=== epoch:110, train acc:0.23333333333333334, test acc:0.2012 ===\n",
      "train loss:2.1658112862394585\n",
      "train loss:2.1322028576135197\n",
      "train loss:2.1669858607135426\n",
      "=== epoch:111, train acc:0.23, test acc:0.2007 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.1746862545614447\n",
      "train loss:2.136586076316587\n",
      "train loss:2.159939629586974\n",
      "=== epoch:112, train acc:0.22666666666666666, test acc:0.1989 ===\n",
      "train loss:2.1622848732392086\n",
      "train loss:2.1511714065552554\n",
      "train loss:2.211690732786596\n",
      "=== epoch:113, train acc:0.23, test acc:0.2012 ===\n",
      "train loss:2.1458988990194188\n",
      "train loss:2.1251276683415226\n",
      "train loss:2.1799116439700272\n",
      "=== epoch:114, train acc:0.22666666666666666, test acc:0.1968 ===\n",
      "train loss:2.1423206910390893\n",
      "train loss:2.131840443671775\n",
      "train loss:2.1620105225788238\n",
      "=== epoch:115, train acc:0.22333333333333333, test acc:0.1943 ===\n",
      "train loss:2.1398826827168054\n",
      "train loss:2.1559771575281004\n",
      "train loss:2.0927422881290165\n",
      "=== epoch:116, train acc:0.22666666666666666, test acc:0.1944 ===\n",
      "train loss:2.159385474358367\n",
      "train loss:2.169514667102211\n",
      "train loss:2.1473972387289453\n",
      "=== epoch:117, train acc:0.22666666666666666, test acc:0.1931 ===\n",
      "train loss:2.203271331625566\n",
      "train loss:2.193610326774537\n",
      "train loss:2.1832788614293275\n",
      "=== epoch:118, train acc:0.23666666666666666, test acc:0.1984 ===\n",
      "train loss:2.1775165869327675\n",
      "train loss:2.129338171699144\n",
      "train loss:2.121205987895985\n",
      "=== epoch:119, train acc:0.23666666666666666, test acc:0.1971 ===\n",
      "train loss:2.1928322490058014\n",
      "train loss:2.1215719911115385\n",
      "train loss:2.1941820944508286\n",
      "=== epoch:120, train acc:0.23666666666666666, test acc:0.2006 ===\n",
      "train loss:2.1477310792460242\n",
      "train loss:2.198094541369502\n",
      "train loss:2.1129249882146492\n",
      "=== epoch:121, train acc:0.23333333333333334, test acc:0.2035 ===\n",
      "train loss:2.1702350984241083\n",
      "train loss:2.1506010553617965\n",
      "train loss:2.140415336359643\n",
      "=== epoch:122, train acc:0.24, test acc:0.2063 ===\n",
      "train loss:2.1532370872833506\n",
      "train loss:2.2198190841622414\n",
      "train loss:2.1321217503321797\n",
      "=== epoch:123, train acc:0.24333333333333335, test acc:0.2091 ===\n",
      "train loss:2.0895143087554695\n",
      "train loss:2.1587916469703403\n",
      "train loss:2.0739339461565316\n",
      "=== epoch:124, train acc:0.24, test acc:0.2091 ===\n",
      "train loss:2.166014474097235\n",
      "train loss:2.1474911448541847\n",
      "train loss:2.1385439029045026\n",
      "=== epoch:125, train acc:0.24, test acc:0.2127 ===\n",
      "train loss:2.1864934271230156\n",
      "train loss:2.1654193956802485\n",
      "train loss:2.131207290001629\n",
      "=== epoch:126, train acc:0.24666666666666667, test acc:0.2145 ===\n",
      "train loss:2.078964253880431\n",
      "train loss:2.0865777852031147\n",
      "train loss:2.1407836811382084\n",
      "=== epoch:127, train acc:0.24666666666666667, test acc:0.2126 ===\n",
      "train loss:2.1503145228191802\n",
      "train loss:2.082374143634125\n",
      "train loss:2.147496402812586\n",
      "=== epoch:128, train acc:0.24666666666666667, test acc:0.2137 ===\n",
      "train loss:2.1552281748079443\n",
      "train loss:2.143510221730199\n",
      "train loss:2.0851556086626415\n",
      "=== epoch:129, train acc:0.24666666666666667, test acc:0.214 ===\n",
      "train loss:2.1644256054148903\n",
      "train loss:2.157827541730362\n",
      "train loss:2.0763185640906787\n",
      "=== epoch:130, train acc:0.25, test acc:0.217 ===\n",
      "train loss:2.1162456898863393\n",
      "train loss:2.130917062109755\n",
      "train loss:2.1209072277535057\n",
      "=== epoch:131, train acc:0.25, test acc:0.2151 ===\n",
      "train loss:2.1426373863095787\n",
      "train loss:2.119060091030779\n",
      "train loss:2.1255033561778074\n",
      "=== epoch:132, train acc:0.25333333333333335, test acc:0.2171 ===\n",
      "train loss:2.121799879297478\n",
      "train loss:2.0819366560309844\n",
      "train loss:2.107829283897225\n",
      "=== epoch:133, train acc:0.25333333333333335, test acc:0.2166 ===\n",
      "train loss:2.1040284303784578\n",
      "train loss:2.1284986780057675\n",
      "train loss:2.1494617414218746\n",
      "=== epoch:134, train acc:0.25333333333333335, test acc:0.2186 ===\n",
      "train loss:2.149896737808335\n",
      "train loss:2.096333607190689\n",
      "train loss:2.126193504961112\n",
      "=== epoch:135, train acc:0.25666666666666665, test acc:0.2229 ===\n",
      "train loss:2.076254605628448\n",
      "train loss:2.121133904866898\n",
      "train loss:2.1041840516138244\n",
      "=== epoch:136, train acc:0.25666666666666665, test acc:0.2236 ===\n",
      "train loss:2.1635019354156877\n",
      "train loss:2.107878135145862\n",
      "train loss:2.1003209788745805\n",
      "=== epoch:137, train acc:0.26, test acc:0.2258 ===\n",
      "train loss:2.146641069853678\n",
      "train loss:2.0776787569175332\n",
      "train loss:2.084145816639141\n",
      "=== epoch:138, train acc:0.2633333333333333, test acc:0.2279 ===\n",
      "train loss:2.0535550117818047\n",
      "train loss:2.074948084460846\n",
      "train loss:2.0978625114885805\n",
      "=== epoch:139, train acc:0.2633333333333333, test acc:0.2287 ===\n",
      "train loss:2.0698741260436084\n",
      "train loss:2.103489102091836\n",
      "train loss:2.079063855264369\n",
      "=== epoch:140, train acc:0.26666666666666666, test acc:0.2299 ===\n",
      "train loss:2.106584913389094\n",
      "train loss:2.0652323392800964\n",
      "train loss:2.1307663639978456\n",
      "=== epoch:141, train acc:0.27666666666666667, test acc:0.2332 ===\n",
      "train loss:2.067040317310058\n",
      "train loss:2.0787158262114254\n",
      "train loss:2.070801058128392\n",
      "=== epoch:142, train acc:0.27666666666666667, test acc:0.2346 ===\n",
      "train loss:2.0805520675628317\n",
      "train loss:2.0921030078325673\n",
      "train loss:2.0630564998005334\n",
      "=== epoch:143, train acc:0.27666666666666667, test acc:0.2365 ===\n",
      "train loss:2.138417221604962\n",
      "train loss:2.102716423517529\n",
      "train loss:2.1062255934233747\n",
      "=== epoch:144, train acc:0.27666666666666667, test acc:0.2401 ===\n",
      "train loss:2.0775329797303583\n",
      "train loss:2.109063158960206\n",
      "train loss:2.1518424449009714\n",
      "=== epoch:145, train acc:0.2866666666666667, test acc:0.2426 ===\n",
      "train loss:2.099762940389623\n",
      "train loss:2.071467657387703\n",
      "train loss:2.0696830346213186\n",
      "=== epoch:146, train acc:0.2866666666666667, test acc:0.2464 ===\n",
      "train loss:2.0669908861558945\n",
      "train loss:2.0307345915405204\n",
      "train loss:2.030143157796328\n",
      "=== epoch:147, train acc:0.2833333333333333, test acc:0.2443 ===\n",
      "train loss:2.139105175903868\n",
      "train loss:2.166760897285856\n",
      "train loss:2.0761039529105894\n",
      "=== epoch:148, train acc:0.29333333333333333, test acc:0.2469 ===\n",
      "train loss:2.0298796807262525\n",
      "train loss:2.091860843538227\n",
      "train loss:2.1004190652187145\n",
      "=== epoch:149, train acc:0.2966666666666667, test acc:0.2484 ===\n",
      "train loss:2.115726845356628\n",
      "train loss:2.069164598174078\n",
      "train loss:2.0706478559967794\n",
      "=== epoch:150, train acc:0.2966666666666667, test acc:0.2487 ===\n",
      "train loss:2.117185283744844\n",
      "train loss:2.0354999119310757\n",
      "train loss:2.0498203570992435\n",
      "=== epoch:151, train acc:0.30333333333333334, test acc:0.2538 ===\n",
      "train loss:2.0289083268731654\n",
      "train loss:1.957255086030448\n",
      "train loss:2.044718213001382\n",
      "=== epoch:152, train acc:0.30333333333333334, test acc:0.2519 ===\n",
      "train loss:2.104533266870011\n",
      "train loss:2.0073732452819772\n",
      "train loss:2.014428990841464\n",
      "=== epoch:153, train acc:0.30333333333333334, test acc:0.252 ===\n",
      "train loss:1.9738050950815338\n",
      "train loss:1.9929849036285676\n",
      "train loss:2.0616650070688425\n",
      "=== epoch:154, train acc:0.30333333333333334, test acc:0.2508 ===\n",
      "train loss:2.0786972376630275\n",
      "train loss:1.9944859781972326\n",
      "train loss:2.0472370633373904\n",
      "=== epoch:155, train acc:0.30333333333333334, test acc:0.2516 ===\n",
      "train loss:2.052091999076464\n",
      "train loss:2.026389882366773\n",
      "train loss:1.979528630488664\n",
      "=== epoch:156, train acc:0.30333333333333334, test acc:0.2507 ===\n",
      "train loss:2.040791151987156\n",
      "train loss:1.9950858031846954\n",
      "train loss:2.0202396561968197\n",
      "=== epoch:157, train acc:0.3, test acc:0.2502 ===\n",
      "train loss:1.971526127853012\n",
      "train loss:1.9772814686553106\n",
      "train loss:1.9826111984077528\n",
      "=== epoch:158, train acc:0.30333333333333334, test acc:0.2509 ===\n",
      "train loss:2.0657204990344415\n",
      "train loss:1.9947255598412985\n",
      "train loss:2.0699729432706904\n",
      "=== epoch:159, train acc:0.31, test acc:0.2542 ===\n",
      "train loss:1.9969951192625488\n",
      "train loss:2.0080069398869376\n",
      "train loss:2.013242610193045\n",
      "=== epoch:160, train acc:0.30666666666666664, test acc:0.2553 ===\n",
      "train loss:2.019621496689204\n",
      "train loss:2.030065939835073\n",
      "train loss:1.9850205358769863\n",
      "=== epoch:161, train acc:0.32, test acc:0.2577 ===\n",
      "train loss:2.0597074236238995\n",
      "train loss:2.008174044994053\n",
      "train loss:2.0007385106301943\n",
      "=== epoch:162, train acc:0.3233333333333333, test acc:0.2599 ===\n",
      "train loss:1.9294008376737137\n",
      "train loss:2.1057384909435295\n",
      "train loss:2.02875306150199\n",
      "=== epoch:163, train acc:0.33, test acc:0.262 ===\n",
      "train loss:2.030089459256083\n",
      "train loss:2.0713096453322204\n",
      "train loss:2.0258523055781192\n",
      "=== epoch:164, train acc:0.3466666666666667, test acc:0.2682 ===\n",
      "train loss:2.011751225018937\n",
      "train loss:2.062095142918614\n",
      "train loss:2.0094007188081817\n",
      "=== epoch:165, train acc:0.35, test acc:0.2712 ===\n",
      "train loss:1.9648016397030628\n",
      "train loss:2.0343728675432975\n",
      "train loss:1.940247130891782\n",
      "=== epoch:166, train acc:0.3433333333333333, test acc:0.2706 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.9937108663268237\n",
      "train loss:1.921259131380019\n",
      "train loss:2.0104681231380477\n",
      "=== epoch:167, train acc:0.3566666666666667, test acc:0.2736 ===\n",
      "train loss:1.9434860143105186\n",
      "train loss:2.00443109294844\n",
      "train loss:2.029383336575174\n",
      "=== epoch:168, train acc:0.36, test acc:0.2779 ===\n",
      "train loss:2.013337890706357\n",
      "train loss:1.9655787081043676\n",
      "train loss:2.0644763180820305\n",
      "=== epoch:169, train acc:0.36666666666666664, test acc:0.2847 ===\n",
      "train loss:2.0333110644015338\n",
      "train loss:1.9779266974277223\n",
      "train loss:1.9772278176390754\n",
      "=== epoch:170, train acc:0.38333333333333336, test acc:0.2879 ===\n",
      "train loss:1.993404098025747\n",
      "train loss:1.9401895387379775\n",
      "train loss:1.9948905384392348\n",
      "=== epoch:171, train acc:0.3933333333333333, test acc:0.2913 ===\n",
      "train loss:1.9624315097695844\n",
      "train loss:1.9005818052882018\n",
      "train loss:1.9004462409423817\n",
      "=== epoch:172, train acc:0.3933333333333333, test acc:0.2923 ===\n",
      "train loss:1.9275588679105098\n",
      "train loss:2.0505998165073014\n",
      "train loss:1.9418114675705556\n",
      "=== epoch:173, train acc:0.4, test acc:0.2928 ===\n",
      "train loss:2.043282645157527\n",
      "train loss:2.0162460657986414\n",
      "train loss:1.8349487186056834\n",
      "=== epoch:174, train acc:0.4033333333333333, test acc:0.2963 ===\n",
      "train loss:2.004927144974861\n",
      "train loss:1.9729170544179437\n",
      "train loss:1.8966689044789253\n",
      "=== epoch:175, train acc:0.41, test acc:0.297 ===\n",
      "train loss:2.0352664179347233\n",
      "train loss:1.9512646848681678\n",
      "train loss:1.9532488033063313\n",
      "=== epoch:176, train acc:0.4066666666666667, test acc:0.2997 ===\n",
      "train loss:1.9805666899093655\n",
      "train loss:1.9725432749657943\n",
      "train loss:1.9297065903468793\n",
      "=== epoch:177, train acc:0.42, test acc:0.3046 ===\n",
      "train loss:1.9282795817025267\n",
      "train loss:1.9538570127671513\n",
      "train loss:2.012449862552167\n",
      "=== epoch:178, train acc:0.43, test acc:0.3089 ===\n",
      "train loss:2.0076077905392227\n",
      "train loss:2.011481432236041\n",
      "train loss:2.0175182846253805\n",
      "=== epoch:179, train acc:0.4266666666666667, test acc:0.3103 ===\n",
      "train loss:1.872117124808307\n",
      "train loss:1.9882299990105077\n",
      "train loss:1.9125846145483087\n",
      "=== epoch:180, train acc:0.42333333333333334, test acc:0.3074 ===\n",
      "train loss:1.9262932881850536\n",
      "train loss:1.971044580554256\n",
      "train loss:1.9220840228473428\n",
      "=== epoch:181, train acc:0.4266666666666667, test acc:0.3071 ===\n",
      "train loss:1.9473319044058557\n",
      "train loss:1.9181176933528865\n",
      "train loss:2.0051621649046765\n",
      "=== epoch:182, train acc:0.43333333333333335, test acc:0.3103 ===\n",
      "train loss:2.0397836916609977\n",
      "train loss:1.9837591415086582\n",
      "train loss:1.9638199836975148\n",
      "=== epoch:183, train acc:0.43666666666666665, test acc:0.3184 ===\n",
      "train loss:1.9822920057919804\n",
      "train loss:1.9783603186630616\n",
      "train loss:1.9978894017581468\n",
      "=== epoch:184, train acc:0.44, test acc:0.322 ===\n",
      "train loss:1.9161382548798886\n",
      "train loss:1.9393018793739203\n",
      "train loss:1.9586570487103507\n",
      "=== epoch:185, train acc:0.43666666666666665, test acc:0.3224 ===\n",
      "train loss:1.9385645034721253\n",
      "train loss:1.8995002722183696\n",
      "train loss:1.9677346248504994\n",
      "=== epoch:186, train acc:0.43333333333333335, test acc:0.3198 ===\n",
      "train loss:1.9410646156950002\n",
      "train loss:1.90013970753254\n",
      "train loss:1.9302370417772472\n",
      "=== epoch:187, train acc:0.44, test acc:0.3205 ===\n",
      "train loss:1.9458861818783537\n",
      "train loss:1.8497932944767586\n",
      "train loss:1.8729816188802033\n",
      "=== epoch:188, train acc:0.44333333333333336, test acc:0.3222 ===\n",
      "train loss:1.8895768755943418\n",
      "train loss:1.90818344399923\n",
      "train loss:1.8073618998475218\n",
      "=== epoch:189, train acc:0.44333333333333336, test acc:0.3221 ===\n",
      "train loss:1.9004420578095678\n",
      "train loss:1.929711534441898\n",
      "train loss:1.9228521932137708\n",
      "=== epoch:190, train acc:0.44333333333333336, test acc:0.3242 ===\n",
      "train loss:1.9217161841508272\n",
      "train loss:2.0099656563269126\n",
      "train loss:2.0488506790756156\n",
      "=== epoch:191, train acc:0.4533333333333333, test acc:0.3312 ===\n",
      "train loss:1.8089944457778915\n",
      "train loss:1.8994462819204918\n",
      "train loss:1.950615024632261\n",
      "=== epoch:192, train acc:0.46, test acc:0.3322 ===\n",
      "train loss:1.8996735105933846\n",
      "train loss:1.871900205535495\n",
      "train loss:1.935829093397204\n",
      "=== epoch:193, train acc:0.47, test acc:0.3393 ===\n",
      "train loss:1.8930327715891169\n",
      "train loss:1.9154486922886687\n",
      "train loss:1.919829783936089\n",
      "=== epoch:194, train acc:0.47, test acc:0.34 ===\n",
      "train loss:1.90538355478917\n",
      "train loss:1.89732472232833\n",
      "train loss:1.825851000673663\n",
      "=== epoch:195, train acc:0.47, test acc:0.3369 ===\n",
      "train loss:1.8805985126386744\n",
      "train loss:1.8991380321079157\n",
      "train loss:1.910469337869919\n",
      "=== epoch:196, train acc:0.47, test acc:0.3358 ===\n",
      "train loss:1.8691228183824091\n",
      "train loss:1.8996711703036695\n",
      "train loss:1.8973666051903373\n",
      "=== epoch:197, train acc:0.4633333333333333, test acc:0.3343 ===\n",
      "train loss:1.8421550418388863\n",
      "train loss:1.9065533801257886\n",
      "train loss:1.825564025157078\n",
      "=== epoch:198, train acc:0.45666666666666667, test acc:0.3327 ===\n",
      "train loss:1.8531602174244435\n",
      "train loss:1.9892396975143034\n",
      "train loss:1.8694621434745309\n",
      "=== epoch:199, train acc:0.4666666666666667, test acc:0.3374 ===\n",
      "train loss:1.8869484602214448\n",
      "train loss:1.8495658044367775\n",
      "train loss:1.7883999352239868\n",
      "=== epoch:200, train acc:0.46, test acc:0.3355 ===\n",
      "train loss:1.860660158824051\n",
      "train loss:1.9202010199351738\n",
      "train loss:1.83550579886284\n",
      "=== epoch:201, train acc:0.47333333333333333, test acc:0.3372 ===\n",
      "train loss:1.9300105759509438\n",
      "train loss:1.8748564354899477\n",
      "train loss:1.835086852577503\n",
      "=== epoch:202, train acc:0.47333333333333333, test acc:0.34 ===\n",
      "train loss:1.8178376472054212\n",
      "train loss:1.8610900347158406\n",
      "train loss:1.8629840315387856\n",
      "=== epoch:203, train acc:0.45666666666666667, test acc:0.3361 ===\n",
      "train loss:1.8623961307324601\n",
      "train loss:1.8660041807944991\n",
      "train loss:1.8596926072946416\n",
      "=== epoch:204, train acc:0.4533333333333333, test acc:0.3358 ===\n",
      "train loss:1.8391993771996378\n",
      "train loss:1.8679544489114859\n",
      "train loss:1.9007219480511026\n",
      "=== epoch:205, train acc:0.4666666666666667, test acc:0.3387 ===\n",
      "train loss:1.869822637573847\n",
      "train loss:1.7977037108528475\n",
      "train loss:1.8270597397833257\n",
      "=== epoch:206, train acc:0.47, test acc:0.3412 ===\n",
      "train loss:1.869524809399539\n",
      "train loss:1.8877756635255851\n",
      "train loss:1.9420844924080811\n",
      "=== epoch:207, train acc:0.4766666666666667, test acc:0.3436 ===\n",
      "train loss:1.8249541833644813\n",
      "train loss:1.7447787859187804\n",
      "train loss:1.8412325053875436\n",
      "=== epoch:208, train acc:0.47333333333333333, test acc:0.3428 ===\n",
      "train loss:1.934348659246108\n",
      "train loss:1.857479604800038\n",
      "train loss:1.7552610022404393\n",
      "=== epoch:209, train acc:0.47333333333333333, test acc:0.3468 ===\n",
      "train loss:1.706645047734703\n",
      "train loss:1.809886220710397\n",
      "train loss:1.73085912839703\n",
      "=== epoch:210, train acc:0.47, test acc:0.3456 ===\n",
      "train loss:1.8703408127568593\n",
      "train loss:1.8753379951711444\n",
      "train loss:1.8426884020548864\n",
      "=== epoch:211, train acc:0.4866666666666667, test acc:0.3514 ===\n",
      "train loss:1.822394348400858\n",
      "train loss:1.8036311136359282\n",
      "train loss:1.8214012422201058\n",
      "=== epoch:212, train acc:0.48, test acc:0.3524 ===\n",
      "train loss:1.8747372004645928\n",
      "train loss:1.8344035876631337\n",
      "train loss:1.8360092137193362\n",
      "=== epoch:213, train acc:0.48333333333333334, test acc:0.3536 ===\n",
      "train loss:1.832094187648741\n",
      "train loss:1.9520973240686406\n",
      "train loss:1.7841268326616537\n",
      "=== epoch:214, train acc:0.5033333333333333, test acc:0.3589 ===\n",
      "train loss:1.7407913039238097\n",
      "train loss:1.8173458630517851\n",
      "train loss:1.8799227538784424\n",
      "=== epoch:215, train acc:0.5, test acc:0.3643 ===\n",
      "train loss:1.7872247746967762\n",
      "train loss:1.8263673413562025\n",
      "train loss:1.8467973094060568\n",
      "=== epoch:216, train acc:0.5066666666666667, test acc:0.3646 ===\n",
      "train loss:1.5969801566434176\n",
      "train loss:1.8574366053716236\n",
      "train loss:1.8460418134866226\n",
      "=== epoch:217, train acc:0.5033333333333333, test acc:0.3679 ===\n",
      "train loss:1.7575294108631536\n",
      "train loss:1.7073071256654198\n",
      "train loss:1.8319650476997298\n",
      "=== epoch:218, train acc:0.5033333333333333, test acc:0.3646 ===\n",
      "train loss:1.7573860961182683\n",
      "train loss:1.7041145701760891\n",
      "train loss:1.8121082285341228\n",
      "=== epoch:219, train acc:0.5066666666666667, test acc:0.3673 ===\n",
      "train loss:1.9680718980490834\n",
      "train loss:1.7960844028388332\n",
      "train loss:1.8057381364942764\n",
      "=== epoch:220, train acc:0.51, test acc:0.375 ===\n",
      "train loss:1.7805751024411018\n",
      "train loss:1.8386104342303913\n",
      "train loss:1.866324654373146\n",
      "=== epoch:221, train acc:0.5166666666666667, test acc:0.3834 ===\n",
      "train loss:1.7666124735020927\n",
      "train loss:1.7765257086051767\n",
      "train loss:1.681608293183824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:222, train acc:0.5133333333333333, test acc:0.376 ===\n",
      "train loss:1.8077473183460164\n",
      "train loss:1.7126032269194238\n",
      "train loss:1.8054375302809214\n",
      "=== epoch:223, train acc:0.51, test acc:0.3809 ===\n",
      "train loss:1.7755506423388971\n",
      "train loss:1.627206785769497\n",
      "train loss:1.738750038499662\n",
      "=== epoch:224, train acc:0.5166666666666667, test acc:0.3834 ===\n",
      "train loss:1.785582479218195\n",
      "train loss:1.7080378382351007\n",
      "train loss:1.672305766370735\n",
      "=== epoch:225, train acc:0.51, test acc:0.3811 ===\n",
      "train loss:1.5767432481383852\n",
      "train loss:1.7559077975116026\n",
      "train loss:1.8024388391759854\n",
      "=== epoch:226, train acc:0.51, test acc:0.377 ===\n",
      "train loss:1.7899947033066423\n",
      "train loss:1.7029053647246184\n",
      "train loss:1.693345721908313\n",
      "=== epoch:227, train acc:0.5133333333333333, test acc:0.3817 ===\n",
      "train loss:1.76148622813521\n",
      "train loss:1.7775201112145096\n",
      "train loss:1.7345518692982806\n",
      "=== epoch:228, train acc:0.5133333333333333, test acc:0.3864 ===\n",
      "train loss:1.767274874207856\n",
      "train loss:1.6343420333264962\n",
      "train loss:1.6422640474664965\n",
      "=== epoch:229, train acc:0.5066666666666667, test acc:0.3811 ===\n",
      "train loss:1.7012931660654302\n",
      "train loss:1.641539121278912\n",
      "train loss:1.7048648201536043\n",
      "=== epoch:230, train acc:0.5166666666666667, test acc:0.3881 ===\n",
      "train loss:1.8895411520156336\n",
      "train loss:1.7143933175693604\n",
      "train loss:1.7789798931645913\n",
      "=== epoch:231, train acc:0.5166666666666667, test acc:0.3924 ===\n",
      "train loss:1.7890789067339954\n",
      "train loss:1.8522457387684512\n",
      "train loss:1.6268659270863557\n",
      "=== epoch:232, train acc:0.53, test acc:0.4018 ===\n",
      "train loss:1.7304930849454823\n",
      "train loss:1.7725069724707598\n",
      "train loss:1.6945252346509927\n",
      "=== epoch:233, train acc:0.54, test acc:0.4066 ===\n",
      "train loss:1.735902156723463\n",
      "train loss:1.759844112068184\n",
      "train loss:1.6176505961969954\n",
      "=== epoch:234, train acc:0.5333333333333333, test acc:0.4061 ===\n",
      "train loss:1.6811174112969138\n",
      "train loss:1.6206861274407012\n",
      "train loss:1.7657968524990937\n",
      "=== epoch:235, train acc:0.54, test acc:0.4071 ===\n",
      "train loss:1.6944727540268136\n",
      "train loss:1.6512950983073242\n",
      "train loss:1.7034669112745828\n",
      "=== epoch:236, train acc:0.5466666666666666, test acc:0.4106 ===\n",
      "train loss:1.7015819435925164\n",
      "train loss:1.700879631620429\n",
      "train loss:1.753257684319293\n",
      "=== epoch:237, train acc:0.5333333333333333, test acc:0.4126 ===\n",
      "train loss:1.6899749437570497\n",
      "train loss:1.6762454148228394\n",
      "train loss:1.6578768759518965\n",
      "=== epoch:238, train acc:0.5366666666666666, test acc:0.4141 ===\n",
      "train loss:1.7457357899170591\n",
      "train loss:1.7402058491189283\n",
      "train loss:1.6636684215060868\n",
      "=== epoch:239, train acc:0.54, test acc:0.4155 ===\n",
      "train loss:1.7659538546429063\n",
      "train loss:1.7715999849172313\n",
      "train loss:1.7052694459593443\n",
      "=== epoch:240, train acc:0.55, test acc:0.4222 ===\n",
      "train loss:1.6849450729170954\n",
      "train loss:1.6863523307574106\n",
      "train loss:1.6963187965091342\n",
      "=== epoch:241, train acc:0.5566666666666666, test acc:0.4297 ===\n",
      "train loss:1.7409375412233854\n",
      "train loss:1.7092633017250143\n",
      "train loss:1.6613626152402865\n",
      "=== epoch:242, train acc:0.55, test acc:0.4278 ===\n",
      "train loss:1.7042766841842296\n",
      "train loss:1.6855735969885302\n",
      "train loss:1.6701959145073775\n",
      "=== epoch:243, train acc:0.54, test acc:0.423 ===\n",
      "train loss:1.5662528030397451\n",
      "train loss:1.6042106734710504\n",
      "train loss:1.6879445142464036\n",
      "=== epoch:244, train acc:0.54, test acc:0.4219 ===\n",
      "train loss:1.7185163024238594\n",
      "train loss:1.640736449576586\n",
      "train loss:1.6278857662312272\n",
      "=== epoch:245, train acc:0.54, test acc:0.4202 ===\n",
      "train loss:1.7241101898017595\n",
      "train loss:1.6301535106902014\n",
      "train loss:1.6096463799195901\n",
      "=== epoch:246, train acc:0.5566666666666666, test acc:0.423 ===\n",
      "train loss:1.7565491426176862\n",
      "train loss:1.6652199331040247\n",
      "train loss:1.7305237150666068\n",
      "=== epoch:247, train acc:0.5533333333333333, test acc:0.4299 ===\n",
      "train loss:1.5596396713656215\n",
      "train loss:1.6990123482901802\n",
      "train loss:1.6347295013003478\n",
      "=== epoch:248, train acc:0.55, test acc:0.4261 ===\n",
      "train loss:1.7189593761855175\n",
      "train loss:1.7257313843250788\n",
      "train loss:1.7411469567680526\n",
      "=== epoch:249, train acc:0.5533333333333333, test acc:0.4338 ===\n",
      "train loss:1.6438226942278138\n",
      "train loss:1.5843545729097128\n",
      "train loss:1.6878107355609058\n",
      "=== epoch:250, train acc:0.5533333333333333, test acc:0.4362 ===\n",
      "train loss:1.6860858769468479\n",
      "train loss:1.6458438514456644\n",
      "train loss:1.713277772981277\n",
      "=== epoch:251, train acc:0.5533333333333333, test acc:0.4416 ===\n",
      "train loss:1.587209910062292\n",
      "train loss:1.5978088212452326\n",
      "train loss:1.5602171848192157\n",
      "=== epoch:252, train acc:0.56, test acc:0.4456 ===\n",
      "train loss:1.5551097365983464\n",
      "train loss:1.6212126144793522\n",
      "train loss:1.6243584365310266\n",
      "=== epoch:253, train acc:0.5566666666666666, test acc:0.4457 ===\n",
      "train loss:1.6589105856068076\n",
      "train loss:1.6611070927671503\n",
      "train loss:1.727112786647077\n",
      "=== epoch:254, train acc:0.56, test acc:0.4478 ===\n",
      "train loss:1.5820603694715913\n",
      "train loss:1.6235555481367743\n",
      "train loss:1.6036473538187095\n",
      "=== epoch:255, train acc:0.56, test acc:0.4485 ===\n",
      "train loss:1.5244011676329619\n",
      "train loss:1.4260811667189395\n",
      "train loss:1.623909365705222\n",
      "=== epoch:256, train acc:0.56, test acc:0.4467 ===\n",
      "train loss:1.574885199799884\n",
      "train loss:1.4798669284096193\n",
      "train loss:1.6416000649689488\n",
      "=== epoch:257, train acc:0.56, test acc:0.4509 ===\n",
      "train loss:1.513542520720432\n",
      "train loss:1.5639822031922832\n",
      "train loss:1.5431152043286755\n",
      "=== epoch:258, train acc:0.5566666666666666, test acc:0.4501 ===\n",
      "train loss:1.6608789049918797\n",
      "train loss:1.4815744342101664\n",
      "train loss:1.6284311437477224\n",
      "=== epoch:259, train acc:0.5766666666666667, test acc:0.458 ===\n",
      "train loss:1.578026104551983\n",
      "train loss:1.5143459698936612\n",
      "train loss:1.5420079234385573\n",
      "=== epoch:260, train acc:0.5666666666666667, test acc:0.4611 ===\n",
      "train loss:1.467308225776656\n",
      "train loss:1.540578148599183\n",
      "train loss:1.4869545021136765\n",
      "=== epoch:261, train acc:0.5633333333333334, test acc:0.4607 ===\n",
      "train loss:1.652751228350843\n",
      "train loss:1.5065410377820112\n",
      "train loss:1.5258318141981777\n",
      "=== epoch:262, train acc:0.56, test acc:0.4615 ===\n",
      "train loss:1.5085999087794866\n",
      "train loss:1.691295848984557\n",
      "train loss:1.5797407013054607\n",
      "=== epoch:263, train acc:0.5733333333333334, test acc:0.468 ===\n",
      "train loss:1.4017571419332417\n",
      "train loss:1.6041199967830957\n",
      "train loss:1.4946689513785163\n",
      "=== epoch:264, train acc:0.5733333333333334, test acc:0.4677 ===\n",
      "train loss:1.6998292393767198\n",
      "train loss:1.676506497468356\n",
      "train loss:1.6259941878189588\n",
      "=== epoch:265, train acc:0.5766666666666667, test acc:0.4754 ===\n",
      "train loss:1.490167587986483\n",
      "train loss:1.601973385926461\n",
      "train loss:1.535853981025663\n",
      "=== epoch:266, train acc:0.5866666666666667, test acc:0.4788 ===\n",
      "train loss:1.4283137910834256\n",
      "train loss:1.4934072908720133\n",
      "train loss:1.6636511637265503\n",
      "=== epoch:267, train acc:0.59, test acc:0.4812 ===\n",
      "train loss:1.4743924327430875\n",
      "train loss:1.5533093769239406\n",
      "train loss:1.5531413734678943\n",
      "=== epoch:268, train acc:0.59, test acc:0.4811 ===\n",
      "train loss:1.6291192666227587\n",
      "train loss:1.5811905005088223\n",
      "train loss:1.5261717886624415\n",
      "=== epoch:269, train acc:0.59, test acc:0.4844 ===\n",
      "train loss:1.54198603430266\n",
      "train loss:1.5676564491742253\n",
      "train loss:1.5962596659269348\n",
      "=== epoch:270, train acc:0.59, test acc:0.4858 ===\n",
      "train loss:1.6188885708844531\n",
      "train loss:1.4587981538524248\n",
      "train loss:1.6663054975333063\n",
      "=== epoch:271, train acc:0.6066666666666667, test acc:0.4937 ===\n",
      "train loss:1.5418689503085878\n",
      "train loss:1.6543760507951675\n",
      "train loss:1.5347102064480254\n",
      "=== epoch:272, train acc:0.6, test acc:0.4951 ===\n",
      "train loss:1.4603810419321335\n",
      "train loss:1.526034618916918\n",
      "train loss:1.5327522047217579\n",
      "=== epoch:273, train acc:0.6066666666666667, test acc:0.4966 ===\n",
      "train loss:1.54177633307209\n",
      "train loss:1.5930613788452828\n",
      "train loss:1.5806851396356887\n",
      "=== epoch:274, train acc:0.62, test acc:0.4974 ===\n",
      "train loss:1.3915642913125894\n",
      "train loss:1.4313202836223429\n",
      "train loss:1.3553027587991715\n",
      "=== epoch:275, train acc:0.61, test acc:0.4956 ===\n",
      "train loss:1.4498197338437493\n",
      "train loss:1.4768906154607644\n",
      "train loss:1.412036118673219\n",
      "=== epoch:276, train acc:0.6233333333333333, test acc:0.501 ===\n",
      "train loss:1.6367896437728233\n",
      "train loss:1.5027948913789044\n",
      "train loss:1.462787161580863\n",
      "=== epoch:277, train acc:0.63, test acc:0.5038 ===\n",
      "train loss:1.5959535339225495\n",
      "train loss:1.5577319279340005\n",
      "train loss:1.4516828930208576\n",
      "=== epoch:278, train acc:0.6366666666666667, test acc:0.5083 ===\n",
      "train loss:1.5595812611555073\n",
      "train loss:1.548186652328552\n",
      "train loss:1.589334997700067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:279, train acc:0.6333333333333333, test acc:0.5096 ===\n",
      "train loss:1.4553105622873341\n",
      "train loss:1.4703993521865493\n",
      "train loss:1.3020288371242774\n",
      "=== epoch:280, train acc:0.6266666666666667, test acc:0.5071 ===\n",
      "train loss:1.4452016116611823\n",
      "train loss:1.5008828204217528\n",
      "train loss:1.536011674168106\n",
      "=== epoch:281, train acc:0.6266666666666667, test acc:0.5063 ===\n",
      "train loss:1.4774701689295902\n",
      "train loss:1.5517365376215657\n",
      "train loss:1.5931491782862768\n",
      "=== epoch:282, train acc:0.6266666666666667, test acc:0.5129 ===\n",
      "train loss:1.424044889538591\n",
      "train loss:1.5577489771101556\n",
      "train loss:1.4534816654515823\n",
      "=== epoch:283, train acc:0.6266666666666667, test acc:0.5149 ===\n",
      "train loss:1.3895973129686618\n",
      "train loss:1.5438646029334044\n",
      "train loss:1.4260139922615174\n",
      "=== epoch:284, train acc:0.6266666666666667, test acc:0.5166 ===\n",
      "train loss:1.5145380853154555\n",
      "train loss:1.3327760049570188\n",
      "train loss:1.3505158370507269\n",
      "=== epoch:285, train acc:0.6233333333333333, test acc:0.5157 ===\n",
      "train loss:1.5000325851342293\n",
      "train loss:1.4190113440277576\n",
      "train loss:1.457108976508914\n",
      "=== epoch:286, train acc:0.6266666666666667, test acc:0.5173 ===\n",
      "train loss:1.4489097894371248\n",
      "train loss:1.4903054088042058\n",
      "train loss:1.3829805398472035\n",
      "=== epoch:287, train acc:0.6266666666666667, test acc:0.5184 ===\n",
      "train loss:1.4379440612876937\n",
      "train loss:1.442247513150469\n",
      "train loss:1.3942216493537065\n",
      "=== epoch:288, train acc:0.6366666666666667, test acc:0.5206 ===\n",
      "train loss:1.477876366171961\n",
      "train loss:1.3292419074841428\n",
      "train loss:1.4383474085278758\n",
      "=== epoch:289, train acc:0.6333333333333333, test acc:0.5188 ===\n",
      "train loss:1.4474861972547424\n",
      "train loss:1.592215960396953\n",
      "train loss:1.3771149462003782\n",
      "=== epoch:290, train acc:0.6466666666666666, test acc:0.5216 ===\n",
      "train loss:1.411560564248323\n",
      "train loss:1.43686854635212\n",
      "train loss:1.460102571664828\n",
      "=== epoch:291, train acc:0.6466666666666666, test acc:0.5232 ===\n",
      "train loss:1.4921590685775348\n",
      "train loss:1.445163468186879\n",
      "train loss:1.3495402876832336\n",
      "=== epoch:292, train acc:0.6433333333333333, test acc:0.5232 ===\n",
      "train loss:1.455340930606291\n",
      "train loss:1.3523802614822125\n",
      "train loss:1.3420076733703568\n",
      "=== epoch:293, train acc:0.6433333333333333, test acc:0.5253 ===\n",
      "train loss:1.2659415718157385\n",
      "train loss:1.183128708300532\n",
      "train loss:1.226532926197722\n",
      "=== epoch:294, train acc:0.6466666666666666, test acc:0.5235 ===\n",
      "train loss:1.2865705500653133\n",
      "train loss:1.3187778104657522\n",
      "train loss:1.3680951327099562\n",
      "=== epoch:295, train acc:0.64, test acc:0.5228 ===\n",
      "train loss:1.3619782340113162\n",
      "train loss:1.3302484515108963\n",
      "train loss:1.3913262907369588\n",
      "=== epoch:296, train acc:0.6433333333333333, test acc:0.5259 ===\n",
      "train loss:1.4949617509875197\n",
      "train loss:1.4131518674903818\n",
      "train loss:1.3565958476933302\n",
      "=== epoch:297, train acc:0.64, test acc:0.5261 ===\n",
      "train loss:1.2329657698473375\n",
      "train loss:1.2685285528345362\n",
      "train loss:1.331318243639174\n",
      "=== epoch:298, train acc:0.6466666666666666, test acc:0.5266 ===\n",
      "train loss:1.4572919729158569\n",
      "train loss:1.2994155618637293\n",
      "train loss:1.4092441854148898\n",
      "=== epoch:299, train acc:0.6466666666666666, test acc:0.531 ===\n",
      "train loss:1.1992382098316323\n",
      "train loss:1.3897641489524617\n",
      "train loss:1.3473542684533217\n",
      "=== epoch:300, train acc:0.6466666666666666, test acc:0.5285 ===\n",
      "train loss:1.2655536051249152\n",
      "train loss:1.4555307194004272\n",
      "train loss:1.4098315446518024\n",
      "=== epoch:301, train acc:0.6466666666666666, test acc:0.5281 ===\n",
      "train loss:1.3734766399449354\n",
      "train loss:1.2088179290346939\n",
      "train loss:1.348177708554732\n",
      "=== epoch:302, train acc:0.6466666666666666, test acc:0.5282 ===\n",
      "train loss:1.3134407630102531\n",
      "train loss:1.4339966277118206\n",
      "train loss:1.4336500458171662\n",
      "=== epoch:303, train acc:0.6433333333333333, test acc:0.5317 ===\n",
      "train loss:1.2811793858061253\n",
      "train loss:1.276626378036971\n",
      "train loss:1.2944204317726968\n",
      "=== epoch:304, train acc:0.65, test acc:0.5357 ===\n",
      "train loss:1.4197074463918253\n",
      "train loss:1.2239227649909794\n",
      "train loss:1.4065005718906765\n",
      "=== epoch:305, train acc:0.65, test acc:0.5394 ===\n",
      "train loss:1.2147940935084218\n",
      "train loss:1.304323520267043\n",
      "train loss:1.2547481981464792\n",
      "=== epoch:306, train acc:0.66, test acc:0.5401 ===\n",
      "train loss:1.2280621162574257\n",
      "train loss:1.348926291845099\n",
      "train loss:1.189421407998718\n",
      "=== epoch:307, train acc:0.6633333333333333, test acc:0.544 ===\n",
      "train loss:1.2331093984700379\n",
      "train loss:1.2990226438336694\n",
      "train loss:1.3223862024988013\n",
      "=== epoch:308, train acc:0.67, test acc:0.5448 ===\n",
      "train loss:1.254749361378746\n",
      "train loss:1.2192611824708555\n",
      "train loss:1.2247882873518772\n",
      "=== epoch:309, train acc:0.6566666666666666, test acc:0.5427 ===\n",
      "train loss:1.1997919440468234\n",
      "train loss:1.250351832213198\n",
      "train loss:1.288040059914418\n",
      "=== epoch:310, train acc:0.66, test acc:0.5394 ===\n",
      "train loss:1.2468328533729476\n",
      "train loss:1.2640019784173198\n",
      "train loss:1.2711138927969068\n",
      "=== epoch:311, train acc:0.6566666666666666, test acc:0.5377 ===\n",
      "train loss:1.303677232948963\n",
      "train loss:1.2340026404394628\n",
      "train loss:1.234579884657696\n",
      "=== epoch:312, train acc:0.6566666666666666, test acc:0.5367 ===\n",
      "train loss:1.2727419675884237\n",
      "train loss:1.3280132987285755\n",
      "train loss:1.2974298274660392\n",
      "=== epoch:313, train acc:0.6566666666666666, test acc:0.5347 ===\n",
      "train loss:1.2794183033092188\n",
      "train loss:1.3098229654965903\n",
      "train loss:1.2413457973545028\n",
      "=== epoch:314, train acc:0.66, test acc:0.5404 ===\n",
      "train loss:1.2971877704882955\n",
      "train loss:1.0999699863622923\n",
      "train loss:1.354504503789874\n",
      "=== epoch:315, train acc:0.66, test acc:0.5406 ===\n",
      "train loss:1.239045495099138\n",
      "train loss:1.1630797055507593\n",
      "train loss:1.1919572410174901\n",
      "=== epoch:316, train acc:0.65, test acc:0.5395 ===\n",
      "train loss:1.277763293022727\n",
      "train loss:1.192779058960879\n",
      "train loss:1.2374942775312021\n",
      "=== epoch:317, train acc:0.66, test acc:0.544 ===\n",
      "train loss:1.0684235450650847\n",
      "train loss:1.1821766071331228\n",
      "train loss:1.2687452126867753\n",
      "=== epoch:318, train acc:0.66, test acc:0.5447 ===\n",
      "train loss:1.2290490537024958\n",
      "train loss:1.069681854449805\n",
      "train loss:1.1944689266943598\n",
      "=== epoch:319, train acc:0.6633333333333333, test acc:0.5469 ===\n",
      "train loss:1.1245986709785731\n",
      "train loss:1.3023247341810222\n",
      "train loss:1.2862769132673286\n",
      "=== epoch:320, train acc:0.67, test acc:0.5482 ===\n",
      "train loss:1.2653507532703017\n",
      "train loss:1.3006981876331773\n",
      "train loss:1.1879256888767626\n",
      "=== epoch:321, train acc:0.6733333333333333, test acc:0.5539 ===\n",
      "train loss:1.1094998471501112\n",
      "train loss:1.2176062755789676\n",
      "train loss:1.3360931316557794\n",
      "=== epoch:322, train acc:0.6833333333333333, test acc:0.5564 ===\n",
      "train loss:1.1686516484584673\n",
      "train loss:1.181505185417371\n",
      "train loss:1.1262631748614043\n",
      "=== epoch:323, train acc:0.6833333333333333, test acc:0.5633 ===\n",
      "train loss:1.0848697712737014\n",
      "train loss:1.167440760617158\n",
      "train loss:1.249551322170732\n",
      "=== epoch:324, train acc:0.6833333333333333, test acc:0.563 ===\n",
      "train loss:1.2333907871074856\n",
      "train loss:1.0695808860655096\n",
      "train loss:1.2089450913556208\n",
      "=== epoch:325, train acc:0.6966666666666667, test acc:0.5669 ===\n",
      "train loss:1.3378032057825147\n",
      "train loss:1.1463193657198383\n",
      "train loss:1.1570809390004486\n",
      "=== epoch:326, train acc:0.7066666666666667, test acc:0.5689 ===\n",
      "train loss:1.053169613718103\n",
      "train loss:1.0431273237590468\n",
      "train loss:1.1353737482194826\n",
      "=== epoch:327, train acc:0.72, test acc:0.5715 ===\n",
      "train loss:1.1392442904023548\n",
      "train loss:1.0843784685827205\n",
      "train loss:1.1565781523416003\n",
      "=== epoch:328, train acc:0.71, test acc:0.5757 ===\n",
      "train loss:1.0390075487021282\n",
      "train loss:1.1882734387241494\n",
      "train loss:1.2025533742022254\n",
      "=== epoch:329, train acc:0.7166666666666667, test acc:0.5748 ===\n",
      "train loss:1.1288566662099253\n",
      "train loss:1.1654377932084696\n",
      "train loss:1.1754957948873415\n",
      "=== epoch:330, train acc:0.72, test acc:0.5765 ===\n",
      "train loss:1.3638951312737746\n",
      "train loss:1.18182289280782\n",
      "train loss:1.17327425905078\n",
      "=== epoch:331, train acc:0.71, test acc:0.5747 ===\n",
      "train loss:1.1854794178079497\n",
      "train loss:1.1192411214041835\n",
      "train loss:1.166966244864156\n",
      "=== epoch:332, train acc:0.72, test acc:0.5749 ===\n",
      "train loss:1.2235557721616914\n",
      "train loss:1.2074504305781346\n",
      "train loss:1.0435512046459055\n",
      "=== epoch:333, train acc:0.7233333333333334, test acc:0.5783 ===\n",
      "train loss:1.183320110636405\n",
      "train loss:1.0642508598136224\n",
      "train loss:1.0201563651051802\n",
      "=== epoch:334, train acc:0.7266666666666667, test acc:0.5818 ===\n",
      "train loss:0.9475192401853195\n",
      "train loss:1.0881706003126896\n",
      "train loss:1.2079916213875344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:335, train acc:0.7266666666666667, test acc:0.5844 ===\n",
      "train loss:1.1086115105737449\n",
      "train loss:1.2061339179495203\n",
      "train loss:1.0649039249102175\n",
      "=== epoch:336, train acc:0.73, test acc:0.5857 ===\n",
      "train loss:1.061871159851841\n",
      "train loss:1.0633906646288716\n",
      "train loss:1.014919393506745\n",
      "=== epoch:337, train acc:0.7266666666666667, test acc:0.5848 ===\n",
      "train loss:1.1307494382480572\n",
      "train loss:1.0925488798293346\n",
      "train loss:1.187800586325223\n",
      "=== epoch:338, train acc:0.7333333333333333, test acc:0.5891 ===\n",
      "train loss:1.0894950777992432\n",
      "train loss:1.087525399401003\n",
      "train loss:1.1564140391377757\n",
      "=== epoch:339, train acc:0.7366666666666667, test acc:0.5934 ===\n",
      "train loss:0.9923674010248227\n",
      "train loss:1.170829632597962\n",
      "train loss:1.0435852876975773\n",
      "=== epoch:340, train acc:0.7333333333333333, test acc:0.5928 ===\n",
      "train loss:1.112583167037923\n",
      "train loss:1.18471431339261\n",
      "train loss:1.1139717777435643\n",
      "=== epoch:341, train acc:0.7433333333333333, test acc:0.5966 ===\n",
      "train loss:0.9891523642718982\n",
      "train loss:1.1068694777023353\n",
      "train loss:1.1294244645092057\n",
      "=== epoch:342, train acc:0.75, test acc:0.5978 ===\n",
      "train loss:1.123578926578312\n",
      "train loss:1.1042466588923117\n",
      "train loss:1.1434601152444563\n",
      "=== epoch:343, train acc:0.7533333333333333, test acc:0.6043 ===\n",
      "train loss:1.0501689696054743\n",
      "train loss:1.075296581412152\n",
      "train loss:1.0363390897979463\n",
      "=== epoch:344, train acc:0.7533333333333333, test acc:0.6041 ===\n",
      "train loss:0.8859362014659264\n",
      "train loss:1.0090259769746133\n",
      "train loss:1.0532098502877394\n",
      "=== epoch:345, train acc:0.7566666666666667, test acc:0.599 ===\n",
      "train loss:1.071263600282387\n",
      "train loss:1.1259556594138846\n",
      "train loss:1.0790741539686315\n",
      "=== epoch:346, train acc:0.7566666666666667, test acc:0.5986 ===\n",
      "train loss:0.9623270705851581\n",
      "train loss:0.9481837713227034\n",
      "train loss:1.1184577682245216\n",
      "=== epoch:347, train acc:0.76, test acc:0.5975 ===\n",
      "train loss:1.0065305352975091\n",
      "train loss:1.0107689958664183\n",
      "train loss:1.0643673100524005\n",
      "=== epoch:348, train acc:0.7633333333333333, test acc:0.6041 ===\n",
      "train loss:1.0643957887822166\n",
      "train loss:0.9792969423887815\n",
      "train loss:1.0236008891553245\n",
      "=== epoch:349, train acc:0.76, test acc:0.6054 ===\n",
      "train loss:1.065254072001334\n",
      "train loss:1.0097050998082961\n",
      "train loss:1.0039476113010513\n",
      "=== epoch:350, train acc:0.7533333333333333, test acc:0.6014 ===\n",
      "train loss:1.0972411188394597\n",
      "train loss:0.9533000982796566\n",
      "train loss:1.0224566705548095\n",
      "=== epoch:351, train acc:0.76, test acc:0.6059 ===\n",
      "train loss:1.031458338096757\n",
      "train loss:1.008475776946907\n",
      "train loss:0.9452192763893253\n",
      "=== epoch:352, train acc:0.75, test acc:0.6036 ===\n",
      "train loss:0.9169325430822886\n",
      "train loss:0.9160556092221028\n",
      "train loss:1.0130319792208897\n",
      "=== epoch:353, train acc:0.7533333333333333, test acc:0.6011 ===\n",
      "train loss:0.9247295097473939\n",
      "train loss:1.0293247553956142\n",
      "train loss:1.0285289247407556\n",
      "=== epoch:354, train acc:0.7633333333333333, test acc:0.6012 ===\n",
      "train loss:0.9696572888378061\n",
      "train loss:0.9191474911250294\n",
      "train loss:1.1263509617832637\n",
      "=== epoch:355, train acc:0.7533333333333333, test acc:0.6033 ===\n",
      "train loss:1.0331572194068182\n",
      "train loss:0.9632209864203527\n",
      "train loss:0.9133008900464799\n",
      "=== epoch:356, train acc:0.76, test acc:0.6076 ===\n",
      "train loss:1.0325116851580036\n",
      "train loss:0.9066326945104793\n",
      "train loss:0.9690064726598522\n",
      "=== epoch:357, train acc:0.7533333333333333, test acc:0.6022 ===\n",
      "train loss:1.0258979384486042\n",
      "train loss:1.017122170372742\n",
      "train loss:0.8690979778959063\n",
      "=== epoch:358, train acc:0.7566666666666667, test acc:0.6058 ===\n",
      "train loss:0.9992421399493636\n",
      "train loss:0.7959089757995019\n",
      "train loss:0.9136677571511603\n",
      "=== epoch:359, train acc:0.76, test acc:0.6071 ===\n",
      "train loss:1.0513543873876967\n",
      "train loss:0.9767245492840495\n",
      "train loss:1.010831018334971\n",
      "=== epoch:360, train acc:0.7633333333333333, test acc:0.6074 ===\n",
      "train loss:0.97870387864416\n",
      "train loss:0.9625810336467076\n",
      "train loss:1.05457901411191\n",
      "=== epoch:361, train acc:0.77, test acc:0.6078 ===\n",
      "train loss:1.0408278640918724\n",
      "train loss:1.0986759542374942\n",
      "train loss:0.9963189906430856\n",
      "=== epoch:362, train acc:0.7733333333333333, test acc:0.6107 ===\n",
      "train loss:0.8370853410543104\n",
      "train loss:0.8620970526938456\n",
      "train loss:0.9623993215389882\n",
      "=== epoch:363, train acc:0.77, test acc:0.6097 ===\n",
      "train loss:0.9942889306480961\n",
      "train loss:0.9055602589421263\n",
      "train loss:0.8744641398655304\n",
      "=== epoch:364, train acc:0.78, test acc:0.6151 ===\n",
      "train loss:0.9008704752882275\n",
      "train loss:0.9799664381892818\n",
      "train loss:0.9911853246679558\n",
      "=== epoch:365, train acc:0.7766666666666666, test acc:0.6176 ===\n",
      "train loss:0.9588029228445558\n",
      "train loss:0.9646862414862306\n",
      "train loss:0.9261032476751292\n",
      "=== epoch:366, train acc:0.78, test acc:0.6179 ===\n",
      "train loss:1.0017705048374888\n",
      "train loss:0.7769163512025966\n",
      "train loss:0.9548442599198569\n",
      "=== epoch:367, train acc:0.76, test acc:0.6144 ===\n",
      "train loss:1.0726977264913644\n",
      "train loss:0.9909188424967341\n",
      "train loss:0.8237105122296887\n",
      "=== epoch:368, train acc:0.77, test acc:0.614 ===\n",
      "train loss:0.9241030549658464\n",
      "train loss:0.8329180484837599\n",
      "train loss:0.9626332133588223\n",
      "=== epoch:369, train acc:0.78, test acc:0.6175 ===\n",
      "train loss:0.9360978043213949\n",
      "train loss:0.7988734686593076\n",
      "train loss:0.9125608425678093\n",
      "=== epoch:370, train acc:0.7833333333333333, test acc:0.6177 ===\n",
      "train loss:0.8981308157394123\n",
      "train loss:0.823169616267386\n",
      "train loss:0.9231452925082716\n",
      "=== epoch:371, train acc:0.78, test acc:0.6159 ===\n",
      "train loss:0.841043433830223\n",
      "train loss:0.8485542340538926\n",
      "train loss:0.8056409599556588\n",
      "=== epoch:372, train acc:0.7866666666666666, test acc:0.616 ===\n",
      "train loss:0.8327710176247198\n",
      "train loss:0.9509424654916425\n",
      "train loss:0.9308055239487478\n",
      "=== epoch:373, train acc:0.78, test acc:0.6197 ===\n",
      "train loss:0.8873562855403029\n",
      "train loss:0.9861209499559463\n",
      "train loss:0.8412418910983241\n",
      "=== epoch:374, train acc:0.7866666666666666, test acc:0.6221 ===\n",
      "train loss:0.9774280104882337\n",
      "train loss:0.8059231724413175\n",
      "train loss:0.8759524793749024\n",
      "=== epoch:375, train acc:0.79, test acc:0.6215 ===\n",
      "train loss:0.934922132012492\n",
      "train loss:0.7879731475988961\n",
      "train loss:0.8317602960352167\n",
      "=== epoch:376, train acc:0.7833333333333333, test acc:0.6221 ===\n",
      "train loss:0.9470174156865826\n",
      "train loss:0.8174437449971134\n",
      "train loss:0.8685714528641948\n",
      "=== epoch:377, train acc:0.7966666666666666, test acc:0.6229 ===\n",
      "train loss:0.8656727585326077\n",
      "train loss:0.8151168671307387\n",
      "train loss:0.8428655846662125\n",
      "=== epoch:378, train acc:0.7833333333333333, test acc:0.6227 ===\n",
      "train loss:0.8882980056466504\n",
      "train loss:0.8026388278095312\n",
      "train loss:0.7026199806298823\n",
      "=== epoch:379, train acc:0.79, test acc:0.6265 ===\n",
      "train loss:0.8122101045411069\n",
      "train loss:0.9338473498823615\n",
      "train loss:0.8093222034131214\n",
      "=== epoch:380, train acc:0.7866666666666666, test acc:0.627 ===\n",
      "train loss:0.9589022126558895\n",
      "train loss:0.8505885460926002\n",
      "train loss:0.7693729998475146\n",
      "=== epoch:381, train acc:0.7833333333333333, test acc:0.6257 ===\n",
      "train loss:0.8297181063639356\n",
      "train loss:0.858329025456383\n",
      "train loss:0.9039748345536573\n",
      "=== epoch:382, train acc:0.79, test acc:0.6241 ===\n",
      "train loss:0.8425727753931785\n",
      "train loss:0.8422863760762556\n",
      "train loss:0.8140094974983266\n",
      "=== epoch:383, train acc:0.79, test acc:0.6256 ===\n",
      "train loss:0.810591371613248\n",
      "train loss:0.7574321029594084\n",
      "train loss:0.9027972629439235\n",
      "=== epoch:384, train acc:0.7833333333333333, test acc:0.6278 ===\n",
      "train loss:0.734621385222784\n",
      "train loss:0.6938760130793485\n",
      "train loss:0.8524233134079258\n",
      "=== epoch:385, train acc:0.7833333333333333, test acc:0.6276 ===\n",
      "train loss:0.87850641422083\n",
      "train loss:0.8273136935719927\n",
      "train loss:0.803977889171011\n",
      "=== epoch:386, train acc:0.79, test acc:0.6281 ===\n",
      "train loss:0.9312704720246485\n",
      "train loss:0.8116911488975166\n",
      "train loss:0.7249385566775259\n",
      "=== epoch:387, train acc:0.7966666666666666, test acc:0.632 ===\n",
      "train loss:0.810445221531863\n",
      "train loss:0.8423128979767744\n",
      "train loss:0.7569826930565137\n",
      "=== epoch:388, train acc:0.79, test acc:0.6344 ===\n",
      "train loss:0.7841105945925456\n",
      "train loss:0.7639869020870623\n",
      "train loss:0.6927145204032371\n",
      "=== epoch:389, train acc:0.7866666666666666, test acc:0.6303 ===\n",
      "train loss:0.822972336888993\n",
      "train loss:0.8434149659475041\n",
      "train loss:0.7652391230864992\n",
      "=== epoch:390, train acc:0.7866666666666666, test acc:0.6299 ===\n",
      "train loss:0.8288314550925184\n",
      "train loss:0.7523038772504513\n",
      "train loss:0.6748987735629645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:391, train acc:0.7966666666666666, test acc:0.6346 ===\n",
      "train loss:0.8387246959959167\n",
      "train loss:0.8600942761972129\n",
      "train loss:0.806419903046344\n",
      "=== epoch:392, train acc:0.8033333333333333, test acc:0.6335 ===\n",
      "train loss:0.7919734646971618\n",
      "train loss:0.7932213532586122\n",
      "train loss:0.7028086342497035\n",
      "=== epoch:393, train acc:0.7933333333333333, test acc:0.6348 ===\n",
      "train loss:0.7472566888501526\n",
      "train loss:0.7477722283698338\n",
      "train loss:0.8033277422630631\n",
      "=== epoch:394, train acc:0.79, test acc:0.6357 ===\n",
      "train loss:0.7430699813351339\n",
      "train loss:0.7098941029299004\n",
      "train loss:0.6824353645249143\n",
      "=== epoch:395, train acc:0.79, test acc:0.6366 ===\n",
      "train loss:0.7481745593223416\n",
      "train loss:0.6578571584743149\n",
      "train loss:0.6385118616342254\n",
      "=== epoch:396, train acc:0.7866666666666666, test acc:0.635 ===\n",
      "train loss:0.7489731054447694\n",
      "train loss:0.9066579961582956\n",
      "train loss:0.6519780113682242\n",
      "=== epoch:397, train acc:0.7966666666666666, test acc:0.638 ===\n",
      "train loss:0.782244847230315\n",
      "train loss:0.6557117716747591\n",
      "train loss:0.7287609016547633\n",
      "=== epoch:398, train acc:0.79, test acc:0.6361 ===\n",
      "train loss:0.6947491262048396\n",
      "train loss:0.7259352965246344\n",
      "train loss:0.6990465634052709\n",
      "=== epoch:399, train acc:0.7933333333333333, test acc:0.6359 ===\n",
      "train loss:0.8504124796905308\n",
      "train loss:0.6323671002947536\n",
      "train loss:0.7680466585842981\n",
      "=== epoch:400, train acc:0.8033333333333333, test acc:0.6363 ===\n",
      "train loss:0.7633899591418135\n",
      "train loss:0.8510452379224382\n",
      "train loss:0.6416826743780204\n",
      "=== epoch:401, train acc:0.81, test acc:0.6398 ===\n",
      "train loss:0.6787212666102724\n",
      "train loss:0.6490887392100211\n",
      "train loss:0.6596630133274678\n",
      "=== epoch:402, train acc:0.8066666666666666, test acc:0.6411 ===\n",
      "train loss:0.7923157194437458\n",
      "train loss:0.7425828772394237\n",
      "train loss:0.7067451805323239\n",
      "=== epoch:403, train acc:0.8066666666666666, test acc:0.6418 ===\n",
      "train loss:0.7333642156078475\n",
      "train loss:0.6591099602605378\n",
      "train loss:0.8067099534305932\n",
      "=== epoch:404, train acc:0.8, test acc:0.6416 ===\n",
      "train loss:0.6634250282995482\n",
      "train loss:0.6409415503932604\n",
      "train loss:0.7699392477912538\n",
      "=== epoch:405, train acc:0.8033333333333333, test acc:0.6414 ===\n",
      "train loss:0.6740744583045872\n",
      "train loss:0.6759331427501261\n",
      "train loss:0.664100284592128\n",
      "=== epoch:406, train acc:0.8066666666666666, test acc:0.6398 ===\n",
      "train loss:0.5655526756065783\n",
      "train loss:0.7632964966347775\n",
      "train loss:0.6202688223139875\n",
      "=== epoch:407, train acc:0.8033333333333333, test acc:0.6399 ===\n",
      "train loss:0.5181901433973917\n",
      "train loss:0.6219285701223028\n",
      "train loss:0.581440434003658\n",
      "=== epoch:408, train acc:0.8, test acc:0.6368 ===\n",
      "train loss:0.6671748558579546\n",
      "train loss:0.6266304443981471\n",
      "train loss:0.7291181019304248\n",
      "=== epoch:409, train acc:0.8, test acc:0.6407 ===\n",
      "train loss:0.6927565373575871\n",
      "train loss:0.7702083367929042\n",
      "train loss:0.7507676242192077\n",
      "=== epoch:410, train acc:0.8033333333333333, test acc:0.6438 ===\n",
      "train loss:0.7895398476460797\n",
      "train loss:0.7010973613367508\n",
      "train loss:0.7777171744415896\n",
      "=== epoch:411, train acc:0.7966666666666666, test acc:0.6438 ===\n",
      "train loss:0.6337553738695285\n",
      "train loss:0.7109560541740536\n",
      "train loss:0.7532629321775217\n",
      "=== epoch:412, train acc:0.8066666666666666, test acc:0.6454 ===\n",
      "train loss:0.7486993319187006\n",
      "train loss:0.6252506870102675\n",
      "train loss:0.561684315765982\n",
      "=== epoch:413, train acc:0.81, test acc:0.6483 ===\n",
      "train loss:0.5629244415712947\n",
      "train loss:0.6659171520155489\n",
      "train loss:0.7271852511849566\n",
      "=== epoch:414, train acc:0.8133333333333334, test acc:0.6492 ===\n",
      "train loss:0.5790159870220343\n",
      "train loss:0.689606097390829\n",
      "train loss:0.6343505799595097\n",
      "=== epoch:415, train acc:0.8133333333333334, test acc:0.6489 ===\n",
      "train loss:0.6532318596789598\n",
      "train loss:0.811300213552022\n",
      "train loss:0.6366718471909772\n",
      "=== epoch:416, train acc:0.81, test acc:0.6489 ===\n",
      "train loss:0.703890438488867\n",
      "train loss:0.7333804473881466\n",
      "train loss:0.7050901887020192\n",
      "=== epoch:417, train acc:0.8066666666666666, test acc:0.6488 ===\n",
      "train loss:0.7440040228850249\n",
      "train loss:0.7058833010976356\n",
      "train loss:0.7051167333676096\n",
      "=== epoch:418, train acc:0.8, test acc:0.651 ===\n",
      "train loss:0.7287708669244359\n",
      "train loss:0.7197708020537017\n",
      "train loss:0.5569643733510722\n",
      "=== epoch:419, train acc:0.8133333333333334, test acc:0.6532 ===\n",
      "train loss:0.6361730100407843\n",
      "train loss:0.6880336672963544\n",
      "train loss:0.7175999570468343\n",
      "=== epoch:420, train acc:0.8133333333333334, test acc:0.6527 ===\n",
      "train loss:0.7347185244855275\n",
      "train loss:0.7185363939152702\n",
      "train loss:0.6526472552057356\n",
      "=== epoch:421, train acc:0.8266666666666667, test acc:0.6556 ===\n",
      "train loss:0.7217659547645993\n",
      "train loss:0.6756985828390062\n",
      "train loss:0.6947261996309099\n",
      "=== epoch:422, train acc:0.82, test acc:0.6555 ===\n",
      "train loss:0.5789645204772672\n",
      "train loss:0.6401332497777246\n",
      "train loss:0.5387803719440453\n",
      "=== epoch:423, train acc:0.82, test acc:0.6537 ===\n",
      "train loss:0.5739533107717841\n",
      "train loss:0.587403251839635\n",
      "train loss:0.49968678486956686\n",
      "=== epoch:424, train acc:0.82, test acc:0.656 ===\n",
      "train loss:0.6887903602764404\n",
      "train loss:0.6867241183033689\n",
      "train loss:0.8551913085454125\n",
      "=== epoch:425, train acc:0.8266666666666667, test acc:0.6577 ===\n",
      "train loss:0.626241342119245\n",
      "train loss:0.6844740216822963\n",
      "train loss:0.6432937948805189\n",
      "=== epoch:426, train acc:0.8266666666666667, test acc:0.6577 ===\n",
      "train loss:0.5817133207759321\n",
      "train loss:0.4960255915069544\n",
      "train loss:0.5030790141179076\n",
      "=== epoch:427, train acc:0.82, test acc:0.6583 ===\n",
      "train loss:0.6040095644930108\n",
      "train loss:0.6313649754867627\n",
      "train loss:0.6012140551052859\n",
      "=== epoch:428, train acc:0.8233333333333334, test acc:0.6583 ===\n",
      "train loss:0.6304475263760071\n",
      "train loss:0.5669782362527193\n",
      "train loss:0.5540959936520337\n",
      "=== epoch:429, train acc:0.82, test acc:0.6574 ===\n",
      "train loss:0.5708196790844127\n",
      "train loss:0.6253518665607035\n",
      "train loss:0.5841353842141769\n",
      "=== epoch:430, train acc:0.8266666666666667, test acc:0.6584 ===\n",
      "train loss:0.6517769574460707\n",
      "train loss:0.578159121945633\n",
      "train loss:0.5805570810386979\n",
      "=== epoch:431, train acc:0.8166666666666667, test acc:0.6545 ===\n",
      "train loss:0.5920755492456025\n",
      "train loss:0.5584007617671913\n",
      "train loss:0.5823906719340151\n",
      "=== epoch:432, train acc:0.8233333333333334, test acc:0.6582 ===\n",
      "train loss:0.6861395818111566\n",
      "train loss:0.6931551524431849\n",
      "train loss:0.5435578330753591\n",
      "=== epoch:433, train acc:0.83, test acc:0.6605 ===\n",
      "train loss:0.4898902857748538\n",
      "train loss:0.5649868814002397\n",
      "train loss:0.6667511310878642\n",
      "=== epoch:434, train acc:0.83, test acc:0.6574 ===\n",
      "train loss:0.5868676832263923\n",
      "train loss:0.6223520236166563\n",
      "train loss:0.6523424385597443\n",
      "=== epoch:435, train acc:0.8266666666666667, test acc:0.6566 ===\n",
      "train loss:0.4918533995944013\n",
      "train loss:0.6172734716044929\n",
      "train loss:0.5823961854064044\n",
      "=== epoch:436, train acc:0.83, test acc:0.6609 ===\n",
      "train loss:0.5896388361786921\n",
      "train loss:0.5551885876928874\n",
      "train loss:0.6014154002299466\n",
      "=== epoch:437, train acc:0.8333333333333334, test acc:0.6631 ===\n",
      "train loss:0.5242329536570406\n",
      "train loss:0.6382171907092133\n",
      "train loss:0.5945681180627601\n",
      "=== epoch:438, train acc:0.8333333333333334, test acc:0.6626 ===\n",
      "train loss:0.5488361191119128\n",
      "train loss:0.47552087668371196\n",
      "train loss:0.5196760286804663\n",
      "=== epoch:439, train acc:0.84, test acc:0.6636 ===\n",
      "train loss:0.6554116236320847\n",
      "train loss:0.7182046031861863\n",
      "train loss:0.7045500742486961\n",
      "=== epoch:440, train acc:0.8466666666666667, test acc:0.6656 ===\n",
      "train loss:0.6034987283663328\n",
      "train loss:0.5715579913215543\n",
      "train loss:0.612163954225225\n",
      "=== epoch:441, train acc:0.8533333333333334, test acc:0.6693 ===\n",
      "train loss:0.5128325300323043\n",
      "train loss:0.5941151262494858\n",
      "train loss:0.6216917193968782\n",
      "=== epoch:442, train acc:0.85, test acc:0.6688 ===\n",
      "train loss:0.6241177838817019\n",
      "train loss:0.5712127319575654\n",
      "train loss:0.5821743824654981\n",
      "=== epoch:443, train acc:0.8433333333333334, test acc:0.667 ===\n",
      "train loss:0.620292492238982\n",
      "train loss:0.5890956935879609\n",
      "train loss:0.5385317588559739\n",
      "=== epoch:444, train acc:0.8533333333333334, test acc:0.6702 ===\n",
      "train loss:0.6424479596321281\n",
      "train loss:0.6666741214222303\n",
      "train loss:0.387790079686156\n",
      "=== epoch:445, train acc:0.85, test acc:0.6691 ===\n",
      "train loss:0.5694589494293993\n",
      "train loss:0.4429267134895129\n",
      "train loss:0.637130662966363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:446, train acc:0.8533333333333334, test acc:0.6697 ===\n",
      "train loss:0.6328191598757669\n",
      "train loss:0.6205318896046795\n",
      "train loss:0.5255056981953764\n",
      "=== epoch:447, train acc:0.8533333333333334, test acc:0.6722 ===\n",
      "train loss:0.6256147251486358\n",
      "train loss:0.5749479241920499\n",
      "train loss:0.5683955240214742\n",
      "=== epoch:448, train acc:0.8533333333333334, test acc:0.6744 ===\n",
      "train loss:0.5894827136767241\n",
      "train loss:0.48726576935719373\n",
      "train loss:0.5359766627368466\n",
      "=== epoch:449, train acc:0.8566666666666667, test acc:0.6731 ===\n",
      "train loss:0.5250407798785119\n",
      "train loss:0.4321894438574627\n",
      "train loss:0.542166731978522\n",
      "=== epoch:450, train acc:0.86, test acc:0.6751 ===\n",
      "train loss:0.4280952105852267\n",
      "train loss:0.5601847036820028\n",
      "train loss:0.4529248469311055\n",
      "=== epoch:451, train acc:0.8566666666666667, test acc:0.6748 ===\n",
      "train loss:0.5569119369999169\n",
      "train loss:0.4703057221831612\n",
      "train loss:0.5115218034477433\n",
      "=== epoch:452, train acc:0.8533333333333334, test acc:0.6742 ===\n",
      "train loss:0.5022923140427724\n",
      "train loss:0.4795954959863416\n",
      "train loss:0.4923893931248476\n",
      "=== epoch:453, train acc:0.8533333333333334, test acc:0.6746 ===\n",
      "train loss:0.3626789830567369\n",
      "train loss:0.5591269827636774\n",
      "train loss:0.4994460226962085\n",
      "=== epoch:454, train acc:0.8566666666666667, test acc:0.6754 ===\n",
      "train loss:0.5324457579023106\n",
      "train loss:0.5966540761467977\n",
      "train loss:0.5718453929804902\n",
      "=== epoch:455, train acc:0.86, test acc:0.6781 ===\n",
      "train loss:0.6713432665494794\n",
      "train loss:0.6504922455237611\n",
      "train loss:0.6023821565291596\n",
      "=== epoch:456, train acc:0.8633333333333333, test acc:0.6784 ===\n",
      "train loss:0.6416141331153945\n",
      "train loss:0.5395492670185191\n",
      "train loss:0.4320212257391931\n",
      "=== epoch:457, train acc:0.8566666666666667, test acc:0.6795 ===\n",
      "train loss:0.5000263619204335\n",
      "train loss:0.5254863106807393\n",
      "train loss:0.5479477926352244\n",
      "=== epoch:458, train acc:0.86, test acc:0.6768 ===\n",
      "train loss:0.45380167093721335\n",
      "train loss:0.5616325228334778\n",
      "train loss:0.493974781835378\n",
      "=== epoch:459, train acc:0.8566666666666667, test acc:0.6799 ===\n",
      "train loss:0.5247844106503821\n",
      "train loss:0.4894675019734883\n",
      "train loss:0.5754071977681423\n",
      "=== epoch:460, train acc:0.8566666666666667, test acc:0.6766 ===\n",
      "train loss:0.4842654777441347\n",
      "train loss:0.5668776266644535\n",
      "train loss:0.48705898498488104\n",
      "=== epoch:461, train acc:0.8633333333333333, test acc:0.6749 ===\n",
      "train loss:0.5681030931288641\n",
      "train loss:0.5864444312776206\n",
      "train loss:0.6158997805930644\n",
      "=== epoch:462, train acc:0.8633333333333333, test acc:0.6763 ===\n",
      "train loss:0.4659219343043317\n",
      "train loss:0.5711748521770749\n",
      "train loss:0.5660197587321598\n",
      "=== epoch:463, train acc:0.8566666666666667, test acc:0.6777 ===\n",
      "train loss:0.4806336607212661\n",
      "train loss:0.49686642313499774\n",
      "train loss:0.5035646828990823\n",
      "=== epoch:464, train acc:0.8633333333333333, test acc:0.6803 ===\n",
      "train loss:0.6297288137208927\n",
      "train loss:0.5242711930416163\n",
      "train loss:0.3609954758938471\n",
      "=== epoch:465, train acc:0.8566666666666667, test acc:0.6827 ===\n",
      "train loss:0.4226342346667483\n",
      "train loss:0.5111775705796741\n",
      "train loss:0.4943973019851064\n",
      "=== epoch:466, train acc:0.86, test acc:0.68 ===\n",
      "train loss:0.42746295219438707\n",
      "train loss:0.4910128602059264\n",
      "train loss:0.44986809623482615\n",
      "=== epoch:467, train acc:0.8633333333333333, test acc:0.6826 ===\n",
      "train loss:0.48826830827836715\n",
      "train loss:0.5501032238732553\n",
      "train loss:0.5502328186636182\n",
      "=== epoch:468, train acc:0.8633333333333333, test acc:0.6828 ===\n",
      "train loss:0.5006229613019495\n",
      "train loss:0.4706442953872206\n",
      "train loss:0.4687220895925154\n",
      "=== epoch:469, train acc:0.8633333333333333, test acc:0.6829 ===\n",
      "train loss:0.4525160087797083\n",
      "train loss:0.480212337171372\n",
      "train loss:0.4001800532748877\n",
      "=== epoch:470, train acc:0.8633333333333333, test acc:0.6845 ===\n",
      "train loss:0.4483872562486104\n",
      "train loss:0.5495516756197592\n",
      "train loss:0.47857893705438537\n",
      "=== epoch:471, train acc:0.8633333333333333, test acc:0.682 ===\n",
      "train loss:0.4084987514616048\n",
      "train loss:0.5102685404389374\n",
      "train loss:0.4687776750509966\n",
      "=== epoch:472, train acc:0.8666666666666667, test acc:0.6837 ===\n",
      "train loss:0.4122213003603889\n",
      "train loss:0.30630987429733314\n",
      "train loss:0.46652570380087377\n",
      "=== epoch:473, train acc:0.87, test acc:0.6828 ===\n",
      "train loss:0.4594424922346233\n",
      "train loss:0.3995773531745852\n",
      "train loss:0.4941090685354423\n",
      "=== epoch:474, train acc:0.87, test acc:0.6818 ===\n",
      "train loss:0.5381142858950146\n",
      "train loss:0.5308228381442307\n",
      "train loss:0.47621870725968357\n",
      "=== epoch:475, train acc:0.8766666666666667, test acc:0.6842 ===\n",
      "train loss:0.4577243180045075\n",
      "train loss:0.5189434323171774\n",
      "train loss:0.4592315729384614\n",
      "=== epoch:476, train acc:0.88, test acc:0.6847 ===\n",
      "train loss:0.45968571827233645\n",
      "train loss:0.412895486796388\n",
      "train loss:0.44967823955093805\n",
      "=== epoch:477, train acc:0.8633333333333333, test acc:0.6848 ===\n",
      "train loss:0.490656280632299\n",
      "train loss:0.4661074930866112\n",
      "train loss:0.4845045396293872\n",
      "=== epoch:478, train acc:0.8666666666666667, test acc:0.6875 ===\n",
      "train loss:0.4563143938529493\n",
      "train loss:0.5532553149904887\n",
      "train loss:0.46020487781554176\n",
      "=== epoch:479, train acc:0.8766666666666667, test acc:0.6874 ===\n",
      "train loss:0.5011328002432718\n",
      "train loss:0.40648292755505433\n",
      "train loss:0.482760699134009\n",
      "=== epoch:480, train acc:0.8766666666666667, test acc:0.6856 ===\n",
      "train loss:0.5688231718430082\n",
      "train loss:0.4227855876150759\n",
      "train loss:0.4157039903272563\n",
      "=== epoch:481, train acc:0.8766666666666667, test acc:0.6883 ===\n",
      "train loss:0.46979752946117637\n",
      "train loss:0.38121751634042406\n",
      "train loss:0.4969966586360763\n",
      "=== epoch:482, train acc:0.87, test acc:0.6885 ===\n",
      "train loss:0.4135469221912724\n",
      "train loss:0.42275728807353047\n",
      "train loss:0.5622021934778022\n",
      "=== epoch:483, train acc:0.8733333333333333, test acc:0.6867 ===\n",
      "train loss:0.5260763952972959\n",
      "train loss:0.47365244528254413\n",
      "train loss:0.4387415166055304\n",
      "=== epoch:484, train acc:0.8766666666666667, test acc:0.6896 ===\n",
      "train loss:0.40202841081991986\n",
      "train loss:0.46584133741654166\n",
      "train loss:0.4125717375889646\n",
      "=== epoch:485, train acc:0.88, test acc:0.688 ===\n",
      "train loss:0.39420209991113386\n",
      "train loss:0.46773741964893156\n",
      "train loss:0.4725198794915956\n",
      "=== epoch:486, train acc:0.8666666666666667, test acc:0.6881 ===\n",
      "train loss:0.4565000186183142\n",
      "train loss:0.3651884071256991\n",
      "train loss:0.3352577866928843\n",
      "=== epoch:487, train acc:0.8733333333333333, test acc:0.6877 ===\n",
      "train loss:0.4342603131629374\n",
      "train loss:0.5074300820150666\n",
      "train loss:0.41955727072628074\n",
      "=== epoch:488, train acc:0.8733333333333333, test acc:0.6899 ===\n",
      "train loss:0.5037136564219903\n",
      "train loss:0.4983832497015954\n",
      "train loss:0.46556360852468404\n",
      "=== epoch:489, train acc:0.8766666666666667, test acc:0.691 ===\n",
      "train loss:0.3540822161203077\n",
      "train loss:0.4200879850418793\n",
      "train loss:0.436197940819307\n",
      "=== epoch:490, train acc:0.8766666666666667, test acc:0.6912 ===\n",
      "train loss:0.4678198471967868\n",
      "train loss:0.3998079803381195\n",
      "train loss:0.3998923048031598\n",
      "=== epoch:491, train acc:0.8766666666666667, test acc:0.6891 ===\n",
      "train loss:0.4814813932430361\n",
      "train loss:0.4667429883510054\n",
      "train loss:0.33120863530671035\n",
      "=== epoch:492, train acc:0.8833333333333333, test acc:0.6905 ===\n",
      "train loss:0.4009420685657686\n",
      "train loss:0.36415424248505274\n",
      "train loss:0.4220363318177281\n",
      "=== epoch:493, train acc:0.8866666666666667, test acc:0.6921 ===\n",
      "train loss:0.4588851918798933\n",
      "train loss:0.5115423003465172\n",
      "train loss:0.5621369564404248\n",
      "=== epoch:494, train acc:0.88, test acc:0.6928 ===\n",
      "train loss:0.5111849228171015\n",
      "train loss:0.3980530454816175\n",
      "train loss:0.5439547983234992\n",
      "=== epoch:495, train acc:0.8833333333333333, test acc:0.6923 ===\n",
      "train loss:0.44609262227047297\n",
      "train loss:0.4796206786005586\n",
      "train loss:0.4444528806929819\n",
      "=== epoch:496, train acc:0.8833333333333333, test acc:0.6917 ===\n",
      "train loss:0.3611347958002685\n",
      "train loss:0.5121592265283892\n",
      "train loss:0.5083402039679038\n",
      "=== epoch:497, train acc:0.8866666666666667, test acc:0.6935 ===\n",
      "train loss:0.4689116032401601\n",
      "train loss:0.3904128124192554\n",
      "train loss:0.3909950588238463\n",
      "=== epoch:498, train acc:0.8833333333333333, test acc:0.6937 ===\n",
      "train loss:0.41813089938706943\n",
      "train loss:0.5532960625930098\n",
      "train loss:0.5159273109049177\n",
      "=== epoch:499, train acc:0.8833333333333333, test acc:0.6959 ===\n",
      "train loss:0.4995186198126701\n",
      "train loss:0.4269667689300337\n",
      "train loss:0.3332656226496371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:500, train acc:0.88, test acc:0.693 ===\n",
      "train loss:0.4874956883760057\n",
      "train loss:0.4187831161338169\n",
      "train loss:0.42088449505943615\n",
      "=== epoch:501, train acc:0.8833333333333333, test acc:0.694 ===\n",
      "train loss:0.4510592070462852\n",
      "train loss:0.3408937702564198\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.696\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "# use_dropout = False  # 드롭아웃을 쓰지 않을 때는 False\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "# num_epochs = 301\n",
    "num_epochs = 501\n",
    "# num_epochs = 1001\n",
    "# num_epochs = 1501\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=num_epochs, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc3eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, color='k', marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, color='r', marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.03)\n",
    "plt.legend(loc='upper left')\n",
    "# plt.legend(loc='lower right')\n",
    "box_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395bca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
